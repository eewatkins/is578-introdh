work_id,conference_label,conference_short_title,conference_theme_title,conference_year,conference_organizers,conference_series,conference_hosting_institutions,conference_city,conference_state,conference_country,conference_url,work_title,work_url,work_authors,work_type,full_text,full_text_type,full_text_license,parent_work_id,keywords,languages,topics
1075,2009 - UMD College Park,UMD College Park,,2009-01-01T00:00:00Z,ADHO,ADHO,"University of Maryland, College Park",College Park,Maryland,United States,http://web.archive.org/web/20130307234434/http://mith.umd.edu/dh09/,Inventing the Future of AI for Games: Lessons from EMPath,,Sherol Chen,poster / demo / art installation,"The space of Narrativity has had the benefit of being
explored for centuries. Technology, however, introduces
a new factor to pioneer by expanding the possibilities
of both the experiencing and the telling of a story.
Advancements of AI provide a multitude of techniques
for the process of authoring and the actual authoring of
stories in games. This process, however, is not so straight
forward, and has proved to be extremely challenging in
practice. Narratives in games, although sharing similar
narrative qualities of its medium predecessors, deliver
a highly interactive experience, making games a matter
of new media and new analysis. The purpose of this talk
is to demonstrate and give an idea of what the contrast
is between the theories and models created in academia
and the practice of industry in using technology to express
compelling and believable experiences.
Introduction
With emphasis on the advancements of believability in
areas of sound and scene, the advancements in the believability
or complexity toward intelligent interactions
within commercial video games are comparably lacking.
Certain games aim to leave the story up to the user’s
imagination, while others reduce user agency to create
an artistically inspired story, and still, others are focused
on procedurally creating a story that has both high user
agency and dramatic significance. Arguments that support
story games demonstrating high levels of intelligence
claim that with the incorporation of Drama Managing,
Multi-Agent Systems, Reactive Planning, and
other sub-areas of AI will come a new frontier in experiencing
and telling stories reducing traditional conflicts
(Mateas 2001). On the other hand, game developers in
industry are resistant against these ideas due to the complications
that come along with adding such methods.
Efforts in commercial games have been more successful
in making the most out of scripted stories, maximizing
from sound and scene, and sacrificing certain qualities
in order to strengthen others. In addition to surveying
the areas that are currently researched in academia and
discussing games developed through research, there will
be a demonstration of the EMPath project. EMPath is a
prototype sized, adventure game that utilizes the Declarative Optimization-Based Drama Manager (DODM).
This prototype game, developed at UC Santa Cruz, is a
real-time playable game that uses the DODM architecture
and has been tested on over 100 users. The purpose
of this demo is to exhibit a novel AI-based approach to
interactive storytelling, as well as provide a concrete example
of the challenges in the design process. Figure 1
is a screen shot of the dungeon map in the original EMPath
game (Sullivan 2009).
Figure 1. The 5x5 map world of EMPath.
Drama Management
A drama manager (DM) monitors an interactive experience,
such as a computer game, and intervenes to shape
the global experience so that it satisfies the author’s expressive
goals without decreasing a player’s interactive
agency. Most research work on drama management has
proposed AI architectures and provided abstract evaluations
of their effectiveness. A smaller body of work has
evaluated the effect of drama management on player experience,
but little attention has been paid to evaluating
the authorial leverage provided by a drama management
architecture: determining, for a given DM architecture,
the additional non-linear story complexity a DM affords
over traditional scripting methods. This poster will propose
three criteria for evaluating the authorial leverage
of a DM: 1) the script-and-trigger complexity of the DM
story policy, 2) the degree of policy change given changes
to story elements, and 3) the average story branching
factor for DM policies vs. script-and-trigger policies
for stories of equivalent quality. Figure 2 illustrates the
decision-tree representation approach in evaluating authorial
leverage. For preliminary studies in evaluating
complexity of the drama manager, thousands of partial
stories were generated and used to train and test decision
trees using the J48 algorithm implemented in Weka, a
machine-learning software package.1 Partial stories (the
independent variable) are represented by a set of boolean
flags indicating whether each plot point and DM action
has happened thus far in this story, and, for each pair of
plot points a and b, whether a preceded b if both happened
(Chen 2009).
Figure 2. Zoomed-in view of a decision tree that has
learned from the DM.
Lessons from EMPath
Gains for creating a more intelligently interactive story
need to be proven through subject testing and other types
of evaluation. In particular, there are two metrics that
need to be established: one to show overall improved
experience, and one to show the lightening of authorial
burden. These approaches are demonstrated in previous
experiments with EMPath; however, the prototype
games that are feasible for research have difficulty demonstrating
significant results due to the scale of these
smaller games. Other challenges that arise from implementing
and evaluating AI systems are as follows (Chen
2009):
• Authoring: Incorporating an AI system creates the
burden of domain understanding, forcing an author
to break traditional habits in authoring.
• Evaluation Measures: Story qualities must be
mathematically represented in order to show improvement
or to encourage better interactions.
• Player Modeling: AI systems often depend on
predicting and anticipating user actions and motivations.
The system would need to model human
tendencies mathematically.
• Simulation: Experiments designed to run offline,
according to the system’s user model are needed
to provide authorial leverage and sanity checks for
story evaluation comparisons.
• User Testing: Users need to notice a difference in
their overall experience when using the AI system
versus not using the AI system. Experiments need to be carefully designed to show improvement in the
user data.
• Game Design: The game must be designed to be
able to demonstrate such differences. In general,
games that are created for research purposes are often
not expansive or large enough to show significant
results.
• Trail Blazing: Finally, a great challenge in creating
AI systems is that evaluation measures and user
study approaches have not been rigorously tested
for these purposes
Dimensions of Narrativity & Interactivity
Taking another look at Narratology, establishing a more
complete understanding of narrative may help ameliorate
some of the challenges in designing and testing AI
systems. If there is a better understanding of the objectives
that an AI system is aiming toward, then the space
of story that it creates may be more easily evaluated. For
instance, reducing the space of possible stories by fixing
the ontological variations in an interactive story space
reduces the variety of experiences, but results in a more
focused output. With a fixed and linear diegetic universe,
both the author’s artistic vision is maintained and, as a
result, the dramatic significance of the vision. Research
can begin by finding ways of delegating types of discourse
actions and performing them on a fixed set of plot
points contingent on the actions of the user in trying to
optimize user agency under those conditions.
Figure 3. Adaptations of Ryan’s 8 narrative dimensions.
By establishing narratives as a relationship among scalar
properties, Marie-Laure Ryan’s dimensions of narrativity
gives a solid means to compare and analyze interactive
narratives (Ryan 2006). For Ryan, her dimensions
are more to establish conditions for the mark of the narrative.
For the purpose of the discussion, a variation of
Ryan’s dimensions will be used analyze the experiential
variations that result from interactivity in narratives.
Figure 3 visually illustrates the analogous dimensions.
The new adaptation, instead of being a model for narratives,
will serve as a model for interactive experiences.
The four dimensions are: temporal (an axis to situate
time), event space (an axis for delineating the occurrences
in a story space), foci (the experiential views from
intelligent existents or perspective), and discourse (an
axis for determining the means of how a story is told).
For further explanation of the relationship between these
dimensions, it helps to “fix” or ignore one or more of the
dimensions.
Conclusion
Overall, this presentation will deliver a broad understanding
of the ways in which AI can integrate with
interactive stories and create a diversity of experiences
and outcomes. In contrast to commercial games, the process
of interactive storytelling provides insights into the
endeavors of universities and research institutions pioneering
the area through advancements in AI. Additionally,
there will be a live demo of the EMPath project in
conjunction to a discussion of the difficulties and challenges
in the counter-intuitive design process of a story
that utilizes concurrent technologies of AI. Ultimately,
this demo will be a case study towards gaining a deeper
understanding of the challenges to be faced before what
is possible in storytelling can be made practical through
the intersections of the arts, sciences, industry, and academia.
Notes
1http://www.cs.waikato.ac.nz/ml/weka/
References
Chen, Nelson, Mateas (2009). Evaluating the Authorial
Leverage of Drama Management. AAAI Spring Symposium,
Interactive Narrative II.
Chen, Sullivan, Nelson, Wardrip-Fruin, Mateas (2009).
Intelligent Interactive-Stories: Theory versus Practice.
Game Developers Conference, San Francisco, CA.
Mateas (2001), A preliminary poetics for interactive
drama and games. Digital Creativity, vol 12, number 3.
Ryan (2006). Narrative, Media, and Modes: Avatars of
Story. University of Minnesota Press.
Sullivan, Chen, Mateas (2009). Abstraction to Reality:
Integrating drama management into a playable game
experience. AAAI Spring Symposium, Interactive Narrative II.",txt,This text is republished here with permission from the original rights holder.,,,English,
1386,2011 - Stanford,Stanford,Big Tent Digital Humanities,2011-01-01T00:00:00Z,ADHO,ADHO,Stanford University,Stanford,California,United States,https://dh2011.stanford.edu/,Towards a Narrative GIS,,John McIntosh;Grant De Lozier;Jacob Cantrell;May Yuan,paper,"Towards a Narrative GIS
McIntosh, John, jmcintosh@ou.edu University of Oklahoma,
De Lozier, Grant, ghaxed@gmail.com University of Oklahoma,
Cantrell, Jacob , jcantrell@ou.edu University of Oklahoma,
Yuan, May, myuan@ou.edu University of Oklahoma,
Introduction
Research in narrative intelligence applies artificial intelligence approaches to study human ability to organize experience into narrative form (Mateas and Sengers 2003). Narratives are traditionally defined as “a series of temporally ordered clauses” (Labov 1972, p360-361). The time-centric approach leads to a lesser consideration of space in narrative construction and analysis. In contrast, we advocate a geospatial narrative in order to stress the importance of space and time in understanding the ordering and spatial interaction of events.

We define a geospatial narrative as a sequence of events in which space and time are equally important. Narratives are stories that constitutes sequential organizations of events (Franzosi 2010). Each event in a narrative relates sequential or consequential occurrence in space and time. The conventional Geographic Information Systems (GIS) center on information about spatial states of reality, and temporal information is handled as add-ons to spatial objects. Alternatively, we conceptualize a narrative GIS that emphasizes representing and ordering events in space and time as well as functional abilities to construct meaningful geospatial narratives. While an event is a complex, fuzzy term, we start with one basic linguistic element of narratives: action, as the primitive data construct to start building a narrative GIS. By relating action events across space and time, a narrative GIS aims to discover spatiotemporal correlates among actions and relate actions across scales.

Depending on the perspectives, there are many kinds of events, e.g. instantaneous events, discrete events, cyclic events, transitional events, and others. In contrast to TimeMaps (Farrimond et al. 2008), our vision of a Narrative GIS goes beyond spatiotemporal visualization to spatial analytics. By using action events as the primitive data constructs, a narrative GIS can support spatial queries of sequential and consequential actions. A Narrative GIS is therefore capable of revealing how time unfolds change and space unfolds interactions (Massey 2005).

We use two distinctive corpuses of histories in building narrative GIS databases and narrative analytics as a proof of concepts: Dyer's Compendium of the War of the Rebellion and the Richmond Daily Dispatch. Frederick H. Dyers, a Civil War veteran compiled the Compendium based on materials from the Official Records of the Union and Confederate Armies and other sources. The compendium lists organizations and movements of regiment cavalries mustered by State and Federal Governments for services in the Union Armies. Collaborating with the digital scholarship group at the University of Richmond, we have started with four files from Dyer's Compendium: the 45th Massachusetts Infantry, the 107th Pennsylvania Infantry,the1stCaliforniaInfantry,andthe1stNewYorkCavalry. The Richmond Daily Dispatch was one of the primary news media in the south during the Civil War. The newspaper was one of the most widely distributed newspapers of the south and included news from the entire east coast. The Richmond Daily Dispatch retained the reputation as politically unbiased was published throughout the Civil War.

Methodology
Our idea of a narrative GIS consists of (1) semantic elements (who did what), (2) temporal elements (when), and (3) spatial elements (where). A geospatial narrative object integrates the three elements and enables search for and analysis of spatial and temporal relationships among narrative objects. Input data for narrative GIS vary widely from structured to unstructured sources. In this study, both input data are texts, albeit in very different structures. Dyer's Compendium concisely lists regiment movements. Richmond Daily Dispatch consists of news articles. Spatial and temporal connections among units in these texts are considerably different. Nevertheless, the conceptual framework of a narrative GIS demands the identifications of semantic, temporal, and spatial elements from the texts to form narrative objects and relationships. As such, our workflow includes six key steps: (1) extract text analysis units; (2) identify action verbs; (3) identify time for words and text units; (4) identify locations for words and text units; (5) combine all identified elements into a GIS database; and (6) build spatial and temporal relationships among narrative objects. A schematic view of the workflow is presented in figure 1

Figure 1

Full Size Image

We begin with electronic versions of the historical documents. The texts are split into subsets such as newspaper articles or book chapters for processing. These subsets are typically written as a unit and need to be analyzed that way for successful interpretation. For each processing unit, we apply natural language processing to tokenize sentences and identify parts of speech (e.g. verbs and nouns). The parts of speech provide important clues to extract information.

The work presented here is centered on the location, time, and other characteristics of events. The part of speech tagging is used to identify verbs. We are most interested in “action” verbs and refine our list of potential candidates by removing stative and modal verbs. Location referencing begins with recognition of a standard grammatical structure to the way locations appear in text. In general, locations are proper nouns that do not directly follow a determiner (except for physical features).

Candidate words are matched to all their possible real-world geographic referents in the “Gazetteer Matching” process. A number of different gazetteers are utilized in the matching including the US Populated Places gazetteer and State hydrography datasets from the USGS, historical counties, states, and territories files from National Historical Geographic Information System, and the US Census Bureau’s historical 100 largest cities dataset (US BGN; US NHD; NHGIS 2008; Gibson 2008). These data are assembled in GIS and each location is identified with a historically and spatially appropriate hierarchy. The names of geographic locations are often highly ambiguous. For example “Georgetown” has over 70 possible locations among U.S. cities. Disambiguating a word to its true location is an important and difficult task. A substantial amount of work has already been done on location disambiguation under the heading of “Toponym Resolution” (Leidner2007;Leidneretal2003). Figure 2 illustrates the steps in the location referencing process.

Figure 2

Full Size Image

The temporal processing steps aim to extract dates, durations of events and the relative temporal ordering between events. Historical texts contain temporal information in a variety of formats. Most obvious are explicit dates that include information such as the day, month and year. In addition, these texts often include clues to derive dates and relative ordering of events. For example words such as “yesterday“ or “last week” allow the date to be derived based on a temporal relation to an anchor date (Han 2006). Similarly, relative temporal expressions allow explicit dates to be determined based on temporal relations to the current temporal focus (Han 2009).

Figure 3 outlines the steps in our approach.

Figure 3

Full Size Image

We begin by extracting anchor dates such as the date of publication for a newspaper article and explicit dates found in the text. We use temporal indicator words to refine the date of events and help establish temporal ordering. Explicit dates contained in the text are modified by deictic or temporal expressions. Semantic relationships between events are extracted based on semantic indicators. When all of the temporal information is relative and there are no explicit dates to give an explicit order, thirteen temporal relationships are used to find the temporal ordering (Allen 1983).
Results and Concluding Remarks
Thus far, our effort has been focused on extraction of events from the natural language text sources, anchoring the events to geographical locations and in time, and extracting information on the actors and objects involved in the events. Figure 4 illustrates results from Dyer's Compendium of the War of the Rebellion.

Figure 4

Full Size Image

This figure shows the activity of the 6th New York Regiment Calvary in Maryland and Virginia in September and October of 1862. The processing identified the events including the regiment’s movements and splitting off of a reconnaissance mission from Lovettsville to Smithville while the main regiment moved to Kearnysville. While this example from a single source, it illustrates the potential for the system to support more complex geospatial narratives with the addition of information from other sources.
Figure 5 shows a visualization of a Richmond Daily Dispatch article.

Figure 5

Full Size Image

The article describes a letter from a Union colonel to his family. It discusses the Union’s plan to move troops to Alexandria Virginia the next evening. The article illustrates that in addition to working with events that had already occurred the approach can also be used to help investigate the thoughts and motivation leading to events that had yet to occur.
These examples of preliminary results demonstrate the basic use of a Narrative GIS. As we continue building the event narrative database, additional functions will be built in for narrative analytics. For example, we are interested in deciphering the local, regional and national processes on emancipation and to identify scalar effects on military, political, and individual processes. One approach will be extracting reports on battles and run-away slaves and analyze spatial and temporal correlations among these events. When we extract events of different categories in space and time, a Narrative GIS will allow us to analyze spatial and temporal relationships among these kinds of events to draw insights into the integration of multiple perspectives and interpretations of geospatial narratives.

References:
Allen, J. Waltz, D. 1983 Maintaining Knowledge about Temporal Intervals Communications of the ACM 26 11 32-843

Bird, S. Klein, E. Loper, E. 2009 Natural Language Processing with Python --- Analyzing Text with the Natural Language Toolkit Cambridge, MA O'Reilly Media

Farrimond, B. Presland, S. Bonar-Law, J. Pogson, F. 2008 Making History Happen: Spatiotemporal Data Visualization for Historians Second UKSIM European Symposium on Computer Modeling and Simulation Liverpool, UK IEEE 424-429

Fellbaum, C. 1998 WordNet: An Electronic Lexical Database Cambridge, MA The MIT Press

Franzosi, R. 2010 Quantitative Narrative Analysis Los Angelas, CA SAGE Publications, Inc.

Gibson, C. 2008 Population Of The 100 Largest Cities And Other Urban Places In The United States: 1790 to 1990. U.S. Census Bureau, Population Division (link)

Han, B. Gates, D. Levin, L. 2006 From Language to Time: A Temporal Expression Anchorer Proc. 13th International Symposium on Temporal Representation and Reasoning

Han, B. 2009Reasoning about Temporal Scenario in Natural LanguageIn the Proceedings of AAAI Workshop on Spatial and Temporal Reasoning

Jackendoff, R. 1992 Languages of the Mind Cambridge, MAThe MIT Press

Labov, W. 1972 Language in the inner cityPhiladelphia University of Pennsylvania Press

Leidner, J, L. Sinclair, G. Webber, B 2003 Grounding spatial named entities for information extraction and question answering Proceedings of the HLT-NAACL 2003 Workshop on Analysis of Geographic References Edmonton, CAN

Leidner, J 2007 Toponym Resolution in Text: Annotation, Evaluation and Applications of Spatial Grounding of Place Names. Diss. University of Edinburgh, School of Informatics. Institute for Communicating and Collaborative Systems

Massey, D. 2005 For Space Thousand Oaks, CA Sage

Mateas, M. Sengers, P. 2003 Narrative Intelligence. Amsterdam/Philadelphia John Benjamins Publishing Company

Miller, G. Beckwith, R. Fellbaum, C. Gross, D. Miller, K. 1993 Introduction to WordNet: An Online Lexical Database (Revised) Princeton University

Pouliquen, B. Kimler, M. Steinberger, R. Ignat, C. Oellinger, T. 2006 Geocoding Multilingual Texts: Recognition, Disambiguation and Visualisation In Proceedings of The Fifth International Conference on Language Resources and Evaluation(LREC) (link)

National Historical Geographic Information System 2008 Minnesota Population Center: University of Minnesota. Minneapolis, MN (link)

U.S. Board on Geographic Names: Domestic and Antarctic Names – State and Topical Gazetteer Download Files United States Geological Survey (link)

U.S. Geological Survey: National Hydrography Dataset United States Geological Survey (link)",txt,This text is republished here with permission from the original rights holder.,,,English,
1531,2012 - Hamburg,Hamburg,"Digital Diversity: Cultures, languages and methods",2012-01-01T00:00:00Z,ADHO,ADHO,Universität Hamburg (University of Hamburg),Hamburg,,Germany,http://www.dh2012.uni-hamburg.de/,"Writing with Sound: Composing Multimodal, Long-Form Scholarship",,Jentery Sayers,paper,"Writing with Sound: Composing Multimodal, Long-Form Scholarship
Print Friendly
XML
Sayers, Jentery, University of Victoria, Canada, jentery@uvic.ca
Historically speaking, the fields of digital humanities and media studies have remained parallel at best, with the former anchored more in computational practices and technical competencies than the latter. However, recent work – such as Sharon Daniel’s ‘Public Secrets’ (2007), Kathleen Fitzpatrick’s Planned Obsolescence (2011), Matthew Kirschenbaum’s Mechanisms (2008), Kari Kraus’s ‘Conjectural Criticism’ (2009), and Lev Manovich’s cultural analytics (2012) – suggestively troubles this parallelism. From the vantage of media studies, digital humanities allows scholars to shift from commenting about new media and technologies to constructing arguments with and through them (McPherson 2009: 120). Informed by claims from experience and anchored in embodied acts of building, digital humanities arguments necessarily become ‘hands on,’ and scholarly distance from technologies no longer holds. Meanwhile, media studies investments in cultural criticism and situated knowledge-making are increasingly important to today’s digital humanities practitioners, involved such as they are in multimodal communication (e.g., interactive visualizations, geospatial representations, rich exhibits, and gaming). For instance, Alan Liu argues that ‘digital humanities should enter into fuller dialogue with the adjacent fields of new media studies and media archaeology so as to extend reflection on core instrumental technologies in cultural and historical directions’ (Liu 2012: 501, emphasis added). This fuller dialogue would enhance the field’s awareness of how work with technologies and data intersects with the relevant social, economic, and political issues of our time. Assuming those conversations are inevitable (and that media studies and digital humanities should continue to overlap and intersect), a key question thus emerges: what would be an appropriate platform for such forms of scholarly communication? How would it function, and under what assumptions about how digital humanities and media studies are practiced?

With these questions in mind, this talk uses the author’s ongoing book project (tentatively titled, How Text Lost Its Source: Magnetic Recording Cultures) to present his findings on the yet-to-be-released Scalar platform. Supported by the Andrew W. Mellon Foundation and the U.S. National Endowment for the Humanities, Scalar is designed for authoring and publishing multimodal books. Built using PHP ARC2 (a MySQL-based Semantic Web/RDF framework), HTML, CSS, jQuery, XLST, Dublin Core, and other ontologies including SIOC, it enables users to assemble media (e.g., audio files) from multiple sources and juxtapose them with their own writing. The platform particularly facilitates work with visual materials; however, it also lends itself to audio, which is central to the history articulated in How Text Lost Its Source. Throughout the talk, ‘multimodal’ is preferred over ‘multimedia’ because the term stresses systems of ‘sensory or perceptual experience’ over the ‘means of conveying [or storing] a representation’ (Anastopoulou, Baber & Sharples 2001). And in the particular case of a Scalar book, it assumes that: (1) attention behaviors such as reading, watching, and listening are not inherent to or determined by a medium, (2) digital communication frequently entails blending approaches to composition (e.g., through images, audio, video, text, and databases), (3) layers of digital content are materially distinct and yet function relationally, and (4) scholarly interpretation demands several sensory modes (e.g., listening closely, scanning, and clicking).

The author’s preliminary findings on Scalar show that, most importantly, it encourages reflexive approaches to the computational processes involved in digital humanities research. Influenced by the work of LaDona Knigge and Meghan Cope (2006) as well as Mei-Po Kwan (2002), the author organizes these findings according to how Scalar fosters: (1) exploratory research across multiple archives, (2) iterative and recursive argumentation, (3) an oscillation between abstract and concrete expressions, and (4) multiple interpretations of media and cultural history. Throughout, an emphasis is placed on juxtaposing critical writing with the critical use of audio in Scalar, including a few demonstrations of How Text Lost Its Source. 

In the case of exploratory research across multiple archives, the platform is persuasive because it affords composites of text, audio, video, and images drawn from the various histories of magnetic recording, enabling the author to represent audio across the material specificities of multiple media (rather than reducing audio to simply sound or text). It also allows historical evidence to be modeled and exhibited independently of the author’s writing (e.g., audiences can navigate all audio files collected for the history without reading the author’s interpretations). However, any given audio file in a Scalar book can be annotated through discrete, time-stamped commentary by the author, and this commentary is displayed within the medium’s own temporality. While such features are now typical in visual culture (e.g., annotating lexia in Commentpress or tagging an image in Flickr), few such mechanisms exist for the scholarly treatment of sound.

Additionally, Scalar facilitates iterative and recursive expression because it not only keeps a version history of all contributions and makes that history public; it also allows authors to duplicate media content (e.g., a magnetic tape recording) in another context and then re-evaluate it. Evidence in a scholarly argument thus becomes subject to constant re-visitation and re-use (e.g., the same tape recording is interpreted several times), underscoring the fact that media histories emerge from multiple (and often conflicting) perspectives, worldviews, and accounts. Importantly, these media – together with the author’s writing – are presented throughout a Scalar book both in the aggregate and in the particular. Using RDF/XML and D3.js dynamic visualizations, any single instance (i.e., anything with a URL) in the book can be situated in relation to the balance of the content. Consequently, the book’s historical materials are structured and expressed in such a way that they can be studied in isolation but cannot exist independently. And when a book is modeled effectively, its audiences can study complex cultural relationships (e.g., between two audio files) established by the author. Importantly, such relationships are frequently constructed and encoded based on what has not been written or recorded in media history. While RDF/XML and D3.js help scholars organize and convey it, no computational practices exist (as of yet) for mining or visualizing implicit content, especially in the case of sound.    

Finally, the Scalar platform excels at fostering various interpretations of media history by allowing audiences to – in the fashion of context-sensitive design – select how a book’s content is viewed. These views range from ‘text-only’ and ‘media-emphasis’ to a radial visualization, a force-directed graph, and a history browser. Again, this array of perspectives brushes against any totalizing account of media history, the cultural history of magnetic recording included. It also destabilizes a scholar’s authority over an audience’s interpretation as it allows them to arrange and re-arrange content. Such an emphasis on the constructedness of arguments is especially key in a moment when visualizations are gaining traction in the field. The dynamic juxtapositions of writing and media in Scalar – D3 visualizations among them – actively demonstrate how our data and content are taken, not given (Drucker 2011). They also facilitate robust and often contradictory accounts of material histories, where scholars can: (1) argue with and through the media they study; (2) present material relationally and discretely, either with or without commentary; (3) author within a medium’s temporality; (4) exhibit the otherwise ignored processes of research and revision; (5) duplicate and interpret media in multiple contexts; and (6) underscore the contingent character of historical artifacts, to such an extent that any complete description of a given media object is difficult to say the least.

references
Anastopoulou, S., C. Baber, and M. Sharples (2001). Multimedia and Multimodal Systems: Commonalities and Differences. Proceedings of the 5th Human Centred Technology Postgraduate Workshop. University of Sussex. http://www.syros.aegean.gr/users/manast/Pubs/Pub_conf/C03/C03.pdf.

Daniel, S. (2007). Public Secrets. Vectors 2(2). http://vectors.usc.edu/index.php?page=7&projectId=57.

Drucker, J. (2011). Humanities Approaches to Graphical Display. Digital Humanities Quarterly 5(1). http://digitalhumanities.org/dhq/vol/5/1/000091/000091.html.

Fitzpatrick, K. (2011). Planned Obsolescence: Publishing, Technology, and the Future of the Academy. New York: New York UP.   

Kirschenbaum, M. (2008). Mechanisms: New Media and the Forensic Imagination. Cambridge: MIT Press.

Knigge, LaDona, and M. Cope (2004). Grounded Visualization: Integrating the Analysis of Qualitative and Quantitative Data through Grounded Theory and Visualization. Environment and Planning A 38(11): 2021-2037. 

Kraus, K. (2009). Conjectural Criticism: Computing Past and Future Texts. Digital Humanities Quarterly 3(4). http://www.digitalhumanities.org/dhq/vol/3/4/ 000069/000069.html.

Kwan, M.-P. (2002). Feminist Visualization: Re-envisioning GIS as a Method in Feminist Geographic Research. Annals of the Association of American Geographers 92: 645-661.

Liu, A. (2012). Where Is Cultural Criticism in the Digital Humanities? In M. K. Gold (ed.), Debates in the Digital Humanities. Minneapolis: U of Minnesota P, pp. 490-509.

Manovich, L. (2012). Trending: the Promises and the Challenges of Big Social Data. In M. K. Gold (ed.), Debates in the Digital Humanities. Minneapolis: U of Minnesota P, pp. 460-475.

McPherson, T. (2009). Media Studies and the Digital Humanities. Cinema Journal 48(2): 119-123.",txt,This text is republished here with permission from the original rights holder.,,,English,
1720,2013 - Nebraska,Nebraska,Freedom to Explore,2013-01-01T00:00:00Z,ADHO,ADHO,University of Nebraska–Lincoln,Lincoln,Nebraska,United States,http://dh2013.unl.edu/,Keywords to Keyframes: Video Analytics for Archival Research,,Virginia Kuhn;Michael Simeone,workshop / tutorial,"The target audience for this workshop consists of scholars with research interests related to the way that visual media impacts culture.

Description + Schedule
This workshop will serve scholars of any level of technical expertise who are interested in studying images as part of their work in the digital humanities using a hybrid method that combines machine analytics (keyframes) and crowd-sourced tagging (keywords). Facilitating a discussion and training session featuring up to twenty participants, we will demo the Large Scale Video Analytics (LSVA) workbench for moving and still image analysis and archiving. The LSVA is a web portal developed through a collaboration among the National Center for Supercomputing Applications (NCSA) and the Extreme Science and Engineering Discovery Environment (XSEDE), the IML (Institute for Multimedia Literacy), and ICHASS (the Institute for Computing in the Humanities, Arts and Social Science). The LSVA has customized the prominent Medici content management system, a multimedia database which has served scholars worldwide. The LSVA requires no software installation, though we do require online access. Further, we will provide access to IM2Learn, a free software package for image analysis developed by the NCSA. There will be no CFP associated with this workshop; rather, we would like participants to self select.

The LSVA deploys the application of various algorithms for image recognition and visualization into the workflow that allows real-time analysis of video, as well as crowd-sourced content labeling such that the system becomes more valuable the more it is used.

In addition, the LSVA team has created and customized visualization tools that enhance research in several ways: novel visualizations employ spatial and temporal simultaneity, revealing unique aspects of a single film sequence; comparative visualizations represent relationships among multiple films within an archive; and, finally, the integration of visualization imagery becomes an input tag and a front end process that feeds the Medici content management system and enhances word-based labels, helping to close the semantic gap that occurs when words are applied to images.

8:00-8:30 am: Introduction to basic concepts of computer vision and image retrieval
8:30-9:00 am: Overview of standard research methodologies and those the LSVA extends
9:00-9:15 am:BREAK
9:15-10:00 am: Demo of LSVA system and walkthrough of interpreting output and requerying
10:00-11:00 am: Hands-on with LSVA system: uploading, sorting, and analyzing moving and still images
Workshop Leader Bios
BIO: Virginia Kuhn is associate director of the Institute for Multimedia Literacy, an organized research unit in the School of Cinematic Arts at the University of Southern California. She was the 2009 recipient of the USC provost’s Award for Teaching with Technology, she co-chairs the Scholarly Interest Group on Media Literacy and Pedagogical Outreach for the Society for Cinema and Media Studies, and she serves on the editorial boards of several journals of media and technology. She joined USC in 2005 after successfully defending one of the first born-digital dissertations in the US, challenging archiving and copyright conventions. Committed to helping shape open source tools for scholarship, she published the first article created in Scalar, which appeared in the International Journal of Learning and Media and titled “Filmic Texts and the Rise of the Fifth Estate. She also serves on the editorial boards of several journals of media and technology.

BIO: Michael Simeone is the Associate Director for Research and Interdisciplinary Studies at ICHASS at the University of Illinois at Urbana-Champaign. Aside from his work on projects that engage the computational study of video, image-analysis of Great Lakes area historical maps, and the significance of social network analytics for the humanities, his research focuses on the intersection of humanities research procedures and data science. He received his PhD in English from the University of Illinois at Urbana-Champaign.",txt,This text is republished here with permission from the original rights holder.,,,English,
1816,2014 - Lausanne,Lausanne,Digital Cultural Empowerment,2014-01-01T00:00:00Z,ADHO,ADHO,École Polytechnique Fédérale de Lausanne (EPFL);Université de Lausanne,Lausanne,,Switzerland,https://web.archive.org/web/20161227182033/https://dh2014.org/program/,<audio>Digital Humanities</audio>: The Intersections of Sound and Method,,Tanya Clement;Kari Kraus;Jentery Sayers;Whitney Trettien;David Tcheng;Loretta Auvil;Tony Borries;Min Wu;Doug Oard;Adi Hajj-Ahmad;Hui Su;Mary Caton Lingold;Daren Mueller;William J. Turkel;Devon Elliott,panel / roundtable,"A wide range of interdisciplinary scholarship on sound has sparked investigations into the cultural histories of aurality and sound reproduction, the politics of the voice and noise, urban soundscapes, ethnographic modernities, acoustemologies, and the sonic construction of gender, race, and ethnicity.[i] These important qualitative studies, moreover, have in recent years been supplemented by large-scale quantitative analyses of speech and music datasets, several of which have been underwritten by the International Digging into Data Challenge, including the “Structural Analysis of Large Amounts of Music” (SALAMI) and the “Mining a Year of Speech” projects. Yet a lingering textual bias within digital humanities – largely a product of the field’s emergence from textual and literary studies – has obscured the significance of this work for the field, often preventing meaningful overlap. Copyright restrictions, the difficulties of archiving audio formats, and the general lack of tools for researching and writing in audio have contributed to the difficulty of working with sound in digital projects. Aside from the occasional use of CD appendixes or supplementary websites, for example, many studies have not taken full advantage of the affordances of digital media to produce scholarship that integrates audio content into scholarly argumentation. It is against this backdrop that leading sound theorist Jonathan Sterne has argued that “existing digital humanities work has largely reproduced visualist biases in the humanities” (2011).
By identifying and highlighting four research initiatives clustered around audio artifacts, this panel aims to bring sound scholarship and digital humanities into a more meaningful conversation with each other. As these projects demonstrate, sound is materially constituted, containing invisible environmental fingerprints or leaving physical traces in artifacts; and, further, is performative and temporally mediated. Thus to access and analyze sound requires not only a new approach to “tool making” within digital humanities, but a deeper engagement with media studies, archival science, and creative forms of scholarship more generally. As Trettien and Lingold’s Soundbox initiative shows, the methodological vibrancy of the field is also predicated on innovation and reform of our critical infrastructures, including the development of publication environments that can take advantage of the cross-medial character of much sound research. Elliott’s kits for cultural history, for example, allow users to experience the past through multiple sensory channels, including sight, sound, and touch; and Clement and Kraus’s work incorporates extensive spectrographic analysis. Thus a larger aim of the panel is to draw attention to the richly synaesthetic nature of digital sound studies.
Access and Analysis, Tanya Clement (15 minutes)

There are few analysis tools available for humanists interested in accessing and analyzing audio archives that comprise significant artifacts of bygone oral traditions represented in storytelling, speeches, oral histories, and poetry performances. In response to this lack, the iSchool at UT-Austin and the Illinois Informatics Institute (I3) at the University of Illinois at Urbana-Champaign (UIUC) hosted a year-long NEH-funded Institute for Advanced Topics in the Humanities called High Performance Sound Technologies for Analysis and Scholarship (HiPSTAS). HiPSTAS included twenty humanities junior and senior faculty and advanced graduate students as well as librarians and archivists interested in analyzing large audio collections. As this speaker will address, HiPSTAS has yielded significant results for audio big data analysis in the humanities including an implementation of the ARLO (Adaptive Recognition with Layered Optimization) software, a machine learning application for analyzing sound on Stampede, an NSF petascale HPC system at the Texas Advanced Computing Center. Originally developed to classify and analyze bird calls by extracting audio features and displaying the audio data as a spectral graph (Downie et al. 2008, Punyasena et al. 2012), ARLO has also been used by humanists as part of HiPSTAS to extract basic prosodic features such as pitch, rhythm and timbre for matching, discovery (clustering) and automated classification (prediction or supervised learning) (Figure 1). This talk will discuss how significant sonic patterns of interest to humanists are discoverable using ARLO with the PennSound poetry archive and the University of Texas Folklore Center Archives, among other collections.

Fig. 1: This spectrogram, created in ARLO, shows Gertrude Stein reading “Some such thing” from her novel The Making of Americans; each row of pixels is a frequency band presented across an X-access of time.
Media Archaeology, Devon Elliott (15 minutes)

Recent research in media archaeology (Fuller 2005, Gitelman 2006, Kirschenbaum 2008) underscores why the material particulars of technology matter where questions of culture are concerned. This research is frequently anchored in archival documents—including lab notebooks, patents, and engineering journals—that correspond with technological experiments. Building on this research, this talk shares initial findings from the “Kits for Cultural History” project, a collaboration between the Maker Lab in the Humanities (UVic), the Lab for Humanistic Fabrication (Western), and several memory institutions across Canada. The project involves making physical kits that encourage scholars to reconstruct historical experiments through the use of schematics, facsimiles, and rich media. Audio is central to a number of these kits, especially kits that focus on sound reproduction. Not only does it add another modality to research that is usually text-based or visual in character. It also emphasizes how any media history is a history of the senses: a history of how embodied behaviors like listening relate recursively with technological developments. With audio in mind, the talk argues for the relevance of experimental reconstruction to digital humanities, highlighting the importance of: 1) old technologies to contemporary computing practices, 2) multimodal learning and applied methods to media history, 3) integrating museum collections into these methods, and 4) understanding sound as necessarily material, subject to techniques commonly found in, say, textual studies. These four points draw together domains all too often parsed: visual and sonic paradigms, critical thinking and critical making, media archaeology and digital humanities. 
Signal and Noise, Kari Kraus (15 minutes)

Twentieth-century recorded sound, like the first electric power system, originated in Thomas Edison’s Menlo Park laboratory shortly before the turn of the century (Hughes, Morton). In the decades that followed, sound technology and power transmission would continue to develop in tandem.  In this presentation we introduce an unexpectedly useful consequence of the historic entanglement of sound and electricity: the ability to code our past for time and place. A new collaboration at the University of Maryland aims to recover the date and time on which an historic recording was made based on analysis of incidentally captured traces of small variations in the electric power supply at the time of recording (Oard, et al; Su, et al). Although the field of audio forensics has used such Electric Network Frequency signatures to authenticate contemporary recordings for over a decade, our project seeks to extend the period for which baselines are available a further half century into the past. We do this by assembling recordings that were made at known times and comparing their ENF signatures with the signatures in recordings for which we lack such provenance information. 
After summarizing the results of our initial experiments, we focus on implications for archival practice, including retention of the original ENF signal across media formats (Figure 1), and conclude on a theoretical note: because ENF is traditionally dismissed as electronic noise by audio engineers and regarded as non-semantic in character, it poses an interesting challenge to the well-established archival concept of “significant properties.”

Fig. 2: Analog recordings that have undergone digital conversion and reformatting will often contain two or more ENF signatures: an original and a recaptured signature. The spectrogram in the image on the left shows the ENF trace from a 1962 magnetic tape recording of an oval office meeting during the Kennedy administration and a separate ENF trace embedded at the time of digitization. In the figure on the right, two signatures overlap. We have developed preliminary techniques for distinguishing these multiple traces.
Publication and performance, Whitney Trettien and Mary Caton Lingold (15 minutes)

Soundbox is a collaborative exercise in producing and publishing sonic scholarship. Its main research output is an edited digital collection bringing together a vanguard of emerging scholars and critical artists engaging in sonic scholarship, from exhibits and installations to digital essays, soundscapes, and speculative digital tools.
While the original goal of the project was to show, through example, the wide range of possibilities for an amplified digital humanities, the impossibility of publishing this work through standard scholarly venues – that is, those that facilitate the forms of peer review required for advancement in the profession – has become clear as the project proceeds. Because of concerns over long-term maintenance of digital scholarship, database-driven platforms like Omeka, Scalar, and Wordpress are quickly becoming the standard publishing format for digital work. Designed around arguments written in text and image, though, these platforms are largely inadequate to scholarship that integrates sound beyond the occasional linked audio clip. Thus the potential for amplified scholarly production opened up by, for instance, creative, small-scale, targeted uses of the HTML5 audio tag remains largely unrealizable within an increasingly calcified digital publishing infrastructure – a fact with ongoing consequences for what “counts” as digital humanities scholarship.
Using Soundbox’s experience as a case study, the speakers address the structural biases that continue to silence digital humanities. We argue for balancing the need for long-term maintenance and accessibility with a pluralistic approach that does not foreclose the possibilities of new forms and formats.
References

Attali, Jacques (1985). Noise: The Political Economy of Music.  Minneapolis: University of Minnesota Press.
Cavarero, Adriana (2005).For More Than One Voice: Toward a Philosophy of Vocal Expression.  Stanford, Calif: Stanford University Press. Print.
Dolar, Mladen (2006). A Voice and Nothing More. Cambridge, Mass: MIT Press.
Downie, J. S. , Tcheng, David K., and Xiang, Xin (2008). “Novel interface services for bioacoustic digital libraries” in Proc. 8th ACM/IEEE-CS Joint Conf. on Digital Libraries. New York: ACM, 2008: 423-423.
Fuller, Matthew. (2005). Media Ecologies: Materialist Energies in Art and Technoculture. Cambridge, Mass: MIT Press.  
Gitelman, Lisa. (2005) Always Already New: Media, History, and the Data of Culture. Cambridge, Mass: MIT Press.  
Hirschkind, Charles. (2006) The Ethical Soundscape: Cassette Sermons and Islamic Counterpublics.  New York: Columbia University Press.
High Performance Sound Technologies for Access and Scholarship project blogs.ischool.utexas.edu/hipstas/
Hughes, Thomas Parke. (1983) Networks of Power: Electrification in Western Society, 1880-1930. Baltimore: Johns Hopkins University Press. Print.
Josephson, Matthew (1992). Edison: A Biography. New York: J. Wiley. Print.
Kirschenbaum, Matthew (2008). Mechanisms: New Media and the Forensic Imagination. Cambridge, Mass: MIT Press.  
LaBelle, Brandon (2010). Acoustic Territories: Sound Culture and Everyday Life.  New York: Continuum.
Meintjes, Louise (2003. Sound of Africa!: Making Music Zulu in a South African Studio. Durham: Duke University Press.
Morton, David. (2004). Sound Recording: The Life Story of a Technology. Westport, CT: Greenwood Press. Print.
Moten, Fred (2003). In the Break: The Aesthetics of the Black Radical Tradition.  Minneapolis: University of Minnesota Press.
Oard, D., M. Wu, K. Kraus, A. Hajj-Ahmad, H. Su, R. Garg (2014). “It’s about Time: Projecting Temporal Metadata for Historically Significant Recordings.” Forthcoming, Proceedings of the 2014 iConference. Berlin, Germany. 4-7 March 2014. ACM Digital Library. Web.
Ochoa, Ana Maíra (2006). “Sonic Transculturation, Epistemologies of Purification and the Aural Public Sphere in Latin America.” Social Identities 12.6: 803-25.
Punyasena, Surangi W., Tcheng, David K., Wesseln, Cassandra, Mueller, Pietra G (2012). “Classifying black and white spruce pollen using layered machine learning.”New Phytologist 196.3: 937-944.
Rodgers, Tara (2010).Pink Noises: Women on Electronic Music and Sound.  Durham, NC: Duke University Press.
Smith, Mark M (2006). How Race Is Made: Slavery, Segregation, and the Senses.  Chapel Hill: University of North Carolina Press. Print
Smith, Mark M (2001). Listening to Nineteenth-Century America.  Chapel Hill: University of North Carolina Press. Print.
Sterne, Jonathan. The Audible Past: Cultural Origins of Sound Reproduction.  Durham, NC: Duke University Press, 2003.
Sterne, Jonathan. (2011) “Audio in Digital Humanities Authorship: A Roadmap.” (essay in progress) Super bon! Online:superbon.net/?p=1915. Accessed June 7, 2013.
Sterne, Jonathan (2012). MP3: The Meaning of a Format.  Durham: Duke University Press.
Su, H., Garg, R., Hajj-Ahmad, A., Min Wu (2013). “ENF Analysis on Recaptured Audio Recordings.” Proceedings of the 2013 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP). Vancouver, BC, Canada. 26-31 May 2013. 3018-3022. Web.
Thompson, Emily Ann (2002). The Soundscape of Modernity: Architectural Acoustics and the Culture of Listening in America, 1900-1933. Cambridge, Mass. : MIT Press.
Toop, David (2010). Sinister Resonance: The Mediumship of the Listener.  New York: Continuum.
Weheliye, Alexander G. (2005). Phonographies: Grooves in Sonic Afro-Modernity.  Durham, NC: Duke University Press.
For cultural histories of aurality, see entries for Smith 2001, 2006 in the bibliography; for sound reproduction, Sterne 2003, 2012; for the politics of the voice, Cavarero 2005, Dolar 2006; and noise, Attali 1984; for urban soundscapes, see entries for Toop 2010, Thompson 2002, Labelle 2010; ethnographic modernities and acoustemologies are covered in Hershkind 2006 and Ochoa 2006. The sonic construction of gender receives treatment in Rodgers 2010 and Martin 1991; for race and ethnicity, see Weheliye 2002, Moten 2003, Smith 2006, and Meintjes 2003.",txt,This text is republished here with permission from the original rights holder.,,archival research;forensics;machine learning;sound,English,"archives, repositories, sustainability and preservation;audio, video, multimedia;cultural studies;data mining / text mining;digital humanities - nature and significance;publishing and delivery systems;spatio-temporal modeling, analysis and visualisation;teaching and pedagogy;visualization"
1967,2014 - Lausanne,Lausanne,Digital Cultural Empowerment,2014-01-01T00:00:00Z,ADHO,ADHO,École Polytechnique Fédérale de Lausanne (EPFL);Université de Lausanne,Lausanne,,Switzerland,https://web.archive.org/web/20161227182033/https://dh2014.org/program/,"Integrating Score and Sound: ""Augmented Notes"" and the Advent of Interdisciplinary Publishing Frameworks",,Joanna Elizabeth Swafford,"paper, specified ""long paper""","1. Introduction
While sound studies is experiencing a resurgence in literary criticism, academic arguments involving sound are nearly impossible to make in traditional print media.  An article could include an excerpt of a score, but only scholars who can read music would be able to understand it.  Likewise, articles or books could include audio files externally, as did Nicholas Temperley’s special edition of Victorian Studies, which included a cassette tape with the songs discussed in the articles. 1  However, these solutions do not address the central problem:  readers will have difficulty finding the exact musical phrases mentioned in articles, and those with less musical expertise will be left out of the conversation entirely.  Newer options for incorporating music in academic articles include SoundCite (soundcite.knightlab.com), a tool that lets users embed sound clips in websites, Scalar (scalar.usc.edu/scalar), a publishing framework that lets users annotate media, and the strategy of assigning a QR code to each audio excerpt and inserting these into a print article, as Jennifer Wood suggests. 2  None of these options integrates the audio with the score:  SoundCite will only let users hear the audio, Scalar only supports textual annotations of media files, and QR codes require readers to have smart phones, which vastly limits the audience for the article.  To address these problems, I have built two tools:  ""Songs of the Victorians"" (www.songsofthevictorians.com), an archive and analysis of musical settings of Victorian poems with an interactive framework that highlights each measure of a score in time with its music, and ""Augmented Notes"" (www.augmentednotes.com), a public humanities tool that allows users who do not know how to program to build their own sites like ""Songs of the Victorians.""

2. Overview of ""Songs of the Victorians""
""Songs of the Victorians"" melds the archive and the scholarly article.  It examines both high- and low-brow Victorian settings of contemporaneous poetry by integrating scores, audio files, and scholarly analytical commentary in an interactive environment to help users understand both the literary and musical elements of the argument.  As an archive, it provides audio files of each song and archival-quality scans of first-edition printings of each score.  For every song, the user can listen to the audio while each measure of the score is highlighted in time with the music, as the archive page for William Balfe’s ""Come into the Garden Maud"" demonstrates (www.songsofthevictorians.com/balfe/archive.html).  The project also functions as a collection of scholarly articles in which each song includes an analysis of the song’s interpretation of the text.  When the commentary discusses a particular measure, the users can click on an icon of a speaker, which will play the relevant excerpt of the audio file and highlight the score so they can hear for themselves the effect the commentary describes, as in the analysis page for Caroline Norton's ""Juanita"" (www.songsofthevictorians.com/norton/analysis.html).


Fig. 1: Musical excerpt from the analysis page of Caroline Norton’s “Juanita”

""Songs of the Victorians"" includes Caroline Norton’s ""Juanita,"" Sir Arthur Sullivan’s setting of ""The Lost Chord,"" and two settings of Tennyson's Maud:  a parlor song by Michael William Balfe and an art song by Sir Arthur Somervell.  The site furthers scholarship for bibliographers, musicologists, Victorianists, and cultural studies scholars alike.  More generally, this new framework, which enables critics to describe musical arguments to non-musicians, facilitates this interdisciplinary approach of bringing music and literature together.  It also preserves the musical and cultural afterlives of well-known poems, as many of these scores have either disintegrated and been lost to time or are only available in select libraries.  ""Songs of the Victorians"" empowers users regardless of musical training:  those who cannot read music can overcome their feelings of intimidation at a musical score and can better understand the ideas described in the analysis, whereas those who can read music will still benefit, since few people can hear in their mind the music on the page.

3. Overview of ""Augmented Notes""
After the success of ""Songs of the Victorians,"" I used its framework to produce ""Augmented Notes"" (http://www.augmentednotes.com), a generalized, public humanities tool to allow anyone to develop similar websites.  ""Augmented Notes"" eliminates the need for users to understand programming by creating archive pages, like those from ""Songs of the Victorians,"" which users can tweak and redesign.  It is simple to use, as the site only requires audio files and images of the score to produce an archive page.  After the audio and image files are uploaded, users are taken to a page where they click and drag to draw boxes around each measure (they can also edit the sizes and order of these boxes), indicating what portion of the score should be highlighted when that measure plays.  


Fig. 2: Box-drawing page of “Augmented Notes”

Users can also optionally upload an MEI file--the TEI-based scholarly standard for music--for the score if they already have measure positions recorded in MEI. Users then set the times at which the highlighting box changes position through a ""time editing"" page.


Fig. 3: Time editing page of “Augmented Notes”

The site brings together the measure and time information, saving them in a JSON file, which enables each measure of the song to be highlighted in time with the music.  Users then click ""Download Zip"" to download a zip file with the HTML, CSS, and JavaScript files necessary for a complete archive page, which they can then restyle themselves.  

""Augmented Notes"" also has a sandbox (www.augmentednotes.com/example) through which users who would like to experiment with the technology but do not themselves have the requisite files can try it out.  ""Augmented Notes"" is already being used by scholars, both for archival purposes (such as the ""Performing Romantic Lyrics"" project from the University of South Carolina) and for pedagogical purposes such as generating interactive scores for use in music classrooms.  Since this tool produces websites with integrated audio and scores, it empowers users to preserve cultural archives, whether their materials include classical music, unpublished manuscripts, popular music, or folk music and traditional tunes from around the globe.

4. Implications
This presentation will discuss the projects in greater detail, complete with live demonstrations and an explanation of the underlying technology to show their digital as well as scholarly innovations.  I will explain the rationale for my choice of poems, settings, sound files, and editions for ""Songs of the Victorians,"" as well as my plans for future collaboration and expansion for both projects.  The presentation will illustrate the sorts of arguments that this framework can enable: for example, my examination of Sir Arthur Sullivan’s setting of Adelaide Procter’s ""A Lost Chord"" challenges the received interpretation that the poem merely describes a domestic, uncomplicated religious moment of transcendence.  Likewise, Caroline Norton’s ""Juanita"" has been considered a conventional song that preserves the traditional rules of courtship and parlor propriety, but my analysis of the music helps us see that it critiques the Victorian institution of marriage as imprisoning.  I will conclude by exploring the ways in which ""Songs of the Victorians"" is itself a Victorian endeavor, as it uses new technology to collect, analyze, and bring together Victorian music and poetry, thereby giving voice to the silent page.

5. Funding
This project was made possible by fellowships from NINES and the Scholars’ Lab.

References
1. Temperley, Nicholas (1986). Music in Victorian Society and Culture: A Special Issue of Victorian Studies. 30.1.

2. Wood, J. (2013). Noisy Texts: How to Embed Soundbytes in Your Writing. Burnable Books. Ed. Bruce Holsinger. burnablebooks.com/noisy-texts-how-to-embed-soundbytes-in-your-writing-a-guest-post/ (Accessed 30 October 2013).",txt,This text is republished here with permission from the original rights holder.,,archives;interdisciplinarity;music;poetry;tool building,English,"archives, repositories, sustainability and preservation;audio, video, multimedia;cultural studies;digital humanities - pedagogy and curriculum;english studies;gender studies;genre-specific studies: prose, poetry, drama;interdisciplinary collaboration;interface and user experience design;literary studies;music;programming;publishing and delivery systems;software design and development;xml"
2199,2015 - Sydney,Sydney,Global Digital Humanities,2015-01-01T00:00:00Z,ADHO,ADHO,Western Sydney University,Sydney,,Australia,https://web.archive.org/web/20190121165412/http://dh2015.org/,Challenges of an XML-based Open-Access Journal: Digital Humanities Quarterly,https://github.com/ADHO/dh2015/blob/master/xml/FLANDERS_Julia_Challenges_of_an_XML_based_Open_Access_J.xml,Julia Flanders;Wendell Piez;John A. Walsh;Melissa Terras,"paper, specified ""long paper""","<?xml version=""1.0"" encoding=""UTF-8""?>
<TEI xmlns=""http://www.tei-c.org/ns/1.0"">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title>Challenges of an XML-based Open-Access Journal: Digital Humanities Quarterly</title>
                <author>
                    <persName>
                        <surname>Flanders</surname>
                        <forename>Julia</forename>
                    </persName>
                    <affiliation>Northeastern University, United States of America</affiliation>
                    <email>j.flanders@neu.edu</email>
                </author>
                <author>
                    <persName>
                        <surname>Piez</surname>
                        <forename>Wendell</forename>
                    </persName>
                    <affiliation>Piez Consulting Services</affiliation>
                    <email>wapiez@wendellpiez.com</email>
                </author>
                <author>
                    <persName>
                        <surname>Walsh</surname>
                        <forename>John</forename>
                    </persName>
                    <affiliation>Indiana University</affiliation>
                    <email>jawalsh@indiana.edu</email>
                </author>
                <author>
                    <persName>
                        <surname>Terras</surname>
                        <forename>Melissa</forename>
                    </persName>
                    <affiliation>University College London</affiliation>
                    <email>m.terras@ucl.ac.uk</email>
                </author>
            </titleStmt>
            <editionStmt>
                <edition>
                    <date>2014-12-19T13:50:00Z</date>
                </edition>
            </editionStmt>
            <publicationStmt>
                <publisher>Paul Arthur, University of Western Sidney</publisher>
                <address>
                    <addrLine>Locked Bag 1797</addrLine>
                    <addrLine>Penrith NSW 2751</addrLine>
                    <addrLine>Australia</addrLine>
                    <addrLine>Paul Arthur</addrLine>
                </address>
            </publicationStmt>
            <sourceDesc>
                <p>Converted from a Word document </p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <appInfo>
                <application ident=""DHCONVALIDATOR"" version=""1.9"">
                    <label>DHConvalidator</label>
                </application>
            </appInfo>
        </encodingDesc>
        <profileDesc>
            <textClass>
                <keywords scheme=""ConfTool"" n=""category"">
                    <term>Paper</term>
                </keywords>
                <keywords scheme=""ConfTool"" n=""subcategory"">
                    <term>Long Paper</term>
                </keywords>
                <keywords scheme=""ConfTool"" n=""keywords"">
                    <term>open access</term>
                    <term>digital publishing</term>
                    <term>XML</term>
                    <term>TEI</term>
                </keywords>
                <keywords scheme=""ConfTool"" n=""topics"">
                    <term>project design</term>
                    <term>organization</term>
                    <term>management</term>
                    <term>publishing and delivery systems</term>
                    <term>xml</term>
                    <term>copyright</term>
                    <term>licensing</term>
                    <term>and Open Access</term>
                    <term>standards and interoperability</term>
                    <term>English</term>
                </keywords>
            </textClass>
        </profileDesc>
    </teiHeader>
    <text>
        <body>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Background and Technical Infrastructure</head>
                <p>
                    <hi rend=""italic"">DHQ</hi>’s technical design was constrained by a set of higher-level goals and needs. As an early open-access journal of digital humanities, the journal had an opportunity to participate in the curation of an important segment of the scholarly record in the field. This meant that it was more than usually important that the article data be stored and curated in a manner that would maximize the potential for future reuse. In addition to mandating the use of open standards, this aim also strongly indicated that the data should be represented in a semantically rich format. Of equal concern was the need for flexibility and the ability to experiment with both the underlying data and the publication interface, throughout the life of the journal, without constraint from the publication system. Both of these considerations moved the journal in the direction of XML, which would give us the ability to represent any semantic features of the journal articles we might find necessary for either formatting or subsequent research. It would also permit us to design a journal publication system, using open-source components, that could be closely adapted to the 
                    <hi rend=""italic"">DHQ</hi> data. At the journal’s founding, several alternative publishing platforms were proposed (including the Open Journal System), but none were XML-based and none offered the opportunity for open-ended experimentation that we needed.
                </p>
                <p>
                    <hi rend=""italic"">DHQ</hi>’s technical infrastructure is a standard XML publishing pipeline built using components that are familiar in the digital humanities. Submissions are received and managed through OJS through the copyediting stage, at which point articles are converted to basic TEI using OxGarage (http://www.tei-c.org/oxgarage/). Further encoding and metadata are added by hand, and items from the articles’ bibliographies are entered into a centralized bibliographic system that is also XML-based. All journal content is maintained under version control using Subversion. The journal’s organizational information concerning volumes, issues, and tables of contents is represented in XML using a locally defined schema. The journal uses Cocoon, an XML/XSLT pipelining tool, to process the XML components and generate the user interface. 
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>
                    <hi rend=""italic"">DHQ</hi>’s Evolving Data and Interface
                </head>
                <p>As noted above, 
                    <hi rend=""italic"">DHQ</hi>’s approach to the representation of its article data has from the start been shaped by an emphasis on long-term data curation and a desire to accommodate experimentation. The specific encoding practices have evolved significantly during the journal’s lifetime. The first schema developed for the journal was deliberately homegrown and was designed based on an initial informal survey of article submissions and articles published in other venues. Following this initial period of experimentation and bottom-up schema development, once the schema had settled into a somewhat stable form we expressed it as a TEI customization and did retrospective conversion on the existing data to bring it into conformance with the new schema. At several subsequent points, significant new features have been added to the journal’s encoding: for example, explicit representation of revision sites within articles (for authorial changes that go beyond simple correction of typographical errors), enhancements to the display of images through a gallery feature, and adaptation of the encoding of bibliographic data to a centralized bibliographic management system.
                </p>
                <p>These changes to the data have typically been driven by emerging functional requirements, such as the need to show where an article has been revised or the requirements of the special issue on comics as scholarship. However, they also respond to a broader set of requirements that this data should represent the intellectual contours of scholarship rather than simply interface. For example, the encoding of revision notes retains the text of the original version, identifies the site of the revision, and supports an explanatory note by the author describing the reason for the revision. Although 
                    <hi rend=""italic"">DHQ</hi>’s current display uses this data in a simple manner to permit the reader to read the original or revised version, the data would support more advanced study of revision across the journal. Similarly, although our current display uses the encoding of quoted material and accompanying citations in very straightforward ways, the same data could readily be used to generate a visualization showing most commonly quoted passages, quotations that commonly occur in the same articles, and similar analyses of the research discourse. The underlying data and architecture lend themselves to incremental expansion.
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Analysis</head>
                <p>The approach 
                    <hi rend=""italic"">DHQ</hi> has taken offers several significant advantages and also some corresponding disadvantages. The most important advantages are
                </p>
                <p rend=""List Paragraph""> • The autonomy the journal has to control all aspects of its own data modeling and interface.</p>
                <p rend=""List Paragraph""> • The high value of the resulting data, from a historiographic perspective.</p>
                <p rend=""List Paragraph""> • The ease of long-term curation of the data, including continuing evolution of our modeling decisions.</p>
                <p rend=""List Paragraph""> • The ease of long-term evolution of the publication infrastructure, including migration to other XML-based systems as needed.</p>
                <p rend=""List Paragraph""> • The scalability of a template-based infrastructure: with the system in place, each article requires no incremental work in styling or design; all effort goes towards consistent representation of semantically valued features.</p>
                <p>These advantages all carry a burden of cost and effort: autonomy and control necessarily entail responsibility for maintaining appropriate levels of expertise and undertaking the labor necessary to build and revise technical systems. Because our article work flow includes some hand encoding in TEI, our managing editors need to be better trained and more expert than if they were simply formatting articles in Word and exporting PDF. However, there are also some less obvious tradeoffs. 
                    <hi rend=""italic"">DHQ</hi>’s publication model gains its efficiencies and scalability through an emphasis on uniform handling of repeated features, but this means that it is comparatively difficult to accommodate individual authorial requests for special handling. These entail not only extra effort at the time of publication but also the long-term prospect of special attention during the future data curation activities and updates to the interface and publication system. Authors familiar with content management systems such as WordPress or Scalar are accustomed to being able to exercise a significant level of control over the formatting and behavior of their text and accompanying media such as images and video. Long-term data curation is a less visible feature of such publishing systems. 
                </p>
                <p>Even more interesting and challenging are the special cases that entail semantically distinctive features. Although such submissions are rare, they have provided some valuable test cases in which the data being represented is not a straightforward ‘article’ but some other rhetorical mode: commented program code, dynamic HTML that provokes reader interaction, an article in the form of a comic book. In handling these cases, 
                    <hi rend=""italic"">DHQ</hi> has sought to find ways to accommodate the distinctive form of the original piece while also giving it a proxy presence within the standard 
                    <hi rend=""italic"">DHQ</hi> XML archive, so that its content can be searched and analyzed as part of the larger 
                    <hi rend=""italic"">DHQ</hi> corpus of DH scholarship. As these cases accumulate, the editors seek to identify repeated needs that could become part of the regular 
                    <hi rend=""italic"">DHQ</hi> feature set. 
                </p>
                <p>In the full version of this paper, we will consider in greater detail the role of authorial design in digital humanities publication, and the possible convergences between XML-based systems like 
                    <hi rend=""italic"">DHQ</hi> and content-management based systems like Scalar.
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Future Directions</head>
                <p>
                    <hi rend=""italic"">DHQ</hi> is now completing a multiyear project to centralize its bibliography, and the next step will be to develop interface features that exploit this data. We are also in the planning stages of a project to explore internationalization of the journal through a series of special issues dedicated to individual languages. In both cases, these amplifications of the journal represent natural extensions of the journal’s existing architecture, and although both are substantial projects, they are made feasible by the investment already made in strongly modeled data and an extensible publication infrastructure. In the fuller version of this paper, we will discuss both of these developments in greater detail.
                </p>
            </div>
        </body>
    </text>
</TEI>",xml,Creative Commons Attribution 4.0 International,,digital publishing;open access;tei;xml,English,"copyright, licensing, and open access;english;project design, organization, management;publishing and delivery systems;standards and interoperability;xml"
2271,2015 - Sydney,Sydney,Global Digital Humanities,2015-01-01T00:00:00Z,ADHO,ADHO,Western Sydney University,Sydney,,Australia,https://web.archive.org/web/20190121165412/http://dh2015.org/,Hypergraph Based Collaborative Film Archive,https://github.com/ADHO/dh2015/blob/master/xml/BIDDALA_Sandeep_Reddy_Hypergraph_Based_Collaborative_Fi.xml,Sandeep Reddy Biddala;Navjyoti Singh,"paper, specified ""long paper""","<?xml version=""1.0"" encoding=""UTF-8""?>
<TEI xmlns=""http://www.tei-c.org/ns/1.0"">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title>Hypergraph Based Collaborative Film Archive</title>
                <author>
                    <persName>
                        <surname>Biddala</surname>
                        <forename>Sandeep Reddy</forename>
                    </persName>
                    <affiliation>International Institute of Information Technology, Hyderabad (IIIT-H), India</affiliation>
                    <email>biddala.sandeepreddy@gmail.com</email>
                </author>
                <author>
                    <persName>
                        <surname>Singh</surname>
                        <forename>Navjyoti</forename>
                    </persName>
                    <affiliation>International Institute of Information Technology, Hyderabad (IIIT-H), India</affiliation>
                    <email>navjyoti@iiit.ac.in</email>
                </author>
            </titleStmt>
            <editionStmt>
                <edition>
                    <date>2014-12-19T13:50:00Z</date>
                </edition>
            </editionStmt>
            <publicationStmt>
                <publisher>Paul Arthur, University of Western Sidney</publisher>
                <address>
                    <addrLine>Locked Bag 1797</addrLine>
                    <addrLine>Penrith NSW 2751</addrLine>
                    <addrLine>Australia</addrLine>
                    <addrLine>Paul Arthur</addrLine>
                </address>
            </publicationStmt>
            <sourceDesc>
                <p>Converted from a Word document </p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <appInfo>
                <application ident=""DHCONVALIDATOR"" version=""1.9"">
                    <label>DHConvalidator</label>
                </application>
            </appInfo>
        </encodingDesc>
        <profileDesc>
            <textClass>
                <keywords scheme=""ConfTool"" n=""category"">
                    <term>Paper</term>
                </keywords>
                <keywords scheme=""ConfTool"" n=""subcategory"">
                    <term>Long Paper</term>
                </keywords>
                <keywords scheme=""ConfTool"" n=""keywords"">
                    <term>CinemaScope</term>
                    <term>Hypergraph</term>
                    <term>Cinema</term>
                    <term>Data Model</term>
                    <term>Annotation.</term>
                </keywords>
                <keywords scheme=""ConfTool"" n=""topics"">
                    <term>archives</term>
                    <term>repositories</term>
                    <term>sustainability and preservation</term>
                    <term>audio</term>
                    <term>video</term>
                    <term>multimedia</term>
                    <term>film and cinema studies</term>
                    <term>metadata</term>
                    <term>data modeling and architecture including hypothesis-driven modeling</term>
                    <term>ontologies</term>
                    <term>knowledge representation</term>
                    <term>crowdsourcing</term>
                    <term>English</term>
                </keywords>
            </textClass>
        </profileDesc>
    </teiHeader>
    <text>
        <body>
            <p>Digital film archives in addition to preserving cinema should also accommodate and provide for the computation of its cinemas by means of the metadata provided to represent the content in them. The provision for the computation of cinema could lead to various applications like semantic search, automatic genre clustering and classification, special visualization tools, and robust comparisons of movies.</p>
            <p>This paper describes a data model for storing the metadata of a film in an archive based on a discrete theory of cinema that has been in development for the past four years based on Indic theories and other theories of drama and film (Muni, 1996). This theory reduces cinema to a hypergraph composed of tags that assume its full form only with collaborative tagging and extensive visual and textual computing. A system called CinemaScope is also being developed based on this data model which uses HypergraphDB as its database and is being designed and developed to be a semiautomated annotation database system.</p>
            <p>
                <anchor xml:id=""h.6pngm6hadp9c""/>Overview of Theory
            </p>
            <p>Cinema is ontologically a three-tier structure:</p>
            <p> 1. Spatio-temporal flow controlled play of light and sound.</p>
            <p> 2. Mere-temporal ‘flow’, which is visually created by a play of 25 fps.</p>
            <p> 3. Trans-temporal content, which is embedded in a ‘flow’.</p>
            <p>Cinema concludes in a thematic unity. Unit of a discrete contiguum of cinema is punctuation. Idea of punctuation is inspired by Leibnizian distinction between ideal point and actual point on the one hand and continuum and discrete contiguum on the other (Leibniz, 2013). Punctuation is a form of an actual point that tells apart two recognizable and non-identical discernible contents. It has a structure &lt;entity1|entity2, relational context&gt; or graphically &lt;node1|node2, edge&gt;. </p>
            <p>There are three classes of punctuations based on the three tiers of ontology of cinema:</p>
            <p> 1. Temporal punctuation. </p>
            <p> 2. Vectorial punctuations between embedded content.</p>
            <p> 3. Mereological punctuations between vectorial contents and the thematic conclusion of cinema.</p>
            <p>This way the form of punctuation constitutes discrete contiguum of cinema, which is computationally reducible to a giant graph that tells truth about cinema as art. </p>
            <p>Ontologically there are categories of discrete content that are embedded in punctuated units of flow like shot and episodes. Some of the categories form the content part of the cinematic narrative (like locale, characters, events, and actions) while the rest (camera work, editing, re-recording) form the expressive part of it (Chatman, 1978). Forces operative on these entities as vector punctuations create kinetics of cinema toward thematic conclusion. The motion in films is through the movement of story or plot from the beginning to the conclusion. Such a motion towards theme is punctuated by points of events and points of considerations. It is through the sequence of events that connection to the theme is established. These events are punctuated with points of considerations. Story can be rendered as sequence of the points of events, and under each event there are several considerations (Dhananjaya, 2004). There are scalars between the sequences of cinema that are merely informative and do not account for the motion of the plot.</p>
            <p>
                <anchor xml:id=""h.jm7whto785mz""/>Overview of Data Model
            </p>
            <p>In Hochin (2006) and Hochin and Tatsuo (2000), a data model called Directed Recursive Hypergraph Data Model (DRHM) has been described in which the content of multimedia is reduced to nodes and edges of a hypergraph. In Radev et al. (1999a; 199b), the structural and behavioral aspects of data that form multimedia information systems have been modelled as a graph-based object-oriented model, and a possible data model for film is shown. These approaches suggest that a graph-based data model for cinema based on the discrete theory of cinema proposed in the previous section would best represent it. Punctuation or point &lt;node | node, edge&gt; can be seen as triple of tags. This will make possible computing of the discrete contiguum of cinema as a graph. Also there are complex relations between the various entities of cinema which is best represented by hyperedges.</p>
            <p>The graph data model should accommodate the various ontological entities and their punctuations, the mereological punctuations as well as the vectors between episodes and the considerations between events. The partial data model for the cinematic hypergraph described is represented in the form of Venn diagram as shown in Figure 1.</p>
            <figure>
                <graphic n=""1001"" width=""9.246305555555555cm"" height=""7.186083333333333cm"" url=""Pictures/image1.jpg"" rend=""block""/>
            </figure>
            <p>Figure 1. Venn diagram of cinematic hypergraph—data model.</p>
            <p>Architecture of CinemaScope</p>
            <p>The architecture of the tagging system we propose for CinemaScope is a web-based collaborative one. The annotation schema for the hypergraph data model in theory captures the whole graph. But in practice manual tagging, which is required for the annotating the themes, considerations, meanings, and vectors of cinema, reveals only a sub graph of the original graph. This is because the graph also contains codes and conventions (which are many times dependent on the individual viewer’s perspective) that regulate the narratives and enrich their pure meaning. It is therefore essential that the tagging of the cinema be made social so that most of the graph is captured. The high-level architecture of CinemaScope is given in Figure 2.</p>
            <p>
                <graphic n=""1002"" width=""13.62075cm"" height=""10.304638888888888cm"" url=""Pictures/image2.jpg"" rend=""inline""/>.
            </p>
            <p>Figure 2. Basic architecture of CinemaScope.</p>
            <p>Methodology of CinemaScope</p>
            <p>The database for the system is built on both relational database and graph database (HyperGraphDB). The relational database is used to store all the direct information about the cinema, like its cast, basic plot structure, related files (like script and subtitles), and other relevant information. The graph database is used to graph the tags which have a graphical relation between them. HypergraphDB is a graph-based as well as an object-oriented database with a Java-based API that allows objective modelling of all categories of tags. For example, ontological categories are modelled as follows:</p>
            <p>
                <hi rend=""color(000088)"">public class</hi>
                <hi rend=""color(660066)"">OntologicalEntity{</hi>
            </p>
            <p>
                <hi rend=""color(000088)"">private</hi>
                <hi rend=""color(660066)"">String</hi> entityName
                <hi rend=""color(666600)"">;</hi>
                <hi rend=""color(880000)"">//Entity Name</hi>
            </p>
            <p>
                <hi rend=""color(000088)"">private</hi>
                <hi rend=""color(660066)"">Map</hi>
                <hi rend=""color(666600)"">&lt;</hi>
                <hi rend=""color(660066)"">String</hi>
                <hi rend=""color(666600)"">,</hi>
                <hi rend=""color(660066)"">Object</hi>
                <hi rend=""color(666600)"">&gt;</hi>attributesNameAndType 
                <hi rend=""color(666600)"">=</hi>
                <hi rend=""color(000088)"">new</hi>
                <hi rend=""color(660066)"">HashMap</hi>
                <hi rend=""color(666600)"">&lt;</hi>
                <hi rend=""color(660066)"">String</hi>
                <hi rend=""color(666600)"">,</hi>
                <hi rend=""color(660066)"">Object</hi>
                <hi rend=""color(666600)"">&gt;();</hi>
                <hi rend=""color(880000)"">//Contains the attributes with their names and values</hi>
            </p>
            <p>
                <hi rend=""color(000088)"">public void</hi> setEntityName
                <hi rend=""color(666600)"">(</hi>
                <hi rend=""color(660066)"">String</hi> entityName
                <hi rend=""color(666600)"">){</hi>
            </p>
            <p>//Setting The entity Name</p>
            <p>}</p>
            <p>
                <hi rend=""color(000088)"">public</hi>
                <hi rend=""color(660066)"">String</hi> getEntityName
                <hi rend=""color(666600)"">(){</hi>
            </p>
            <p>
                <hi rend=""color(000088)"">return</hi> entityName;
            </p>
            <p>}</p>
            <p>
                <hi rend=""color(000088)"">public</hi>
                <hi rend=""color(660066)"">Object</hi> getAttributeValue
                <hi rend=""color(666600)"">(</hi>
                <hi rend=""color(660066)"">String</hi> attribute
                <hi rend=""color(666600)"">){</hi>
            </p>
            <p>
                <hi rend=""color(000088)"">return</hi> attributesNameAndType
                <hi rend=""color(666600)"">.</hi>
                <hi rend=""color(000088)"">get</hi>
                <hi rend=""color(666600)"">(</hi>attribute
                <hi rend=""color(666600)"">);</hi>
            </p>
            <p>}</p>
            <p>
                <hi rend=""color(000088)"">public void</hi> fillAttribute
                <hi rend=""color(666600)"">(</hi>
                <hi rend=""color(660066)"">String</hi> value
                <hi rend=""color(666600)"">){</hi>
            </p>
            <p>/*Code for filling the attributes*/</p>
            <p>}</p>
            <p>}</p>
            <p>The pre-processing stage involves identification of shots, episodes, and the tagging of basic ontological entities. The pre-processing step cannot be completely automated owing to the limitations of current vision and audio processing algorithms. But this stage of the annotation can be aided with a number of supporting files and techniques. For example, movie screenplays and subtitles that are freely available on the Internet help in giving hints of annotation to the user. Even the processes that are completely automated require manual intervention and editing. There are various shot transition detection methods (Boreczky and Rowe, 1996) along with techniques for identification of camera properties like depth, movement, and angle (Benini et al., 2010). The camera properties identified are dependent on the definitions used in the methods, and they are not completely accurate. The tagging system should provide options for manually editing and supervising the shots and camera properties.</p>
            <p>Film scripts and subtitles aid in the tagging of ontological entities by supplying hints. The script is first aligned with the subtitles for time stamps based on the work of Ronfard and Theung (2003). A basic version of this has been implemented based on the work of Larissa Munishkina et al. (2013). An example hint given by the system for the film 
                <hi rend=""italic"">Indiana Jones and the Raiders of the Lost Ark</hi> is as follows:
            </p>
            <p>E.g. Scene #1 (0:00–2:15)</p>
            <p> Characters: Indiana Jones, Baranaca</p>
            <p> Locale: High Jungle, Peru</p>
            <p> Things: Gun, Idol</p>
            <p> Events: Shooting, Running</p>
            <p>The Collaborative or Social tagging follows the pre-processing step, and it helps in the creation of tags and links in cinema. The user is given the provision of defining the relations, which is made possible by the use of HyperGraphDB. Hertzum et al. (2002) suggests that collaboration of film archives should facilitate different archives in identifying a common ground on which to base a collaborator and in acknowledging the distinctiveness of each archive. The architecture of CinemaScope allows identifying a common ground, in terms of pre-processing tags as well as distinctiveness, by allowing the users of different background to provide interpretations and considerations of the story in terms of vectors, relations, and links (each with a different label).</p>
            <p>The various relations added by the user and the tags obtained from the pre-processing stage build up the graph, which could later be used for various applications like searching. For example, the following code snippet answers semantic queries like ‘Find all the camera properties used when character is holding the whip’:</p>
            <p>
                <hi rend=""color(660066)"">HyperGraph</hi> graph 
                <hi rend=""color(666600)"">=</hi>
                <hi rend=""color(000088)"">new</hi>
                <hi rend=""color(660066)"">HyperGraph</hi>
                <hi rend=""color(666600)"">(</hi>
                <hi rend=""color(660066)"">HyperGraphLocation</hi>
                <hi rend=""color(666600)"">);</hi>
            </p>
            <p>
                <hi rend=""color(660066)"">List</hi>
                <hi rend=""color(666600)"">&lt;</hi>
                <hi rend=""color(660066)"">CameraTemporalRelations</hi>
                <hi rend=""color(666600)"">&gt;</hi> cameras 
                <hi rend=""color(666600)"">=</hi> hg
                <hi rend=""color(666600)"">.</hi>getAll
                <hi rend=""color(666600)"">(</hi>hg
                <hi rend=""color(666600)"">.</hi>type
                <hi rend=""color(666600)"">(</hi>
                <hi rend=""color(660066)"">CameraTemporalRelations</hi>
                <hi rend=""color(666600)"">));</hi>
            </p>
            <p>
                <hi rend=""color(660066)"">List</hi>
                <hi rend=""color(666600)"">&lt;</hi>
                <hi rend=""color(660066)"">CharacterThingTemporalRelations</hi>
                <hi rend=""color(666600)"">&gt;</hi> CTR 
                <hi rend=""color(666600)"">=</hi> hg
                <hi rend=""color(666600)"">.</hi>getAll
                <hi rend=""color(666600)"">(</hi>hg
                <hi rend=""color(666600)"">.</hi>
                <hi rend=""color(000088)"">and</hi>
                <hi rend=""color(666600)"">(</hi>hg
                <hi rend=""color(666600)"">.</hi>type
                <hi rend=""color(666600)"">(</hi>
                <hi rend=""color(660066)"">CharacterThingTemporalRelations</hi>
                <hi rend=""color(666600)"">.</hi>
                <hi rend=""color(000088)"">class</hi>
                <hi rend=""color(666600)"">),</hi> hg
                <hi rend=""color(666600)"">.</hi>eq
                <hi rend=""color(666600)"">(</hi>
                <hi rend=""color(008800)"">""spatial_relation""</hi>
                <hi rend=""color(666600)"">,</hi>
                <hi rend=""color(008800)"">""hold""</hi>
                <hi rend=""color(666600)"">),</hi> hg
                <hi rend=""color(666600)"">.</hi>eq
                <hi rend=""color(666600)"">(</hi>
                <hi rend=""color(008800)"">""thing_name""</hi>
                <hi rend=""color(666600)"">,</hi>
                <hi rend=""color(008800)"">""whip""</hi>
                <hi rend=""color(666600)"">)));</hi>
            </p>
            <p>
                <anchor xml:id=""h.u2e32glmo8qr""/>Summary
            </p>
            <p>The paper describes the discrete theory of cinema and explains the hypergraph data model of cinema. The paper also describes CinemaScope, a semi-automated web-based collaborative film archive based on the hypergraph data model for annotating the film. This project is different from other movie annotation projects (ANSWER, 2009; Jewell et al., 2005); Lombardo and Damiano, 2010), which fail to capture the flow of cinema and make the computational representation of cinema in a database very descriptive and computationally infeasible.</p>
            <figure>
                <graphic n=""1003"" width=""16.51cm"" height=""9.278055555555556cm"" url=""Pictures/image3.png"" rend=""block""/>
            </figure>
            <p>Figure 3. Prototype of CinemaScope annotation system.</p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend=""bold"">ANSWER Annual Report.</hi> (2009). http://cordis.europa.eu/fp7/ict/content-knowledge/docs/answer-annual-report-2009.pdf.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Benini, S., Canini, L. and Leonardi, R.</hi> (2010). Estimating Cinematographic Scene Depth in Movie Shots. Multimedia and Expo (ICME), 2010 IEEE International Conference.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Boreczky, J. S. and Rowe, L. A.</hi> (1996). Comparison of Video Shot Boundary Detection. 
                        <hi rend=""italic"">Journal of Electronic Imaging,</hi>
                        <hi rend=""bold"">5</hi>(2) (April): 122–28.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Chatman, S.</hi> (1978). 
                        <hi rend=""italic"">Story and Discourse: Narrative Structure in Fiction and Film</hi>. Cornell University Press, Ithaca, NY.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Dhananjaya.</hi> (1100). Dasarupaka, Dr. Keshavrao Musalgaunkar. Hindi Dasarupaka, 2004.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Hertzum, M., Pejtersen, A. M., Cleal, B. and Albrechtsen, H.</hi> (2002). An Analysis of Collaboration in Three Film Archives: A Case for Collaboratories. 
                        <hi rend=""italic"">CoLIS4: Proceedings of the Fourth International Conference on Conceptions of Library and Information Science.</hi> Libraries Unlimited, pp. 69–83.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Hochin, T.</hi> (2006). Graph-Based Data Model for the Content Representation of Multimedia Data. Knowledge-Based Intelligent Information and Engineering Systems. 
                        <hi rend=""italic"">Lecture Notes in Computer Science,</hi>
                        <hi rend=""bold"">4252</hi> (1182–90).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Hochin, T. and Tatsuo T.</hi> (2000). A Directed Recursive Hypergraph Data Model for Representing the Contents of Multimedia Data. 
                        <hi rend=""italic"">Memoirs of the Faculty of Engineering, Fukui University, </hi>
                        <hi rend=""bold"">48</hi>: 343–60.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Jewell, M., Lawrence, K., Tuffield, M., Prugel-Bennett, A., Millard, D., Nixon, M. and Shadbolt, N.</hi> (2005). OntoMedia: An Ontology for the Representation of Heterogeneous Media. 
                        <hi rend=""italic"">Proceedings of SIGIR Workshop on Multimedia Information Retrieval.</hi> ACM.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Leibniz, G. W.</hi> (2013). 
                        <hi rend=""italic"">The Labyrinth of the Continuum: Writings on the Continuum Problem 1672–1686</hi>. Translated, edited, and with an introduction by Richard T. W. Arthur. Yale University Press, New Haven, CT.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Lombardo, V. and Damiano, R.</hi> (2010). Narrative Annotation and Editing of Video. Interactive Storytelling. 
                        <hi rend=""italic"">Lecture Notes in Computer Science,</hi>
                        <hi rend=""bold"">6432</hi>, 62–73.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Muni, B.</hi> (1996 [300 BC]). 
                        <hi rend=""italic"">Nāṭya śāstra</hi>. With Abhinavagupta’s Commentary; with Hindi Commentary by Dwivedi Parasnath. Sampurnanand Sanskrit Mahavidyalaya, Varanasi.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Munishkina, L., Parrish, J. and Walker, M. A.</hi> (2013). Fully Automatic Interactive Story Design from Film Scripts. Interactive Storytelling. 
                        <hi rend=""italic"">Lecture Notes in Computer Science,</hi>
                        <hi rend=""bold"">8230</hi>: 229–32.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Radev, I., Pissinou, N. and Makki, K.</hi> (1999a). Film Video Modeling. 
                        <hi rend=""italic"">Proceedings of IEEE Workshop on Knowledge and Data Engineering Exchange, KDEX 99</hi>, Chicago, IL, November 1999.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Radev, I., Pissinou, N., Makki, K. and Park, E. K. </hi>(1999b). Graph-Based Object-Oriented Approach for Structural and Behavioral Representation of Multimedia Data. 
                        <hi rend=""italic"">Proceedings of the Eighth International Conference on Information and Knowledge Management</hi>, Kansas City, MO, 2–6 November 1999, pp. 522–30.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Ronfard, R. and Thuong, T. T.</hi> (2003). A Framework for Aligning and Indexing Movies with Their Script. 
                        <hi rend=""italic"">Proceedings of ICME</hi>, Baltimore, MD, 6–9 July 2003.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>
</TEI>",xml,Creative Commons Attribution 4.0 International,,annotation;cinema;cinemascope;data model;hypergraph,English,"archives, repositories, sustainability and preservation;audio, video, multimedia;crowdsourcing;data modeling and architecture including hypothesis-driven modeling;english;film and cinema studies;knowledge representation;metadata;ontologies"
2422,2016 - Kraków,Kraków,Digital Identities: the Past and the Future,2016-01-01T00:00:00Z,ADHO,ADHO,Jagiellonian University;Pedagogical University of Krakow,Kraków,,Poland,https://dh2016.adho.org/,Boutique Big Data: Reintegrating Close and Distant Reading of 19th-Century Newspapers,,M. H. Beals,poster / demo / art installation,"<text xmlns=""http://www.tei-c.org/ns/1.0"">
        <body>
            <p>From their earliest incarnations in the seventeenth-century, through their Georgian expansion into provincial and colonial markets and culminating in their late-Victorian transformation into New Journalism, British newspapers have relied upon scissors-and-paste journalism to meet consumer demands for the latest political intelligence and diverting content. Although this practice, wherein one newspaper extracted or wholly duplicated content from another, is well known to scholars of the periodical press, in-depth analysis of the process is hindered by the lack of formal records relating to the reprinting process. Although anecdotes abound, attributions were rarely and inconsistently given and, with no legal requirement to recompense the original author, formal records of where material was obtained were unnecessary. Even if they had existed, the number of titles that relied upon reprinted material makes systematic analysis impossible; for many periodicals, only a few issues, let alone business records, survive. However, mass digitisation of these periodicals, in both photographic and machine-readable form, offers historians a new opportunity to rediscover the mechanics of nineteenth-century reprinting. By undertaking multi-modal and multi-scalar analyses of digitised periodicals, we can begin to reconstruct the precise journeys these texts took from their first appearance to their multiple ends. </p>
            <p>Before the advent of the telegraph, individual texts were disseminated manually, through postal and private correspondence routes, over sea and land. This allowed for the relatively slow spread of texts across communication networks, as well their adaptation, truncation and expansion various stages. In a manner similar to modern internet memes, blogs and online news content, texts underwent evolutionary changes with each reprinting. These could be minute, such as the correction of spelling errors or the application of house style, or significant, through selective reordering and truncation to alter the overall meaning of the text. While identifying meme families, or collections of related texts, can help us understand what made particularly texts popular, or viral, it is only by tracing the specific trajectories and pathways of these texts that the causes and consequences of evolutionary changes can be understood. </p>
            <p>Doing so requires us to approach these texts on multiple scales. First, by mining extremely large corpora, derived from several independent collections, we are able to identify a statistically sufficient portion of the historical network. Then, by carefully analysing the chronology and discrepancies between these reprints, hypotheses regarding institutional and industry standards can be posited and tested against the wider corpus. These efforts can be further buttressed by utilising manual transcriptions found in the personal archives of researchers using historical newspapers, such as the Scissors and Paste Database (www.scissorsandpaste.net). These transcriptions, far more accurate than the majority of datasets derived from optical character recognition, greatly improve the mining of the corpora, yielding a more complete initial network to analyse, as well as offset the skewing effect of the ‘offline penumbra’.</p>
            <p>This poster will explore the possibilities of large-scale reprint identification within and across digitised collections using a combination of Lou Bloomfield’s 
                <hi rend=""italic"">Copyfind</hi> and project-specific code to identify matches between individual articles or full pages of texts in both manual (perfect) and OCR (messy) transcriptions. Exemplar collections include the British Library's 19th-Century Newspapers digital collection and planned expansions into the digital collections of the National Library of Wales (Welsh Newspaper Online) and of Australia (Trove). The poster will also demonstrate the means by which reprint branching can be mapped using chronology and character clustering and the relative precision of manual and computer-aided techniques. Finally, it will explore the nature of multi-scalar analysis and how we might best reintegrate ‘boutique’ periodical research, such as the author’s 
                <hi rend=""italic"">Scissors and Paste Database</hi>, into large-scale text-mining projects.
            </p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl><hi rend=""bold"">Adamic, L. A., Lento, T. M., Adar, E. and Ng, P. C.</hi> (2016). Information Evolution in Social Networks,<hi rend=""italic"">Proceedings of the Ninth ACM International Conference on Web Search and Data Mining - WSDM ’16</hi>, doi: 10.1145/2835776.2835827.
                    </bibl>
                    <bibl><hi rend=""bold"">Beals, M. H.</hi> (forthcoming). The Role of the Sydney Gazette in Scottish Perceptions of Australia, 1803-1842. In Hinks, J. and Feeley, C. (eds.) 
                        <hi rend=""italic"">Historical Networks in the Book Trade</hi>. London: Routledge.
                    </bibl>
                    <bibl><hi rend=""bold"">Smith, D. A., Cordell, R. and Mullen, A.</hi> (2015). Computational methods for uncovering reprinted texts in antebellum newspapers, 
                        <hi rend=""italic"">American Literary History</hi>, <hi rend=""bold"">27</hi>(3): 1–15. doi: 10.1093/alh/ajv029.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>
",xml,This text is republished here with permission from the original rights holder.,,history;networks;newspapers;reprinting,English,"authorship attribution / authority;corpora and corpus activities;data mining / text mining;historical studies;media studies;networks, relationships, graphs"
2538,2016 - Kraków,Kraków,Digital Identities: the Past and the Future,2016-01-01T00:00:00Z,ADHO,ADHO,Jagiellonian University;Pedagogical University of Krakow,Kraków,,Poland,https://dh2016.adho.org/,An Iterative 3DGIS Analysis of the Role of Visibility in Ancient Landscapes,,Heather Richards-Rissetto,"paper, specified ""long paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"">
        <body>
        <div type=""div1"" rend=""DH-Heading1"">
            <head>Introduction</head>
            <p>Through the spatial arrangements of temples, houses, roads, and more, the built environment provides a window to human interaction (Lawrence and Low, 1990). Spatial configurations influence how people negotiate their surroundings. People “read environmental cues, make judgments…and then act accordingly” (Rapoport, 1990: 139), and these decisions in turn, affect the frequency and intensity of interaction (Fletcher 1981). While many factors influence interaction within landscapes, in this paper I focus on visibility. </p>
            <p>The visibility, intervisibility, and invisibility of features communicate information that guides pedestrian movement, and consequently, structures social interaction and community organization (Llobera, 2003, 2006; Gillings, 2015). Building on these ideas, this paper uses Geographic Information Systems (GIS) and 3D visualization to explore the role of visibility in ancient landscapes asking: 
                <hi rend=""italic"">How might visibility influence where people went, what they did, who interacted with whom, and how did these interactions shape their daily experiences? </hi>
            </p>
            <figure>
                <graphic url=""140/image1.jpg"" rend=""block""/>
                <head>Figure 1: Map of Copan’s location at southeastern periphery of Maya region (Map: H. Richards-Rissetto)</head>
            </figure>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
            <head>Case Study: Copan, Honduras</head>
            <p>The case study is the ancient Maya polity of Copan (Figure 1) ruled for over four-hundred years by a line of dynastic kings who by the late eighth century were facing mounting sociopolitical and environmental problems (Fash, 2001). Copan’s final dynastic ruler, 
                <hi rend=""italic"">Yax Pasaj</hi>, like the rulers of many other Maya polities, was coping with strenuous environmental, demographic, and sociopolitical circumstances that would ultimately lead to the kingdom’s demise. Yet during this time of stress, it seems that 
                <hi rend=""italic"">Yax Pasaj</hi> carried out a major urban renewal project commissioning several new temples in the city center that elevated Copan’s skyline. Given the changes to Copan’s urban fabric, 
                <hi rend=""italic"">Yax Pasaj’s</hi> reign is an ideal case study to investigate the role visibility may have played in the production or reproduction of social interaction among the ancient Maya. 
            </p>
            <p>At Copan, as at other Maya centers, imagery on ceramics, murals, and freestanding monuments depicted deities floating over lords who subsequently looked down over lower-ranking persons. Maya architecture replicated this vertical succession by elevating royal compounds above other architecture, and in essence linking Maya rulers to the heavens (Messenger, 1987). In terms of visibility, epigraphic decipherments indicate that “seeing” afforded high status, and sight had an authorizing gaze and witnessing function—similar to Foucault’s (1995) Panoptic gaze—where those who were all-seeing were all-knowing (Houston et al. 2006: 173). In order to be all-seeing or to give such an impression, however, Maya rulers needed to be seen, and so often located themselves in physically high and easily visible places or built tall temples that dominated the landscape.</p>
            <p>While we know that Maya kings typically constructed highly visible temples, we actually know very little about the role visibility may have played in structuring social connections and daily interactions among social groups. To do this we need to broaden our view from civic-ceremonial precincts to encapsulate the broader landscape (Doyle et al., 2012; Richards-Rissetto 2010; Landau, 2015). </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
            <head>Background: GIS & 3D Visualization</head>
            <p>Early visibility studies in the Maya region focused on astronomical alignments among structures, freestanding monuments, and the sky (Aveni and Hartung, 1986). Later, ethnographic studies showing that contemporary Maya often use sight lines to mark out spaces (Hanks, 1990) inspired researchers to investigate whether non-astronomical lines-of-sight also existed at ancient sites; and in fact, archaeologists identified sight lines between a major temple and outlying stelae at the site of La Milpa, Belize (Hammond and Tourtellot, 1999). Recent research has moved away from lines-of-sight between two objects to study the relationships that an object may have to the many objects or features found within a landscape, referred to as a visualscape (Llobera, 2003). Simple line-of-sight measurements cannot provide data on the relationships among multiple objects because they are done along a fixed line; however, visualscapes can be measured using viewsheds that calculate an object‘s entire 360° field-of-view using GIS. </p>
            <p>A GIS links mapped features to attributes stored in a database and overlays different data layers such as land usage, elevation, and buildings to help reveal complex patterns, relationships, and trends that are not readily apparent using other tools such as traditional databases not linked to maps. </p>
            <p>
                <hi rend=""underline"">Pros:</hi> In regard to visibility analysis, GIS allows archaeologists to move beyond line-of-sight analysis to viewshed analysis. A viewshed uses raster data (pixels) to identify all cells visible from one or more viewpoints in a landscape; all non-visible cells are assigned a 0 and all visible cells are assigned a 1. This basic binary schema allows for complex mathematical calculations, for example, Boolean operations or map algebra, to calculate topographic prominence of individual features (or classes of features) and percentage of intervisibility among features. 
            </p>
            <p>
                <hi rend=""underline"">Cons:</hi> “Viewsheds depicted in a GIS map bear little resemblance to what people experience on the ground” (Conolly and Lake, 2006: 233). This limitation occurs because viewshed data are 2.5D. In other words, viewsheds store heights and elevation, but they are not actually 3D models (Figure 2). For digital humanists, these flat maps lack a sense of mass, scale, and aesthetics integral to human perception and experience, and the numerical outputs fail to differentiate visibility of a building’s façade versus its sides or back—essential for close reading interpretation. Technically, data resolution (i.e., ratio of pixel size to earth’s surface) can dramatically affect viewshed results—low spatial resolution often masking variation and too high a spatial resolution underestimating visibility (King et al., 2015). 
            </p>
            <figure>
                <graphic url=""140/image2.jpg"" rend=""block""/>
                <head>Figure 2: Cumulative viewshed illustrating number of valley stelae visible at locations at Copan</head>
            </figure>
            <p>3D technologies offer an alternative to GIS. 3D data acquisition (e.g., airborne LiDAR, terrestrial laser scanning, and photogrammetry), 3D modeling (e.g., SketchUp, 3D StudioMax, Agisoft), and interactive 3D visualization (e.g., Unity, Oculus Rift) are transforming archaeological practice. But, what impact are such 3D technologies having on visibility analysis across ancient landscapes? Airborne LiDAR, for example, rapidly collects 3D data for archaeological sites across vast areas (Thompson and Prufer, 2015). Most LiDAR data are of unexcavated mounds requiring subsequent 3D modeling of architecture and proper alignment within terrains in order to perform visibility analysis—traditionally time-consuming tasks (Richards-Rissetto, 2013). </p>
            <p>While most visibility analyses of archaeological landscapes use traditional 2.5D GIS, recently archaeologists have been exploring the potential of 3D approaches for visibility analysis in archaeology. Paliou (2014) developed a computational visibility approach to analyze the visual range of paintings first using 3D modeling programs (3DStudioMax and AutoCAD) and then converting the results into raster maps to be analyzed in a GIS. Dell’ Unto and colleagues (2015) bring georeferenced 3D architectural models (using laser scanning and photogrammetry) into a GIS to calculate visibility of building interiors at Pompeii. While Saldana and Johanson (2015) also use 3DGIS, they employ procedural modeling to rapidly generate alternative 3D building reconstructions based on a set of architectural rules and attributes stored in a GIS to explore visibility in Ancient Rome (Saldana, 2015).</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
            <head>Methods</head>
            <p>Building on this scholarship, I employ an iterative 3DGIS approach to explore the role of visibility at the ancient Maya site of Copan—today a UNESCO World Heritage Site in Honduras. The approach is twofold: computational and experiential. In the computational approach, I employ traditional 2.5D viewshed analysis in GIS to establish a baseline for comparative analysis with viewshed results in 3DGIS. </p>
            <p>First, I use ArcGIS 10.3 (standard GIS software) to assign known building heights and interpolate building heights of unexcavated mounds and run viewsheds to calculate topographic prominence and percent visibility in relation to settlement of major temples and classes of architecture (Richards-Rissetto, 2013). Recent acquisition of airborne LiDAR data has generated a 1m resolution terrain allowing for greater accuracy than earlier visibility analyses (Richards-Rissetto, 2010; von Schwerin et al., 2016). Second, I employ CityEngine—a procedural modeling program that convert GIS data to 3D models—to generate 3D models for Copan’s 3,000+ buildings with the LiDAR terrain using the GIS data and a set of architectural rules as well as laser scanned and photogrammetric models of some standing monuments at Copan (Figure 3) (Muller et al., 2006; Richards-Rissetto and Plessing, 2015; von Schwerin et al., 2013). These procedurally-generated 3D models are then returned to ArcScene (a 3D viewer for ArcGIS) and the viewshed analysis is rerun for comparative analysis of 2.5DGIS vs. 3DGIS of visibility at ancient Copan.</p>
            <figure>
                <graphic url=""140/image3.jpg"" rend=""block""/>
                <head>Figure 3: Illustrating procedurally-generated models and various data types imported into CityEngine</head>
            </figure>
            <p>In the experiential approach, I export the 3D models and terrain from CityEngine into Unity 5—a gaming engine—to interactively explore the 3D models. In this model, vegetation is added to the landscape and avatars proceed along set paths generated from a combined cost surface and visibility analysis (Figure 4) (Richards-Rissetto, 2013; Richards-Rissetto and Landau, 2014). Oculus Rift—a head-mounted virtual reality display—is employed to create an immersive experience for ancient Copan as a means to more intuitively interact with archaeological data (Bartolo et al., 2000; Frisher and Dakouri-Hild, 2008). </p>
            <figure>
                <graphic url=""140/image4.jpeg"" rend=""block""/>
                <head>Figure 4: 3D Models (from SketchUp using GIS data) visualization in Unity 5 (Richards-Rissetto and Day)</head>
            </figure>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
            <head>Discussion</head>
                <p>Strongly embedded in the Digital Humanities, this 3DGIS iterative approach tacks back and forth between 2.5D and 3D data to compare results and potentially derive new methods and interpretations for visibility analysis of ancient landscapes—analyses that would not be possible without taking advantage of the digital to cross-cut the computational and experiential. </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
            <head>Acknowledgements</head>
                <p>The Layman Award, University of Nebraska-Lincoln provided a seed grant to carry out initial procedural modeling tests. This research would not be possible without permission and assistance from the Honduran Institute of Anthropology and History (IHAH). The MayaArch3D Project has generously providing the airborne LiDAR data and the laser scanned and photogrammetric models for this research. I want to thank UNL students Zachary Day, Stephanie Sterling, and Rachel Plessing for their important work on the visualizations. </p>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend=""bold"">Aveni, A., and Hartung, H.</hi> (1986). Maya City Planning and the Calendar. 
                        <hi rend=""italic"">Transactions of the American Philosophical Society</hi>, 0065-9746, Vol. <hi rend=""bold"">76</hi>, pt. 7. Philadelphia: American Philosophical Society.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Barcelo, J., Forte, M. and Sanders, D.</hi> (Eds.) (2000). 
                        <hi rend=""italic"">Virtual reality in archaeology. </hi>Oxford: Archaeopress. 
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Conolly, J. and Lake M.</hi> (2006). 
                        <hi rend=""italic"">Geographical Information Systems in Archaeology</hi>. Cambridge University Press. 
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Dell’ Unto, N., Landeschi, G., Leander, T., Touati, A., Dellepiane, M., Callieri M. and Ferdani, D.</hi> (2015). Experiencing Ancient Buildings from a 3D GIS Perspective: a Case Drawn from the Swedish Pompeii Project. 
                        <hi rend=""italic"">Journal of archaeological method and theory</hi>.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Doyle, J., Garrison, T. and Houston, S.</hi> (2012). Watchful Realms: integrating GIS analysis and political history in the southern Maya lowlands. 
                        <hi rend=""italic"">Antiquity</hi>, <hi rend=""bold"">86</hi>(333): 972-807.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Fash, W.</hi> (2001). 
                        <hi rend=""italic"">Scribes, Warriors, and Kings: The City of Copan and the Ancient Maya</hi>. Thames and Hudson, London. 
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Fletcher, R.</hi> (1981). People and Space: A Case Study on Material Behavior. In 
                        <hi rend=""italic"">Pattern of the Past: Studies in Honour of David Clarke</hi>, edited by I. Hodder, G. Issac, and N. Hammond, Cambridge University Press, Cambridge, pp. 97-128.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Foucault, M.</hi> (1995). 
                        <hi rend=""italic"">Discipline and Punishment.</hi> Vintage Books, New York.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Frisher, B. and Dakouri-Hild, A.</hi> (Eds.) (2008). 
                        <hi rend=""italic"">Beyond Illustration: 2D and 3D Digital Technologies as Tools for Discovery in Archaeology</hi>, BAR International Series 1805. Oxford: Archaeopress, 2008
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Gillings, M.</hi> (2015). Mapping invisibility: GIS approaches to the analysis of hiding and seclusion. 
                        <hi rend=""italic"">Journal of Archaeological Science</hi> <hi rend=""bold"">62</hi>: 1–14
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Hammond, N. and Tourtellot G.</hi> (1999). Shifting Axes: Spatial Expressions of Power at La Milpa. Paper presented at the 64
                        <hi rend=""superscript"">th </hi>Annual Meeting, <hi rend=""italic"">Society for American Archaeology</hi>. Chicago, IL. March 27th.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Hanks, W.</hi> (1990). 
                        <hi rend=""italic"">Referential Practice: Language and Lived Space among the Maya</hi>. The University of Chicago Press, Chicago and London.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Houston, S., Stuart, D. and Taube, K.</hi> (2006). 
                        <hi rend=""italic"">The Memory of Bones: Body, Being, and Experience among the Classic Maya</hi>. University of Texas, Austin.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">King. J., Richards-Rissetto, H. and Landau K.</hi> (2015). Enter the Void: A GIS Analysis of the Visibility of Empty Spaces at Copan, Honduras. Paper presented at Society for American Archaeology 80th Annual Meeting, San Francisco, CA. April 2015.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Landau, K.</hi> (2015). Spatial Logic and Maya City Planning: The Case for Cosmology. 
                        <hi rend=""italic"">Cambridge Archaeological Journal </hi><hi rend=""bold"">25</hi>(1): 275-92.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Lawrence, D. and Low, S.</hi> (1990). The Built Environment and Spatial Form. 
                        <hi rend=""italic"">Annual Review of Anthropology </hi><hi rend=""bold"">19</hi>: 453-505.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Llobera, M.</hi> (2003). Extending GIS Based Analysis: The Concept of the Visualscape. 
                        <hi rend=""italic"">International Journal of Geographic Information Science</hi> <hi rend=""bold"">1</hi>(17): 25-48.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Llobera, M.</hi> (2006). What you see is what you get?: Visualscapes, visual genesis and hierarchy. In 
                        <hi rend=""italic"">Digital Archaeology: Bridging Method and Theory</hi>, (Ed) P. Daly and T. Evans,  Routledge, Taylor and Francis, New York and London, pp. 148-67.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Messenger, L.</hi> (1987). Community Organization of the Late Classic Southern Periphery of Mesoamerica: Expressions of Affinity. In 
                        <hi rend=""italic"">Interaction on the Southeast Mesoamerican Frontier: Prehistoric and Historic Honduras and El Salvador</hi>, In E. J. Robinson (Ed), BAR International Series 327 (ii), pp. 385-420.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Muller, P., Vereenooghe, T., Wonka, P., Papp, I. and van Gool L.</hi> (2006). Procedural 3D reconstruction of Puuc buildings in Xkipché. 
                        <hi rend=""italic"">7th International Symposium on Virtual Reality, Archaeology and Cultural Heritage, VAST</hi>. M. Ioannides, D. Arnold, F. Niccolucci, and K. Mania (Ed). 
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Paliou, E.</hi> (2014). Visibility analysis in 3D built spaces: a new dimension to the understanding of social space. In 
                        <hi rend=""italic"">Spatial analysis and social spaces: Interdisciplinary approaches to the interpretation of prehistoric and historic built environments</hi>, E. Paliou, U. Lieberwirth, and S. Polla (eds). Series: Topoi – Berlin Studies of the Ancient World 18.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Rapoport, A.</hi> (1990). 
                        <hi rend=""italic"">The Meaning of the Built Environment: A Nonverbal Communication Approach</hi>. University of Arizona Press: Tucson.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Richards-Rissetto, H.</hi> (2010). 
                        <hi rend=""italic"">Exploring Social Interaction at the Ancient Maya City of Copán,</hi>
                    </bibl>
                    <bibl>
                        <hi rend=""italic"">Honduras: A Multi- Scalar Geographic Information Systems (GIS) Analysis of Access and Visibility</hi>. Unpublished PhD: University of New Mexico.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Richards-Rissetto, H. and Plessing, R.</hi> (2015). Procedural modeling for ancient Maya cityscapes: Initial methodological challenges and solutions. 
                        <hi rend=""italic"">Proceedings for Digital Heritage International Congress 2015, </hi>Granada, Spain. 
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Richards-Rissetto, H.</hi> (2013). From mounds to maps to models: visualizing ancient architecture across landscapes. 
                        <hi rend=""italic"">Proceedings of Digital Heritage International Congress 2013</hi>, Marseille, France.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Richards-Rissetto, H. and Landau, K.</hi> (2014). Movement as a means of social re(production): Using GIS to measure social integration in urban landscapes. 
                        <hi rend=""italic"">Journal of Archaeological Science</hi> <hi rend=""bold"">41</hi>: 365-75.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Saldaña, M.</hi> (2015). An Integrated Approach to the Procedural Modeling of Ancient Cities and Buildings. 
                        <hi rend=""italic"">Digital Research in the Humanities</hi> (print volume forthcoming).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Saldaña, M. and Johanson, C.</hi> (2013). Procedural Modeling for Rapid-Prototyping of Multiple Building Phases and Hypothetical Reconstructions of Early Rome. 
                        <hi rend=""italic"">International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences</hi>, Vol. XL-5/W1.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Thompson, A. and Prufer, K.</hi> (2015). Evaluating airborne LiDAR for detecting settlements and modified landscapes in disturbed tropical environments at Uxbenka, Belize. 
                        <hi rend=""italic"">Journal of Archaeological Science </hi><hi rend=""bold"">57</hi>: 1-13.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">von Schwerin, J., Richards-Rissetto, H., Remondino, F. and Agugiaro G.</hi> (2013). The MayaArch3D Project: A 3D WebGIS for Analyzing Ancient Maya Architecture and Landscapes at Copan, Honduras. 
                        <hi rend=""italic"">Literary and Linguistic Computing</hi>. Oxford University Press.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Von Schwerin, J., Richards-Rissetto, H., Remondino, F., Grazia Spera, M., Auer, M., Billen, N., Loos, L. and Reindel M.</hi> (2016). Airborne LiDAR Acquisition, Post-Processing and Accuracy-Checking for a 3D WebGIS of Copan, Honduras. 
                        <hi rend=""italic"">Journal of Archaeological Science Reports</hi>. 
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>
",xml,This text is republished here with permission from the original rights holder.,,3d visualization;gis;landscape archaeology;mesoamerica;visibility analysis,English,"archaeology;archives, repositories, sustainability and preservation;databases & dbms;digital humanities - pedagogy and curriculum;games and meaningful play;geospatial analysis, interfaces and technology;maps and mapping;standards and interoperability;virtual and augmented reality;visualization"
2588,2016 - Kraków,Kraków,Digital Identities: the Past and the Future,2016-01-01T00:00:00Z,ADHO,ADHO,Jagiellonian University;Pedagogical University of Krakow,Kraków,,Poland,https://dh2016.adho.org/,Intersectional Scholarship in Electronic Literature and Digital Humanities,,Elika Ortega;James O'Sullivan;Dene Grigar,panel / roundtable,"<text xmlns=""http://www.tei-c.org/ns/1.0"">
        <body>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Introduction</head>
                <p rend=""normal"">This panel examines some of the many shared issues between Digital Humanities (DH) practices and theories with those in the study of Electronic Literature (E-Lit). Until recently, the fields of DH and E-Lit, though intimately related, have intersected only to a certain extent. The historical development of each of the fields––broadly speaking, DH originating from the earlier humanities computing; E-Lit work from experimental poetics and digital media––might be the reason why these two fields have not engaged in sustained communication. A few events have started to revert this tendency. Within the Alliance of Digital Humanities Organizations (ADHO), the approval of the Special Interest Group on Audiovisual Data in Digital Humanities (SIG AVinDH) is an important milestone fostering the exchange of “knowledge, expertise, methods and tools by scholars who make use of audiovisual data types that can convey a certain level of narrativity: spoken audio, video and/or (moving) images” (
                    <ref target=""https://avindhsig.wordpress.com/2015/06/24/avindh-sig-dh2015-in-sydney/"">
                        <hi rend=""underline color(1155CC)"">AVinDH SIG @DH2015 in Sydney)</hi>
                    </ref>. Similarly, constant collaboration between the Digital Humanities Summer Institute (DHSI) and the Electronic Literature Organization (ELO) in the last few years has lead to deeper collaborations between scholars bridging both fields of knowledge. 
                </p>
                <p rend=""normal"">In previous ADHO conferences, though on occasion E-Lit has been part of the schedule, it remains a fact that there is room for a timely intervention not only signaling where E-Lit and DH intersect, but also pointing out where E-Lit specific insights are capable to illuminate instrumental approaches to DH theory and practice. E-Lit work has much to offer to DH. An awareness of the expressiveness and historicity of the digital medium that compliments its instrumental and innovative dimension. Dealing with multiple expressive codes besides language, and through the leadership of the ELO, E-Lit work has been at the forefront of inclusivity, diversity, and multilingualism. Issues that continue to be discussed in DH venues. </p>
                <p rend=""normal"">Specifically, the papers in this panel will focus on the materiality of electronic literature as it illuminates the ongoing debates of print-digital media and changing reading and writing practices; the applicability to works of E-Lit of forms of quantitative criticism that had been used exclusively for print literature in DH; and finally, the best practices for collecting and archiving electronic literature as it affects GLAM and what it can teach us about all, or most, DH work subject to obsolescence. We hope that this panel will foster further explorations and collaborations between the two fields of study.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>""Print"" Works of Electronic Literature and Scholarly DH Narratives</head>
                <p>
                    <hi rend=""bold"">Élika Ortega, Institute for Digital Research in the Humanities. University of Kansas.</hi>
                </p>
                <p rend=""normal"">These paper starts with the question what can DH practitioners learn from material composition of electronic literature works in order to improve the outreach of DH projects? This work focuses specifically on the material architecture of ""print"" works of electronic literature, which I understand as those that depend or heavily hinge on print materials for their digital configuration. Drawing from this corpus, I propose to take E-Lit works as models to explore and address the effect of digital media as it has modified––and continues to propose a modification of––reading and writing practices as well as modes of abstracting, encoding, and communicating information, all of which are common in DH pedagogical and research praxis. </p>
                <p rend=""normal"">First, I examine a handful of creative print works of electronic literature including Stephanie Strickland's et al 
                    <hi rend=""italic"">Vniverse</hi> (2011), Amaranth Borsuk and Brad Bouse’s
                    <hi rend=""italic""> Between Page and Screen</hi> (2012), Nick Montfort’s 
                    <hi rend=""italic"">#!</hi> (2014), and Jacob Garbe and Aaron Reed’s 
                    <hi rend=""italic"">Ice-Bound </hi>(2015). I argue that the architecture of these works requires specific infrastructural conditions and the unfolding of several practices or protocols for their reading that pose challenges not only for preservation and archives professionals, but for the average reader as well. Strickland’s
                    <hi rend=""italic"">, </hi>Borsuk and Brad Bouse's
                    <hi rend=""italic"">, </hi>Montfort's, and Garbe Reed's works are so uniquely imagined and crafted that they seem to embed within them the specific critical framework to be theorized. In that sense, they too demand a tailored reading: a look into how their text is media and how their media is text. These kinds of compositions, I argue, have much to teach DH practitioners and students about the expressiveness of the digital medium, the way electronic and print media reciprocally inform, shape, and inflect each other. Further, they allow us to study the modification of the practices and protocols associated with each of its material components: print objects are not self-sufficient and translatable outside of the digital realm, computational devices are rendered useless without input from print materials. Even when these works are highly experimental, the specific conditions of each one constitute a laboratory to investigate contemporary changing reading and writing practices.
                </p>
                <p rend=""normal"">Further, I argue that in their radical specificity, creative works like these that rely on various print or digital media for their poetic, material, or narrative construction provide models for multimodal design that is both highly desirable and commonly found in DH scholarly outputs. The organization of information––whether poetic, narrative, or scholarly––is certainly responding to the same moving-target media landscape and, thus, bringing them all together offers an opportunity to observe how material composition is approached in creative works in ways that can be extrapolated to scholarly works. To that end, I extract a handful of compositional strategies from the works mentioned above that can be translated to a scholarly realm. Among them, we can find the use of augmented reality, the design of a script that takes the reader from one medium to another, the 
                    <hi rend=""italic"">extension</hi> and complementation of information through different expressive languages, and even the performance of reading as an interpretive act. Under this light, aside from being great examples of poetic and computational creativity, these works of electronic literature are capable of illuminating the ongoing debates on the future of the book, and the place of the monograph in academic careers. Crucially, these works also signal the need for training in alternative reading and writing capacities that sits at the center of DH instruction, project development, and outreach. Taken as models of composition in the media ecology in which DH work is currently carried out, these works offer avenues for communication between the two fields not only on a conceptual level, but also as a methods of argumentation and interpretation.
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Quantifying the Evolution of Electronic Literature with Zeta</head>
                <p>James O'Sullivan, Pennsylvania State University</p>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Introduction</head>
                    <p rend=""normal"">This paper seeks to determine to extent to which electronic literature (understood as born-digital literature with an inherent computational aesthetic) has evolved, by analysing the language used to describe the works included in both 
                        <hi rend=""italic"">Volume I</hi> and 
                        <hi rend=""italic"">II</hi> of the Electronic Literature Organization's 
                        <hi rend=""italic"">Electronic Literature Collection</hi>. These anthologies include descriptions of the works by their respective editors, as well as by the contributing authors. Outlining the various technical and literary characteristics reflected in each work, these descriptions provide a unique opportunity to determine the aesthetic qualities of the canon, as depicted by some of the field’s most prominent practitioners. Furthermore, the considerable time between the publication of the collections, released in 2006 and 2011 respectively, is such that they provide a useful sample when examining how the electronic literary movement has developed throughout the contemporary era. Using a method typically reserved for print literature, this paper applies a macro-analytical approach to the analysis of these descriptions in an effort to produce some quantitative evidence to support critical interpretations on the evolution of electronic literature. Research of this sort has never been conducted in this field, and thus, not only does this paper develop our understanding of the literary movement in question, but it also breaks new ground in the application of specific computational methods to born-digital artistry.
                    </p>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Methodology & Results </head>
                    <p rend=""normal"">For the purposes of this study, Craig’s Zeta was selected as the method best suited to identifying trends in the manner by which electronic literature is described by its creators and curators. A Zeta analysis compares two datasets, producing a set of words distinct to each. In other words, it gives a set of words most likely to occur in Set A, which are unlikely to appear in Set B. In this instance, the analysis compared the editor and author contributions from each volume, providing a list of words which indicate what topics were being prioritised across the collections. Comparing these wordlists, we can see how it is that the focus of the electronic literature community changed over the course of this particular time period. The Zeta analysis was conducted using R, with a text slice length of 2,000, text slice overlap of 1,000, an occurrence of 2, and filter threshold of 0.1. For the purposes of this abstract, the top 25 distinctive words have been displayed (see Table 1), but a more complete set of results will be addressed in the final offering.</p>
                    <table rend=""rules"">
                        <row>
                            <cell rend=""normal"">
                                <hi rend=""italic"">Volume I </hi>(2006)
                            </cell>
                            <cell rend=""normal"">
                                <hi rend=""italic"">Volume II</hi> (2011)
                            </cell>
                        </row>
                        <row>
                            <cell rend=""normal"">diagrams</cell>
                            <cell rend=""normal"">video</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">exploring</cell>
                            <cell rend=""normal"">rather</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">versions</cell>
                            <cell rend=""normal"">google</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">blue</cell>
                            <cell rend=""normal"">relation</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">clock</cell>
                            <cell rend=""normal"">see</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">gallery</cell>
                            <cell rend=""normal"">herself</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">red</cell>
                            <cell rend=""normal"">pages</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">ambient</cell>
                            <cell rend=""normal"">creative</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">away</cell>
                            <cell rend=""normal"">water</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">corresponding</cell>
                            <cell rend=""normal"">last</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">dhtml</cell>
                            <cell rend=""normal"">map</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">practice</cell>
                            <cell rend=""normal"">emblems</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">earlier</cell>
                            <cell rend=""normal"">home</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">murder</cell>
                            <cell rend=""normal"">engine</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">my</cell>
                            <cell rend=""normal"">production</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">version</cell>
                            <cell rend=""normal"">tree</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">line</cell>
                            <cell rend=""normal"">unknown</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">nature</cell>
                            <cell rend=""normal"">age</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">author</cell>
                            <cell rend=""normal"">beyond</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">makes</cell>
                            <cell rend=""normal"">break</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">landscapes</cell>
                            <cell rend=""normal"">friends</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">frame</cell>
                            <cell rend=""normal"">had</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">day</cell>
                            <cell rend=""normal"">imagery</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">poetics</cell>
                            <cell rend=""normal"">screens</cell>
                        </row>
                        <row>
                            <cell rend=""normal"">meditation</cell>
                            <cell rend=""normal"">starts</cell>
                        </row>
                    </table>
                    <p rend=""normal"">
                        <hi rend=""italic"">Table 1. Top 25 distinctive words used to described the anthologised works</hi>
                    </p>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Interpretations</head>
                    <p rend=""normal"">The results of the Zeta analysis provide computational evidence for many of the assumptions that one might make when speculating on this issue. For example, there is a marked shift from static “diagrams” in 
                        <hi rend=""italic"">Volume I</hi>, to “video”, in 
                        <hi rend=""italic"">Volume II.</hi> The evolution of Web cultures is also apparent, with “dhtml” giving way to “google”. Beyond these, somewhat expected, findings, other, more interesting, revelations are also present. In particular, the inclusion of herself"" in the later collection would suggest a rise in feminist electronic literature, while words like “exploring” and “poetics” in 
                        <hi rend=""italic"">Volume I </hi>suggests a field that, in 2006, is still ontologically uncertain. As already noted, a more robust analysis drawn from a more thorough interpretation of the entire set of findings will be offered in this paper. However, from this limited snapshot into this study, it is clear that this approach yields valuable insights into the field, and justifies the use of macro-analysis in the extrapolation of cultural contexts.
                    </p>
                </div>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Rendering Literature: Methods for Collecting and Archiving Electronic Literature</head>
                <p>
                    <hi rend=""bold"">Dene Grigar, PhD, The Creative Media & Digital Culture Program, Washington State</hi>
                </p>
                <p>University Vancouver</p>
                <p rend=""normal"">This presentation, entitled “Rendering Literature: Methods for Collecting and Archiving Electronic Literature”, focuses on methods developed to document early digital literature, 1986-1995.</p>
                <p rend=""normal"">This paper builds on research undertaken with 
                    <hi rend=""italic"">Pathfinders: Documenting the Experience of Early Digital Literature</hi> (with Stuart Moulthrop, scalar.usc.edu/works/pathfinders), a project funded by the National Endowment for the Humanities that developed the methodology for documenting early works of electronic literature (1986-1995) and the print-based book, 
                    <hi rend=""italic"">Traversals</hi> (forthcoming, The MIT Press, 2016, also with Moulthrop) that provides a critical look at the works themselves. 
                    <hi rend=""italic"">Rendering Literature</hi> aims to discuss best practices for collecting and archiving electronic literature by libraries, museums and other institutions so that works retain their inherent significant properties, including its cultural context.
                </p>
                <p rend=""normal"">Electronic literature is an experimental literary art form that can include a combination of words, images, sound, video, animation, gestures, and movement but always involves code and computation. Referred to often as born digital literature, electronic literature cannot be experienced meaningfully in print and is intended, instead, to be accessed through digital devices. Early work was published on floppy disks, CDs, and DVDs, but the advent of the web made sharing it online with a global audience popular from 1995 onward. The introduction of smart mobile devices in the mid-2000s drove artists to innovate their art for the app environment. To remain accessible to a reading audience, many works of electronic literature have been updated to newer platforms and software iterations––sometimes many times––resulting in numerous versions of a work. In cases of literary art produced as apps, it is not possible to study versions of a work saved on a single device because upgrading to a new version of a work overwrites the previous version completely.</p>
                <p rend=""normal"">Contributing to the challenge of archiving electronic literature is that many of these works are published as a combination of digital files, accompanying documentation websites, and ephemera. Some, like John McDaid's 
                    <hi rend=""italic"">Uncle Buddy Phantom Funhouse</hi> (1993) include audio cassettes that are part of the narrative. Others like Judy Malloy’s 
                    <hi rend=""italic"">Uncle Roger Version 3</hi> (1987-8) were packaged in hand-made artists boxes that themselves are works of visual art. Recent works like Erik Loyer’s 
                    <hi rend=""italic"">Breathing Room</hi> (2013) or Amaranth Borsuk and Brad Bouse’s 
                    <hi rend=""italic"">Whispering Galleries </hi>(2014), require additional equipment like a Leap Motion controller. Still others like Jody Zellen’s 
                    <hi rend=""italic"">Urban Rhythms</hi> (2011) exist only as apps. In a word, these works differ widely from traditional digital texts and yet, to date, there are no specific methods used for handling this form of literary art.
                </p>
                <p rend=""normal"">A visit in October 2015 to the David M. Rubenstein Rare Book and Manuscript Library</p>
                <p rend=""normal"">at Duke University to locate data in the Judy Malloy Papers for an article about her database novel,
                    <hi rend=""italic"">Uncle Roger</hi>, drove home the need to analyze methods of archiving and preservation undertaken at collections of electronic literature in the U.S. Floppy disks were separated from their artists boxes and unavailable for review, while inserts for the artists boxes were placed in separate folders in a different section of the archival containers. The six versions of the work were not readily distinguishable from one another. Discussions with the librarians and archivists revealed that they too were interested in determining how best to handle such complex problems for works that resist current preservation and archival practices.
                </p>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Research Significance</head>
                    <p rend=""normal"">Nothing lasts forever. Paper mildews. Sappho’s nine books of poetry were burned, leaving but a few extant poems for us to read. Today, poetry and literary forms are increasingly produced in the electronic medium, and the danger facing them is not dampness or fire but the constant innovation of digital technology. Net poetry by artists like Jason Nelson created a mere 10 years ago, for example, is quickly becoming obsolete today because the Apple Corporation decided in 2007 not to support Flash on its iPhones. Despite this problem, digital technologies have fostered the production of so much experimental work that one of the key challenges facing the humanities today is how to transmit the heritage of a culture whose objects are multiplying not simply in mass of items but also in types of system or interface––and where the nature of those varying interfaces greatly complicates the task of identifying, collecting, and otherwise treating the object. This is an enterprise that requires traditional archival research to work in conjunction with Digital Humanities practice where computation methods figure largely (Burdick et al., 3).</p>
                </div>
                <div type=""div2"" rend=""DH-Heading2"">
                    <head>Experience</head>
                    <p>For the last 25 years I have collected works of electronic literature. Driving my efforts besides a fascination with avant-garde literature was the early realization that many of the works in my collection were, over time, becoming impossible to access without computer equipment contemporary with the works themselves. In other words, it became necessary for me to collect, along with floppy disks, CDs, and DVDs holding electronic literary poetry, fiction and essays, computers for which the works were intended to be experienced. To date, I have collected a library of 200 works of electronic literature and 46 vintage computers dating to 1977. I have also found it necessary to collect versions of software for which these works were produced, such as Netscape Communicator used by many electronic literature artists for early experiments with net art and other web-based practices. My library and computer collections are now housed together in the Electronic Literature Lab (ELL, dtc-wsuv.org/wp/ell) at the Vancouver campus. ELL represents the method of digital preservation called Collecting, an approach different from Migrating and Emulating in that it seeks to retain the cultural experience of a work without moving it to a newer platform or representing it in a new setting, respectively. </p>
                </div>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl rend=""normal"">
                        <hi rend=""bold"">Electronic Literature Organization.</hi>
                        <hi rend=""italic"">Electronic Literature Collection</hi>, Vol. <hi rend=""bold"">1</hi> and Vol. <hi rend=""bold"">2</hi>.
                        <ref target=""http://collection.eliterature.org/"">
                            <hi rend=""underline color(1155CC)"">http://collection.eliterature.org/</hi>
                        </ref>
                    </bibl>
                    <bibl rend=""normal"">
                        <hi rend=""bold"">Burrows, J.</hi> (2007). All the Way Through: Testing for Authorship in Different Frequency Strata. 
                        <hi rend=""italic"">Literary and Linguistic Computing</hi>, <hi rend=""bold"">22</hi>(1): 27–47.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Burrows, J.</hi> (2004). Textual Analysis. In Schreibman, S., Siemens, R. and Unsworth, J. (eds),
                        <hi rend=""italic"">A Companion to Digital Humanities</hi>. Oxford: Blackwell.
                    </bibl>
                    <bibl rend=""normal"">
                        <hi rend=""bold"">Hoover, D.</hi> (2008). Quantitative Analysis and Literary Studies. In Schreibman, S., Siemens, R. and Unsworth, J. (eds),
                        <hi rend=""italic"">A Companion to Digital Humanities</hi>. Oxford: Blackwell, pp. 517–33.
                    </bibl>
                    <bibl rend=""normal"">
                        <hi rend=""bold"">Eder, M., Kestemont, M. and Rybicki, J.</hi> (2013). Sylometry with R: a suite of tools. 
                        <hi rend=""italic"">Digital Humanities 2013: Conference Abstracts</hi>. Lincoln (NE): University of Nebraska Lincoln, pp. 487–89.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>
",xml,This text is republished here with permission from the original rights holder.,,collection;computational analysis;electronic literature;materiality;preservation,English,"archives, repositories, sustainability and preservation;interface and user experience design;literary studies;text analysis;virtual and augmented reality"
2721,2016 - Kraków,Kraków,Digital Identities: the Past and the Future,2016-01-01T00:00:00Z,ADHO,ADHO,Jagiellonian University;Pedagogical University of Krakow,Kraków,,Poland,https://dh2016.adho.org/,Editing in a text-image-sound form: the eTalks,,Claire Clivaz;Martial Sankar;Cecile Pache,poster / demo / art installation,"<text xmlns=""http://www.tei-c.org/ns/1.0"">
        <body>
            <p>An interdisciplinary team of researchers has built a new multimedia editorial tool: the eTalks (Clivaz 2014; Clivaz et al., 2015a; Clivaz et al., 2015b; EADH projects, 2016), based primarily on speeches of scholars. Simple videos or MP3 recordings of lectures may prove insufficient to many researchers since they are unquotable in detail and they do not offer the possibility of being combined with text, images, hyperlinks, and references. Until now, no tool has been available for creating a carefully edited product that includes text-image-sound, all entirely quotable in details: yet, this is what we have achieved with the eTalks [<ref target=""http://etalk.vital-it.ch/mooser/mode-demploi-en/"">http://etalk.vital-it.ch/mooser/mode-demploi-en/</ref>].</p>
            <p>In creating the eTalks, we were motivated by the fact that academic publications and pedagogy have been deeply reconfigured by the emergence of a new kind of knowledge produced by the synergy between text, image and sound. As Tanya Clement points out, diverse Digital Humanities (DH) pedagogies, such as new media studies and game studies, can be characterized by looking at multiliteracies “that are engaged within undergraduate humanities curricula through general skills, principles and habits of mind that allow students to progress within and engage society in the twenty-first century” (Clement 2012). Academic publications in Humanities are slower than pedagogy in terms of the testing of multimodal literacies. However, different tools are now able to present slides joined to videos of scholarly talks, such as Slideshot and Dashboarding [<ref target=""http://slideshot.epfl.ch/play/cops_binney"">http://slideshot.epfl.ch/play/cops_binney</ref>; <ref target=""http://www.infoq.com/presentations/dashboard-data-analysis?utm_source=infoq&utm_medium=related_content_link&utm_campaign=relatedContent_presen"">http://www.infoq.com/presentations/dashboard-data-analysis?utm_source=infoq&utm_medium=related_content_link&utm_campaign=relatedContent_presen</ref>], but they cannot be quoted in detail. Scalar, a very impressive multimodal tool, proposes to “create interpretive pathways through the materials”[<ref target=""http://scalar.usc.edu/about/"">http://scalar.usc.edu/about/</ref>], privileging users’ points of view. The eTalks claim to rely on the scholar’s oral talk as a leading way among multimodal materials while giving the users the possibility of reconsidering the auctorial point of view by directly accessing all the quoted sources.</p>
            <figure>
                <graphic url=""149/image1.png"" rend=""inline""/>
            </figure>
            <p>The eTalks application implements an easy-to-use editor interface, designed for the use of researchers themselves, allowing for the creation and editing of original enhanced talks. This permits the linking together of images, sounds and textual materials by means of hyperlinks, thereby enriching the content with relevant information. The result of the editing is displayed through a viewer interface, allowing one to experiment with the entire eTalk or to actively navigate, scroll and search inside its content. After recording the speech of the scholar, the Audacity software allows for the splitting of the speech into pieces of 2-3 sentences. Each piece of speech can be associated with its written version, a slide, images, or hyperlinks and so forth. Each piece is also quotable with a specific URL: a new kind of reference. Thus, the final release of eTalks allows for the complete ‘citability’ of its contents: each and every portion of the researchers’ talks can be precisely referred to and therefore cited, just like any traditional, paper-based scientific publication but with all the potential for plural literacies.</p>
            <p>The core of the eTalk engine was developed in JavaScript and the code is now available as open source on Github as a free application for further development. The eTalks are currently being further developed and disseminated by an interdisciplinary team of researchers in Digital Humanities and bioinformatics at the Swiss Institute of Bioinformatics (Lausanne). Four series of eTalks have thus far been published as openly accessible: twelve on funerary rituals, nine on the enhanced Human, two on the institutional biobank of Lausanne, and one in Digital Humanities [<ref target=""http://etalk.vital-it.ch"">http://etalk.vital-it.ch</ref>]. The eTalks are now in development by institutional and research collaborations, notably the Pedagogical High School of Lausanne (HEPVaud) and the ERASMUS+ #dariahTeach project, whose purpose is to offer a webportal by 2017 that will include digital teaching modules [<ref target=""http://www.dariah.eu/teach"">www.dariah.eu/teach</ref>].</p>
            <p>We will present eTalks’ main features in our poster, and in particular the question of copyrights: to be able to quote several images, the team had to learn the basic rules of the relevant Swiss laws, and how Wikipedia commons work in Switzerland; furthermore we plan to develop European test-cases. We have also learned to negotiate with the authors and to convince them to rather use open access material. In difficult cases, we consult specialized people. Such obstacles had to be navigated and new skills acquired by our team as new, necessary knowledge. We will secure the interoperability of our data, and progressively introduce videos, and purl references.</p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend=""bold"">Clement, T.</hi> (2012). Multiliteracies in the Undergraduate Digital Humanities Curriculum: Skills, Principles, and Habits of Mind. In Hirsch, B. (ed.)
                        <hi rend=""italic"">Digital Humanities Pedagogy: Practices, Principles and Politics</hi>, Cambridge, UK: Open Book Publishers, pp. 365–88. 
                        <ref target=""http://www.openbookpublishers.com/htmlreader/DHP/chap15.html"">http://www.openbookpublishers.com/htmlreader/DHP/chap15.html</ref>
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Clivaz, C.</hi> (2014). De l’article à l’etalk : enjeux et défis de la littératie plurielle dans la communication académique, 
                        <hi rend=""italic"">Actes du colloque de l'AIPU 2014, Mons (Belgique)</hi>. 
                        <ref target=""http://hosting.umons.ac.be/php/aipu2014/C9TEST/select_depot2.php?q=1775"">http://hosting.umons.ac.be/php/aipu2014/C9TEST/select_depot2.php?q=1775</ref>
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Clivaz, C., Rivoal, M. and Sankar, M.</hi> (2015a). A New Platform for Editing Digital Multimedia: The eTalks. In Schmidt, B. and Dobreva, M.  (Eds.)
                        <hi rend=""italic"">New Avenues for Electronic Publishing in the Age of Infinite Collections and Citizen Science</hi>, The authors and IOS Press, doi: 10.3233/978-1-61499-562-3-156; 
                        <ref target=""http://ebooks.iospress.nl/publication/40894"">http://ebooks.iospress.nl/publication/40894</ref>
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Clivaz, C., Pache, C., Rivoal, M. and Sankar, M.</hi> (2015b). Multimodal literacies and academic publishing: the eTalks, 
                        <hi rend=""italic"">Information Services and Use</hi>, <hi rend=""bold"">35</hi>: 4.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">EADH projects</hi> (2016). 
                        <ref target=""http://eadh.org/projects/etalks"">http://eadh.org/projects/etalks</ref>
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>
",xml,This text is republished here with permission from the original rights holder.,,digital edition;multimodal literacies,English,"audio, video, multimedia;copyright, licensing, and open access;digitisation, resource creation, and discovery;publishing and delivery systems"
2795,2016 - Kraków,Kraków,Digital Identities: the Past and the Future,2016-01-01T00:00:00Z,ADHO,ADHO,Jagiellonian University;Pedagogical University of Krakow,Kraków,,Poland,https://dh2016.adho.org/,Thresholds: Valuing the Creative Process in Digital Publishing,,Whitney Trettien;Frances McDonald,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"">
        <body>
            <div type=""div1"" rend=""DH-Heading2"">
                <head>Introducing 
                    <hi rend=""italic"">thresholds</hi>
                </head>
                <p>
                    <hi rend=""italic"">handwritten sticky notes, highlighted document pages, and grainy photographs rub against one another, forming dense and shifting thickets. the blank spaces between once-distinct districts become cluttered and close. geographically distant realms ache to converge. the bookcase furiously semaphores toward the far corner of the room. thin lines of colored paper arrive to splay across sections. the wall bursts at every seam.</hi>
                </p>
                <p>Whether it be real or virtual, every project has its own “wall”: the irrepressibly interdisciplinary network that inspires and propels the work. Populating this capharnaum are the ideas, images, sentences, scenes, and characters that “stick to us,” to use Lara Farina’s evocative phrase (Farina, 2014). They are the “encounters” that Deleuze describes as the impetus toward work, the things that “strike” us, as Benjamin puts it, like a hammer to unknown inner chords (Deleuze, 1988; Benjamin, 1999). This affective principle of collection (what strikes you) means that the wall is an intensely personal artifact. Its unique architecture springs from a thinker’s nomadic wanderings through and amidst a cultural and aesthetic landscape, whose dimensions are stretched beyond traditional disciplinary boundaries to include anything that clings to us, whether it be Werner Heisenberg’s letters or an episode of 
                    <hi rend=""italic"">Breaking Bad</hi>.
                </p>
                <p>Although instrumental to every humanities project, the wall has a brutally short lifespan. The writer strives to reassert control over its borders and boundaries by whittling down its undisciplined excesses; indeed, training to be a scholar is in large part learning to compress and contain the wall’s licentious sprawl. We shorten our focus to a single period, place, or author; excise those fragments that fall outside the increasingly narrow range of our “expertise”; and briskly sever any loose ends that refuse to be tied. These regulatory measures help align our work with the temporal, geographic, and aesthetic boundaries of our disciplinary arbiters: the journals and university presses that publish our work, the departments that hire and tenure us. In an increasingly tight academic marketplace, where the qualified scholars, articles, and projects far outnumber the available positions, deviation from the standard model can seem like risky business indeed. </p>
                <p>Even as entrenched structures dictate compression and containment in scholarly writing, the open networks of the web have enabled a publication model based on public sharing and collaboration, spurring a turn to process across the humanities. It has become normal for scholars of all fields to share their incipient, in-progress research on blogs and wikis, and look to the comments sections for peer review. On a larger scale, these moves toward a collaborative process of knowledge-making are visible in the editing policies of Wikipedia; in Femtechnet’s Distributed Open Content Course (DOCC), an open repository for course materials; and in new open access imprints like the Dead Letter Office of Punctum Books, which publishes abandoned scholarly projects (to name just a few examples among many). This turn to process has put pressure on the gatekeeping mechanisms described above, as many scholars yearn for a less rigid publishing model that foments the networked creativity of the wall.</p>
                <p>Advocating for the transformative effect of a process-oriented model of digital publication, this short paper asks: how can digital humanities not only embrace process rhetorically, but in fact accrete tangible value to the more piecemeal, contingent aspects of knowledge creation? How can we make it the wall’s scholarly sprawl “count” within systems that still rely on the trimmed and trussed-up products of research? How can we not only laud conceptually but help to build materially critical practices that eschew disciplinary (and disciplining) boundaries in favor of openings and traversals? </p>
                <p>After a brief survey of existing digital journals and other publishing initiatives, including 
                    <hi rend=""italic"">Hyperrhiz</hi>, Scalar, and Electric Press, we turn to our own incipient venture, titled 
                    <hi rend=""italic"">thresholds</hi>. 
                    <hi rend=""italic"">thresholds</hi> is a web-based digital publishing platform for creative scholarship, stitched together from existing digital humanities tools. By sketching the primary design features of 
                    <hi rend=""italic"">thresholds</hi> – both their theoretical motivations and technical solutions, described in brief below – this short paper argues for a capacious digital publishing model that negotiates, without dissolving, the shifting edges between reading and writing, process and product, the fragment and the collective.
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading2"">
                <head>Design Features</head>
                <p>The primary design feature of 
                    <hi rend=""italic"">thresholds </hi>is the split screen. On the webpage’s virtual verso are short critical essays that exceed disciplinary boundaries, whether it be in content, style, or approach. We solicit work that a traditional academic journal may deem unfinished, unseemly, or otherwise unbound, but which discovers precisely in its unboundedness new and oblique critical perspectives. Along with her essay, the author submits the textual, visual, and audible fragments that provoked and surreptitiously steered her work. These are published on the right side of the screen and scroll in tandem with the corresponding essay. These scraps are not explicitly harnessed to the work’s main body, but instead lie beside it to create provocative juxtapositions; it is left to the reader to forge lines of connection between recto and verso.
                </p>
                <p>Reinforcing its commitment to process and material form, 
                    <hi rend=""italic"">thresholds </hi>further provides a digital toolkit for readerly making. These tools assign names and haptic functions to those critical traversals that a reader makes through and against a text. As the author’s fragments scroll up the right-hand side of the screen, the reader can anchor a piece, holding it in place for future reference, or join one scrap to another to generate new patterns and co-movements. She can also import new material, either by copying text over from the essay on the verso or by composing additional fragments that leak new texts, artists, or ideas into the system. At the end of any given reading session, then, the reader will have generated her own “wall,” plucking, amassing, and recomposing the author’s fragments to create her own annotative assemblage.
                </p>
                <p>At any time, the reader can capture and conserve the “constellation” that she has produced—that is, the current arrangement of the fragments that she has chosen to lock and join together. Although every user has access to the same firmament of texts that cycle through 
                    <hi rend=""italic"">thresholds</hi>, each constellation will be singular; their unique spatial architecture will attest to the creative and critical value in visualizing the relations between fragments and texts, readers and authors, and readers and texts. Readers who choose to publically share their work will be able to see how their own creation fits into a galaxy of all other users’ constellations, mapping their own choices against that of a collective readership. By enabling the reader to place herself in relation to both the author’s text 
                    <hi rend=""italic"">and </hi>all other readers of the site, 
                    <hi rend=""italic"">thresholds </hi>models criticism as an intimate yet communal activity that inheres in the delicate links we build in the spaces between each other, as much as between the texts themselves.
                </p>
                <p>To ensure that this intervention is not only conceptually provocative but also formally useful, 
                    <hi rend=""italic"">thresholds</hi> endows each fragment with a flexible markup language. Readers can download their constellations, receiving a file listing all texts, objects, and art cited therein. This file can then be imported into citation software or shared with others. This underlying information architecture, not immediately present to visitors but baked into the structure of the site, plugs the swirl of scraps that make up any given constellation into the existing citational infrastructure of the humanities. In so doing, it allows 
                    <hi rend=""italic"">thresholds </hi>to negotiate the gap between that which is in-progress and incomplete within our reading practices—the stray underline, the forgotten marginal note—and more formalized and prescriptive methods for incorporating others’ work into our own. There is a place, 
                    <hi rend=""italic"">thresholds </hi>implicitly argues, for the fragmentary in our collecting and collective practices; for the wall’s sprawl within the more regimented systems that order our work.
                </p>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend=""bold"">Benjamin, W. (1999).</hi> 
                        <hi rend=""italic"">The Arcades Project</hi>, trans. Howard Eiland and Kevin McLaughlin. Cambridge: Harvard University Press.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Deleuze, G. (1988).</hi> 
                        <hi rend=""italic"">L'abécédaire de Gilles Deleuze, an interview with Gilles Deleuze, directed by Claire Parnet.</hi>
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Farina, L. (2014). Sticking Together. In Cohen, J. J., Joy, E. A., and Seaman, M. (eds), </hi>
                        <hi rend=""italic"">Burn After Reading/The Future We Want.</hi> Brooklyn: Punctum Books, pp. 31-38.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>
",xml,This text is republished here with permission from the original rights holder.,,creative critical scholarship;digital publishing,English,"audio, video, multimedia;authorship attribution / authority;creative and performing arts, including writing;cultural studies;interdisciplinary collaboration;knowledge representation;publishing and delivery systems"
3794,2017 - Montréal,Montréal,Access/Accès,2017-01-01T00:00:00Z,ADHO,ADHO,McGill University;Université de Montréal,Montréal,,Canada,https://dh2017.adho.org/,Lexos: An Integrated Lexomics Workflow,https://dh2017.adho.org/abstracts/054/054.pdf,Scott Kleinman;Mark D. LeBlanc,poster / demo / art installation,"Lexos is a browser-based suite of tools that helps lower barriers of entry to computational text analysis for humanities scholars and students. Situated within a clean and simple interface, Lexos consolidates the common pre-processing operations needed for subsequent analysis, either with Lexos or with external tools. It is especially useful for scholars who wish to engage in research involving computational text analysis and/or wish to teach their students how to do so but lack the time for a manual preparation of texts, the skill sets needed to prepare their texts analysis, or the intellectual contexts for situating computational methods within their work. Lexos is also targeted at researchers studying early texts and texts in non-Western languages, which may involve specialized processing rules. It is thus designed to facilitate advanced research in these fields even for users more familiar with computational techniques. Lexos is developed by the Lexomics research group led by Michael Drout (Wheaton College), Mark LeBlanc (Wheaton College), and Scott Kleinman (California State University, Northridge). It is built on Python 2.7-Flask microframework, with jQuery-Bootstrap UI, and visualizations in d3.js. The Lexomics research group provides access to an public installation of Lexos which does not retain data after a session has expired. Users may also install Lexos locally by cloning the GitHub repository.

Lexos guides users through a workflow of steps that reflects effective practices when working with digitized texts. The workflow includes: (i) uploading Unicode-encoded texts in plain text, HTML, or XML formats; (ii) “scrubbing” functions for consolidating preprocessing decisions such as the handling of punctuation, white-space, and stop words, the use of lemmati-zation rules, and the handling of embedded markup tags and special character entities; (iii) “cutting” texts into segments based on the number of characters, tokens, or lines, or by embedded milestones such as chapter breaks; (iv) tokenization into a Document Term Matrix of raw or proportional counts using character or word n-grams; (v) visualizations such as comparative word clouds per segment (including the ability to visualize topic models generated by MALLET); Rolling Window Analysis that plots the frequency of string, phrase, or regular expression patterns or pattern-pair ratios over the course of a document or collection; and (vi) analysis tools including statistical summaries, hierarchical and k-means clustering, cosine similarity rankings, and Z-tests to identify the relative prominence of terms in documents, document classes, and the collection as whole. At each stage in the workflow the user may download data, visualizations, or the results of the analytical tools, along with metadata about their preprocessing decisions or the parameters selected for their experiments. Lexos thus enables the export of data for use with other tools and facilitates experimental reproducibility.

Lexos {scrubber} An Integrated Lexomics Workflow

Scrubbing Options

Q Remove All Punctuation

B Keep Hyphens ©

Q Make Lowercase

B Keep Word-Internal Apostrophes©

Q Remove Digits

■ Remove Whitespace 0

B Scrub Tags 0

Additional Options

Stop Words/Keep Words O >


Previews of Documents


A1.3_Dan_T00030.txt




Gefr&ae;gn ic Hebreos eadge lifgean in Hierusalem goldhord d&ae;lan cyningdom hab ban swa him gecynde w&ae;s si&d;&d;an &t;urh metodes m&ae;gen on Moyses hand w

ealra gesceafta drihten and waldend se him dom forgeaf unscyndne bl&ae;d eor&d;an rices and &t;u lignest nu &t;&ae;t sie lifgende se ofer deoflum duge&t;um wealde&d;. A3.3_Az_T00130.txt


orn dryhten herede wis in weorcum ond &t;as Word acw&ae;&d;: Meotud allwihta &t;u eart meahtum swi&d; ni&t;as to nerganne. Is &t;in noma m&ae;re wütig ond wul h




Special Characters 0 v


Lemmas 0 v


Consolidations 0 v


Figure 1: The Lexos Scrubber Tool

Lexos addresses three significant challenges for our intended users. The first challenge involves the adoption of computational text analysis methods. Many approaches require proficiency with command line scripting or the use of complex user interfaces that require time to master. Lexos addresses this problem through a simple, browser-based interface that manages workflow through the three major steps of text analysis: pre-processing, generation of statistical data, and visualization. In this, Lexos resembles Voyant Tools (Sinclair and Rockwell, 2016), although Lexos places more emphasis on and providing more tools for preprocessing and segmenting texts. Lexos also shares with tools like Stylometry with R (Eder, et al., 2013; Eder, 2013) and emphasis on cluster analysis, providing both hierarchical and K-Means clustering with silhouette scores as limited form of statistical validation. While Lexos is not a topic modeling tool, it provides a useful “topic cloud” feature for MALLET data that will be useful for beginners since there are few accessible ways to visualize MALLET output that work well out of the box.


Figure 2: The Lexos Multicloud tool showing Chinese ""topic clouds""

The second challenge is the opacity of the procedures required to move between computational and traditional forms of text analysis. In order to reduce the “black boxiness” of algorithmic methods, Lexos contains an embedded component called “In the Margins” which provides non-technical explanations of the statistical methods used and effective practices for

handling situations typical of humanities data. “In the

Margins” is a Scalar “book” which can be read separately; however, its individual pages are embedded in Lexos using Scalar's API, making them easily accessible for users of the tool. Lexos shares with tools like Voyant an engagement with the hermeneutics of text analysis and attempts to embed “In the Margins” discussion of these issues in the user interface close to the user's workflow. We hope “In the Margins” will host advice and commentary from contributors with the Digital Humanities community.

A third challenge is the tension between quantitative and computational approaches and the traditions of theoretical and cultural criticism that dominate the humanities in the academy. As Alan Liu (2013) has recently argued, the challenge is to give a better theoretical grounding to the hybrid quantitative-qualitative method of the Digital Humanities by exploring the ways in which we negotiate the difficulties imposed by “the aporia between tabula rasa quantitative interpretation and humanly meaningful qualitative interpretation” (414). The design of Lexos and the discussions in “In the Margins” are intended to open a space for discussion of issues related to the opacity of algorithmic approaches and the limitations and epistemological challenges of computational stylistic analysis and visual representation of humanities data.

This poster presentation provides demonstrations of Lexos using some literature from Old, Middle, and Modern English, as well Chinese, which are in our current test suite. We also discuss use cases and best practices, how to install Lexos locally, and how scholars may contribute to the still growing content of “In the Margins”.

Bibliography

Drout, M., Kleinman, S., and LeBlanc, M. 2016-. “In the Margins.” http://scalar.usc.edu/works/lexos./

Eder, M. (2013). “Mind Your Corpus: Systematic Errors in Authorship Attribution.” Literary and Linguistic Computing 28 (4): 603-14.

Eder, M., Kestemont, M., and Rybiki, J. 2013. “Stylometry with R: A Suite of Tools (Abstract of Poster Session)”. Presented at Digital Humanities 2013, Lincoln, Nebraska. http://dh2013.unl.edu/abstracts/ab-136.html, https://sites.google.com/site/computationalstylistics/

Kleinman, S., LeBlanc, M.D., Drout, M. and Zhang, C. 2016. Lexos v3.0. https://github.com/WheatonCS/Lexos/.

Liu, A. (2013). “The Meaning of the Digital Humanities.” PMLA 128 (2): 409-23.

McCallum, A.K. (2002). MALLET: A Machine Learning for

Language Toolkit. http://mallet.cs.umass.edu.

Sinclair, S., and Rockwell, G. (2016). Voyant Tools. Web.

http://voyant-tools.org/.",txt,Creative Commons Attribution 4.0 International,,interdisciplinary;lexomics;stylometry,English,"authorship attribution / authority;computer science;interdisciplinary collaboration;literary studies;medieval studies;philology;stylistics and stylometry;teaching, pedagogy, and curriculum;text analysis"
3879,2017 - Montréal,Montréal,Access/Accès,2017-01-01T00:00:00Z,ADHO,ADHO,McGill University;Université de Montréal,Montréal,,Canada,https://dh2017.adho.org/,Access to DH Pedagogy as the Norm: Introducing Students to DH Methods Across the Curriculum and at a Distance,https://dh2017.adho.org/abstracts/186/186.pdf,Dan Tracy;Elizabeth Massa Hoiem,poster / demo / art installation,"This poster presents research into integration and assessment of digital humanities pedagogy in a distance course on the History of Children's Literature, and provokes conversation about pedagogical approaches that expand student access to DH methods, tools, and dispositions. Much of the existing literature on DH pedagogy addresses methods courses or multimodal writing courses rather than integration of DH practices in particular topical contexts, or advanced topics courses that explore a narrow slice of disciplinary content through extended engagements with digital projects (Ball 2012; Mostern & Gainor 2013; Fyfe 2016; Nyhan, Mahony, and Terras 2016). This literature provides valuable lessons but raises questions about the feasibility of engaging with DH across the curriculum in small-to-medium scale engagements with new methods and technologies. Amy E. Earhart and Toniesha L. Taylor (2016), for example, respond to this situation by rejecting the idea that DH should be limited to advanced courses and propose broader integration of “embedded [DH] skills development” that students can take out of the environment of a specific institution. Similarly, we suggest that allowing for repeated and diverse engagement by students across methods-intensive and topic-intensive courses (as is now common for writing) is necessary for teaching deeper DH dispositions like collaboration, openness to failure, and creativity with technology.

Simultaneously, the existing literature has focused on residential instruction with access to physical artifacts. This limit is problematic when at least one discipline with a heavy investment in DH, library and information science, is well past transition to a majority distance learning population. LIS programs have developed experience and expertise in teaching technology at a distance, and lessons from these programs may be useful to the DH community. While some teaching goals may only be met in person, others might be achieved through well-structured online learning.

To ground this discussion, the authors, the course instructor, and a subject librarian will present their development, assessment, and rethinking of a multimodal publication assignment using the Scalar platform in a synchronous online course on the History of Children's Literature. Students worked in groups to create a multi-media web resource on “diverse history.” The class discussed what is included or omitted from historical narratives, whether they be children's historical fiction or history textbooks, before contemplating this selection process in children's literature itself. The librarian introduced students to the context of DH publishing and Scalar, and to issues related to responsible use of multimedia. Then each group chose an issue related to “diverse history” and built one section of the website. The long-term goal is for successive classes to edit, revise, and expand this project

This collaborative project replaced an assignment from previous years, when students built individual websites about a children's book of their choice. This project maximized scaffolding, with detailed guidance on information students should locate about their books and the final website shape. This iteration of the class took place during a time when distance students came to campus one weekend each semester, and this time was used for in-depth introduction to the array of specialized library resources needed to complete the questions about their book's production and reception. The new assignment sought to re-imagine learning outcomes that would allow students to engage with a particular DH publishing technology, Scalar, and grapple with issues of collaboration and multimodal authoring in a context where the final product was less predetermined. Nonetheless, the elimination of the in person component, which occurred at the same time, removed an obvious “lab” opportunity for learning related technical issues. The pedagogical design involved making the best balance between asynchronous and synchronous activities to compensate for the absence of in person activities. Our evaluation of the success of the assignment relied on assessment

of Scalar sample sites and final projects created by the students, as well as on reflective essays written by the students and observations made in the course of student consultations. This evaluation led to ideas for how to revise the course for future semesters to improve learning of collaborative behaviors, openness to failure, and creativity with technology. This includes, most notably, a re-envisioning of how synchronous class time is used in the future.

By sharing our experiences in developing, teaching, assessing, and revising this course in successive iterations, we hope to explore with attendees the ways in which DH methods, tools, and dispositions can proliferate across the curriculum. We will promote discussion of what DH methods, tools, and dispositions can be taught well in different settings, whether that means varying scales of integration in DH classrooms, or exploring what can be taught virtually versus in person.

Bibliography

Ball, C. E. (2012). “Assessing Scholarly Multimedia: A Rhetorical Genre Studies Approach.” Technical Communication Quarterly 21: 61-77.

Earhart, A. E., and Taylor, T L. (2016) “Pedagogies of Race: Digital Humanities in the Age of Ferguson.” Debates in the Digital Humanities 2016. Ed. Matthew K. Gold and Lauren F. Klein. U of Minnesota P, Minneapolis. 251-64.

Fyfe, P. (2016). “Mid-Sized Digital Pedagogy.” Debates in the Digital Humanities 2016. Ed. Lauren F. Klein and Matthew K. Gold. University of Minnesota Press. 104-117.

Mostern, R., and Gainor, E.. (2013). “Traveling the Silk

Road on a Virtual Globe: Pedagogy, Technology and Evaluation for Spatial History.” Digital Humanities Quarterly

7.

Nyhan, J., Mahony, S., and Terras, M. (2015)“Digital Humanities and Integrative Learning.” Integrative Learning. Ed. Daniel Blackshields, James Cronin, Bettie Higgs, Shane Kilcommins, Marian McCarthy, and Anthony Ryan. London: Routledge. 235-47.",txt,Creative Commons Attribution 4.0 International,,children's literature;pedagogy;publishing;scalability;scalar,English,"audio, video, multimedia;copyright, licensing, and open access;cultural and/or institutional infrastructure;historical studies;library & information science;literary studies;project design, organization, management;rhetorical studies;teaching, pedagogy, and curriculum"
4163,2017 - Montréal,Montréal,Access/Accès,2017-01-01T00:00:00Z,ADHO,ADHO,McGill University;Université de Montréal,Montréal,,Canada,https://dh2017.adho.org/,German History-Digital: Platform for Transnational Historical Knowledge Co-creation,https://dh2017.adho.org/abstracts/607/607.pdf,Matthew Hiebert;Simone Lässig;Andreas Witt,"paper, specified ""short paper""","The German Historical Institute Washington (GHI) is in the development phase of German History-Digital (GH-D), a transatlantic digital initiative to meet the scholarly needs of historians and their students facing new historiographical and technological challenges. In the proposed paper we will discuss the research goals, methodology, prototyping, and development strategy of GH-D as infrastructure to facilitate transnational historical knowledge co-creation for the large community of researchers and students already relying on digital resources of the GHI and for the growing constituency of citizen scholars.

Despite its great progress, the digital humanities have yet to broadly impact research in German history. The past ten years have witnessed the proliferation of online resources relevant to the field, yet these materials largely remain siloed in different systems, with material difficult to discover or gather by scientists into corpora. Historians themselves are today increasingly producing scholarly content in digital form, but there remains no established criteria for the peer review of digital publications and projects. This ultimately limits the time and energy the research community is willing to invest into digital knowledge production and thus confines the Digital Humanities' potential for growth.

Preservation and future access to digital materials is also of critical importance, particularly in the North American context where continental and national digital research infrastructures for digital humanities are lacking; there is currently no equivalent to European research infrastructures like CLARIN or DARIAH. In respect to scientific methodology, there is growing expectation that historians take advantage of an abundance of digital tools, yet there remains insufficient integration between tools for historical research and between tool sets and online resources. The importance of citizen science and knowledge co-creation for the future of historical research is also recognized, yet for these developments to occur there must exist beyond e-lists and other legacy communication technologies scholarly environments for the creation of area-specific research communities, scientific collaboration, and public engagement.

The planning for GH-D involved surveying over four hundred scholars of the many thousands already using digital resources produced by the GHI. The most prominent of these resources is the digital source collection „German History in Documents and Images“ (GHDI), which is widely used at universities in the German and English speaking world. Launched in 2003 and currently undergoing a technical and conceptual revamp in conjunction with GH-D, GHDI currently includes thousands of pages of English-language translations of German historical texts, as well as images and maps, all of which are accessed by approximately 5,000 visitors per day. Our planning for GH-D also continues to involve consultations and workshops with expert historians and digital humanists, and the establishment of partnerships with institutions and major initiatives that share our concern for the future of history in the digital age.

The German History-Digital platform addresses needs of digital scholarship through five goals and integrated work packages concerted to these goals: discovery, analysis, production, preservation, and community.

We believe GH-D provides a new model in the design and development of a social knowledge creation environment for humanities-oriented research. The proposed paper will be structured by providing technical and theoretical explication of the core work packages within relevant DH contexts.

Discovery
A major challenge facing scholarship online is that a vast number of digital resources, particularly those produced independently by scholars or smaller institutions, do not have standardized metadata records and are not accessible via any centralized scientific index. GH-D involves development of a peer-reviewed index of scholarly digital objects using Dublin Core

(DC) and CLARIN's Component MetaData Infrastructure (CMDI) standards via a customized Backlight technology stack.

Preservation
For scholars developing historical digital projects in North America, there exists no inter-institutional infrastructure for preserving their data and making it openly available. With consultative and knowledge support from CLARIN-D, which is part of the European research infrastructure CLARIN, the GH-D project will establish the first portal to CLARIN in North America at GHI Washington. Central to this process is the implementation of a repository that allows a sustainable storage of the content and the inclusion in a digital environment to ease access, search and an interoperable data formats. The content of the repository and the repository itself adheres to international, widely accepted and supported standards. The high quality of the technical solution and the conformance to standards is secured by an independent organization that gives out the Data Seal of Approval. Like the majority of CLARIN centres in Germany, the GH-D will use a Fedora Commons repository with Apache Solr for indexing and search, components included in the technology stack of Project Hydra. Our partnership with CLARIN promotes open access, open science and knowledge co-creation in the North American context, and is an important component in the overall digital humanities research strategy of the GHI. As an institute of the Max Weber Stiftung, we are also in partnership with DARIAH-DE and arrangements have been made for DARIAH to provide long term preservation of GHI digital projects in their entirety, beginning with the first edition of German History in Documents and Images. Beginning with the GHDI project, GH-D is part of the DARIAH-DE Service Lifecycle program. Production and Publication

As a knowledge co-creation platform, GH-D will bring together editors, researchers and citizen scientists in the development of innovative online projects. Three such pilot projects are currently in development based on customization, including support for TEI, and internationalization of the Scalar 2.0 platform. GH-D is using Scalar 2.0 for the baseline content management system, particularly on account of its interface features, support for RDF, connectivity to external repositories, Dublin Core support. Hypothes.is integration, and its multiple path navigation system.

Analysis
Historians are increasingly using digital humanities tools to analyze data and express their research findings. A further advantage of storing digital objects within the CLARIN repository the GHI wants to built up is that the full range of corpus linguistic analytic tools of CLARIN can be applied by scientists to GHI textual content. During the first phase of the project we also look to prototyping connectivity to PARTHENOS, another major European infrastructure project. PAR-THENOS integrates within a virtual research environment (VRE) access to data from numerous national archives and a broad set of digital tools which can be chained together into analytic processing workflows. Community

The GH-D platform integrates blog aggregation, an advanced discussion system, community-oriented tools, and social media, to facilitate collaborative knowledge communities and open research. This is a pioneering aspect of our project that will investigate the adoption by historians of social and community digital tools in their research activities. We also intend to make use of the unique role the GHI plays as a hub of transatlantic scholarly dialogue and a major knot within an international network of historians in order to facilitate connections between different scholarly communities.",txt,Creative Commons Attribution 4.0 International,,history;infrastructure;knowledge creation;repository,English,"archives, repositories, sustainability and preservation;art history;german studies;historical studies;information architecture;knowledge representation;project design, organization, management;standards and interoperability"
6263,2018 - Mexico City,Mexico City,Puentes/Bridges,2018-01-01T00:00:00Z,ADHO,ADHO;EHD,El Colegio de México;Universidad Nacional Autónoma de México (UNAM) (National Autonomous University of Mexico),Mexico City,,Mexico,https://dh2018.adho.org/,Jumpstarting Digital Humanities Projects,,Amanda French;Anne Chao;Marco Robinson;Brian Riedel,workshop / tutorial,"<text>
        
            <div>
                <div>
                    Brief Summary
                    <p>“Jumpstarting Digital Humanities Projects” is a half-day pre-conference workshop on various aspects of beginning a digital humanities project: scoping and planning a sizable project; determining when to use institutional infrastructure and when to go beyond the institution; winning cooperation from institutional authorities and collaborators; collecting and digitizing materials; and designing for iterative development and efficient feedback loops. Our sessions will focus on the common type of digital humanities project that consists of a assembling a database of source material and generating interactive interpretations such as maps and visualizations from that database. Five scholars from different disciplines and institutions, each a participant in the Mellon-funded Resilient Networks for Inclusive Digital Humanities initiative, will give short tutorials, and workshop attendees will spend an hour on exercises in which they can begin planning a digital humanities project with help from the instructors.</p>
                    <p>Description of Content</p>
                    <p>“Jumpstarting Digital Humanities Projects” is a half-day pre-conference workshop on various aspects of beginning a digital humanities project: scoping and planning a sizable project; determining when to use institutional infrastructure and when to go beyond the institution; winning cooperation from institutional authorities and collaborators; collecting and digitizing materials; hiring students and technologists; and designing for iterative development and efficient feedback loops. Our sessions will focus on the common type of digital humanities project that consists of a assembling a database of source material and generating interactive interpretations such as maps and visualizations from that database. Five scholars from different disciplines and institutions, each a participant in the Mellon-funded Resilient Networks for Inclusive Digital Humanities initiative, will give presentations apiece of 30-45 minutes, and workshop attendees will spend an hour on exercises in which they themselves can begin planning their own digital humanities project with individualized help from the instructors. We will end the day with a brief group discussion on how humanities scholars at institutions without digital humanities centers can best form networks and advocate for infrastructure at their own institutions to support digital scholarship. </p>
                    <div>
                         Scoping and Planning
                        <p>Workshop leaders will discuss the collaborative and creative processes by which they determine what is achievable in a given project, and how they found the most optimal paths towards achieving their goals. These presentations will not be didactic but exploratory, the “leaders” having at this stage, on average, only begun to execute their workflows. This will provide an ideal space for attendees at various stages in their projects to feel invited to ask questions and contribute to strategies for determining what can be achieved within the specific constraints of budget, time, skills, and archival resources.</p>
                    </div>
                    <div>
                         Institutional and Extra-Institutional Infrastructure
                        <p>One of the major decisions projects have to make in their beginning stages is where to host content. Digital humanities projects of the type we are discussing in this workshop require a website, yet many if not most institutions do not provide server space for humanities scholars. Increasingly, libraries will host and manage digital humanities projects, but not all libraries provide this service, and those that have provided it in the past often find that as software and systems age, the cost in labor of maintaining digital humanities projects is a disincentive to provide such services for future projects. Commercial hosts such as GoDaddy and HostGator are one option, and an increasingly well-known option is Reclaim Hosting, founded by instructional technologists by and for educators, but many humanities faculty members are either not aware of these options or do not know how to choose between them. Workshop leaders will discuss their own choices and the relative advantages and disadvantages of each, balancing speed, efficiency, cost, support, sustainability, and longevity. </p>
                    </div>
                    <div>
                         Feedback loops &amp; iterative design
                        <p>Collaborative humanities projects depend on the gathering of diverse skills in the pursuit of complex goals. While it is difficult in institutional settings to achieve appropriate parity, this sort of cross-department and cross-strata project work can form alternative modes of collective intellectual labor that takes seriously the input of all stakeholders. The appropriate site for this integration of viewpoints in the context of project work is what we call “design.” By negotiating over what a thing does and how, a team comes to understand better what it is they are doing in the first place. A project often looks different at the end than it did in the earliest planning stages, and this aspect of the discussion will invite participants to think more creatively about the possibilities of interdisciplinary and inter-departmental collaboration.</p>
                    </div>
                    <div>
                         Achieving and Maintaining Buy-in
                        <p>The differences in institutional situations between the different groups represented by collaborating members in an interdisciplinary project necessarily create communicative friction and potential divergences in goals and perceptions. While this on some level represents differences in commitments, the perceived shared goal of any project is what brings collaborators to the table in the first place, and a flexible orientated-ness is what maintains buy-in. Workshop leaders will lead open-ended discussions about experiences in this process.</p>
                    </div>
                    <div>
                         Collecting and Digitizing Materials
                        <p>Many digital projects in the humanities begin with non-digital materials, such as the images and documents in the county archives of Waller County, Texas. Projects that include oral histories such as the Houston Asian American Archive now usually capture recordings in born-digital formats, but comprehensive archives of this nature may also need to convert analog audio and video materials from earlier eras. Libraries and archives have a great deal of knowledge about digitization and metadata standards and conversion and migration technologies that can be of use to humanities scholars, so partnering with library and archives professionals early on can be of great benefit. Workshop leaders in this section will discuss their practices with digitizing and collecting materials, especially in partnership with librarians.</p>
                    </div>
                </div>
                <div>
                     Description of Audience
                    <p>Humanities scholars in the early planning stages of large projects that require a broad array of technical and scholarly competencies. While Digital Humanities is of course a conference for advanced practitioners, we hope in this session both to entice “analog” humanities scholars to commingle with more experienced digital humanities scholars and to encourage experienced digital humanities scholars to think about how best to foster the spread of their methods.</p>
                </div>
                <div>
                     Technical Requirements
                    <p>This workshop requires a digital projector with audio capabilities, preferably one that can be used with instructor laptops: it requires no special software or hardware. We will expect attendees to bring laptops, and we hope that the workshop room will have sufficient power outlets for attendees.</p>
                </div>
                <div>
                     Length, Format, and Budget
                    <p>“Jumpstarting Digital Humanities Projects” will be a one-day workshop on the following schedule: </p>
                    <p>9am-12:30pm: Presentations of 20 to 30 minutes by course instructors</p>
                    <p>12:30pm-1:30pm: Lunch</p>
                    <p>1:30pm-3:30pm: Guided exercises in digital humanities project planning</p>
                    <p>3:30pm-4:15pm: Reflections on the day and discussion of institutional support needs for digital humanities projects</p>
                    <p>The Resilient Networks for Inclusive Digital Humanities project can fund the registration and travel of instructors. We would prefer a cost of no more than $25 USD for participants, especially since this workshop is meant to appeal chiefly to relative beginners in digital humanities.</p>
                </div>
                <div>
                     Workshop Leaders
                    <div>
                         Anne Chao
                        <p>Title: Manager, Houston Asian American Archive</p>
                        <p>Email: annechao@rice.edu</p>
                        <p>Phone: 713-202-5599</p>
                        <p>Address: 3970 Inverness Dr., Houston, TX 77019</p>
                        <p>Anne Chao is manager of the Houston Asian American Archive at Rice University. She oversees Rice student interns to conduct interviews with Asian Americans in Houston and the greater metropolitan area. Since 2010, HAAA has accumulated over 160 oral history interviews spanning diverse ethnicities from East, to Southeast, and South Asian-Americans. The collection of primary source materials details the contribution of Asian Americans in the building of greater Houston since the Jim Crow era, and provides new insight into the history of the region. Working with the archivist at the Fondren Library, HAAA uses the Omeka platform and includes GIS mapping to plot the life trajectories of the interviewees. The interviews are fully transcribed and time-stamped, synchronized, indexed with key words through the use of the Oral History Metadata Synchronizer (OHMS).</p>
                    </div>
                    <div>
                         Amanda French
                        <p>Title: Director, Resilient Networks for Inclusive Digital Humanities</p>
                        <p>Email: amandafrench@gwu.edu</p>
                        <p>Phone: 720-530-7515</p>
                        <p>Address: GWU Libraries, 2130 H Street NW, Washington, DC 20052</p>
                        <p>
                            <hi rend=""background(white)"" xml:space=""preserve"">Amanda French’s particular expertise consists of making humanities content (both cultural content and scholarly interpretation of that content) openly available online, as well as introducing scholars to the various methods of and issues with making humanities content openly available online. She held the CLIR Postdoctoral Research Fellowship at NCSU Libraries from 2004-2006. From 2010-2014, she was first Coordinator and later Principal Investigator for the Mellon-funded initiative THATCamp (The Humanities and Technology Camp), an international unconference that has seen more than 300 events to date attended by more than 7000 people. She often speaks and sometimes writes about open access, the scholarly publication landscape, Omeka, Scalar, Hypothes.is, THATCamp, the Digital Public Library of America, Wikipedia, grant-writing, and alternative careers for humanities PhDs. Her most recent digital research project is a catalog with accompanying exhibits of the personal library of the American poet Edna St. Vincent Millay, available at </hi>
                            <ref target=""http://steepletoplibrary.org"">
                                <hi rend=""background(white)"">http://steepletoplibrary.org</hi>
                            </ref>
                            <hi rend=""background(white)"" xml:space=""preserve"">. </hi>
                        </p>
                    </div>
                    <div>
                         Brian Riedel 
                        <p>Title: Professor in the Practice of Humanities; Associate Director, Center for the Study of Women, Gender, and Sexuality – Rice University</p>
                        <p>Email: riedelbs@rice.edu </p>
                        <p>Phone: 713-348-2162</p>
                        <p>Address: CSWGS, MS-38 | 6100 Main St | Houston, TX | 77005-1892</p>
                        <p>Brian Riedel received his Ph.D. in Anthropology from Rice University. His research and teaching focus on engaged research and lesbian, gay, bisexual, transgender, and queer social movements, particularly in Greece and the United States. Two of his current projects use GIS to examine the historical connections of place and sexuality. One project examines the histories of the Montrose neighborhood of Houston, Texas, and the uses to which they are put. A core component of that project is a GIS visualization of Houston’s LGBT-centered businesses from 1945 to 2015. The other project, conducted in collaboration with the African American Library at the Gregory School (part of Houston Public Library) and Rice Century Scholar Cameron Wallace, documents Houston's formal red-light district known as the ""reservation,"" which operated from 1908 to 1917. Although freed slaves had settled on that land since Emancipation, the city claimed the area held “only a few Negro huts.” The project uses GIS and StoryMaps to meld primary resources like census, city directory, and tax record data.</p>
                    </div>
                    <div>
                         Marco Robinson
                        <p>Title: Assistant Professor of History, Prairie View A &amp; M University, Prairie View, Texas</p>
                        <p>Email: mtrobinson@pvamu.edu</p>
                        <p>Phone: 936-261-3219</p>
                        <p>Address: Division of Social Work, Behavioral, and Political Sciences, Prairie View A&amp;M University, P.O. Box 519; MS 2203, Prairie View, TX 77446-2203</p>
                        <p>Marco Robinson is an Assistant Professor of History at Prairie View A &amp; M University, Prairie View, Texas. Marco’s research is centered around capturing the social, political, economic, and cultural histories of communities in the American South through collecting, preserving, and analyzing archival and oral history data. As it relates to digital humanities, Dr. Robinson uses this data to tell digital stories, for mapping using GIS and the digitization of historical artifacts. His most recent publication and project are ""Telling the Stories of Forgotten Communities: Oral History, Public Memory, and Black Communities in the American South"" (Collections: A Journal for Museum and Archives Professionals, Volume 13, Number 2, (Spring 2017): 171- 184.) and Using Interactive Maps and Apps to Preserve Local History: Digitizing the Black Experience in Waller County, Texas.</p>
                    </div>
                </div>
            </div>
        
    </text>",xml,Creative Commons Attribution 4.0 International,,databases;digitization;project management;project planning;visualization,English,"asian studies;digitisation, resource creation, and discovery;english;gender studies;historical studies;interface & user experience design/publishing & delivery systems/user studies/user needs;project design, organization, management;visualization"
6419,2018 - Mexico City,Mexico City,Puentes/Bridges,2018-01-01T00:00:00Z,ADHO,ADHO;EHD,El Colegio de México;Universidad Nacional Autónoma de México (UNAM) (National Autonomous University of Mexico),Mexico City,,Mexico,https://dh2018.adho.org/,Transatlantic knowledge production and conveyance in community-engaged public history: German History in Documents and Images/Deutsche Geschichte in Dokumenten und Bildern,,Matthew Hiebert;Simone Lässig,poster / demo / art installation,"<text>
        
            <p>This poster presents the technical redesign of the web resource 
                <hi rend=""italic"">German History in Documents and Images/Deutsche Geschichte in Dokumenten und Bildern</hi> (GHDI) as a transatlantic knowledge production and conveyance model for community-engaged public history. It is a multilingual project led and based at the German Historical Institute Washington (GHI) in partnership with DARIAH-DE, the Max Weber Foundation, and the University of Southern California. It was awarded a three-year development grant from the German Research Foundation/Deutsche Forschungsgemeinschaft (DFG) in 2017. We display the project’s theoretical foundations and aims, the resulting technical design, and report on the proof-of-concept phase and first-year of development.
            </p>
            <p>GHDI was first conceived in 2002 by a group of academic historians who sought to make a large collection of German historical documents openly available online in German and English translation. GHDI would consist of ten chronological volumes to cover German history from 1500 to 2009, each of which includes an introduction and a selection of historical documents, images, and maps, accompanied by interpretations. The site currently contains 1,784 German documents (along with an equal number of English translations), 2,374 images, and 55 maps (for a total of 16,068 pages), with content being expanded in the revamp. The project has developed a large and diverse international community of users, registering approximately 100,000 unique visitors a month.</p>
            <p>The reconceptualization and revamp of the GHDI includes the encoding of original and new materials in TEI P5, Dublin Core metadata for all content, a site-wide co-created bibliography, and a scholarly annotation system. The integration of, and project development contributions to, 
                <hi rend=""italic"">Scalar</hi>—a robust open-source authoring, editing, and publishing platform with support for RDF content—allows users to navigate content in diverse ways and along various critical historiographical paths, challenging “master narrative” approaches to German history. The Scalar adapters developed by the project will link a number of important German archives to English-speaking scholarly communities for the first time, and the GHDI platform will ultimately allow users to use and “mix” this and other content to produce their own and collaborative scholarly outputs.
            </p>
            <p>Data resources of the project are being described using Dublin Core metadata vocabulary.  Sources with annotations or other semantic enhancement adhere to TEI (Text Coding Initiative) P5 using the DTA base format.  Linked-open data representations are being be stored in RDF-XML.  Using Scalar’s built-in API, all content will be made available directly via URL-based requests in RDF-XML.  This is also the technical basis for user content ""remixing"" and user publication facilitation being developed within the GHDI environment. Authority control for personal names and other entities, both in consumption and publication, will be assured through GND and similarly broadly accepted standards.  Resources suitable for language analyses tools conform to Component MetaData Infrastructure (CDMI) as prescribed by CLARIN-DE data centers.   Geographic data is being encoded in GeoJSON.   All data will be published to prioritize permissiveness of use under Creative Commons licensing. </p>
        
    </text>",xml,Creative Commons Attribution 4.0 International,,community engagement;german studies;history;public history,English,"audio, video, multimedia;cultural and/or institutional infrastructure;english;german studies;historical studies;knowledge mobilization;multilingual / multicultural approaches"
6453,2018 - Mexico City,Mexico City,Puentes/Bridges,2018-01-01T00:00:00Z,ADHO,ADHO;EHD,El Colegio de México;Universidad Nacional Autónoma de México (UNAM) (National Autonomous University of Mexico),Mexico City,,Mexico,https://dh2018.adho.org/,Mid-Range Reading: Manifesto Edition,,Grant Wythoff;Alison Booth;Sarah Allison;Daniel Shore,panel / roundtable,"<text>
        
            <div type=""div1"" rend=""DH-Heading"">
                Overview
                <p>This panel intervenes in debates about interpretative methods that are often lumped under “reading,” and often measured by metaphors of scale, from close to distant. Mining data in vast corpora promises to transform literary history, and all scholars in the humanities rely upon online materials and tools. Yet many humanists stand aloof from DH because of its presumed hyperbolic claims, its apparent blurring of the detailed artifact (the domain of humanities), and to some, its collusion, post-critique, with neo-liberal globalization. Four panelists, collaborating for the first time, have encountered provocative concepts in each other’s work that moderate such stark oppositions between the humanist and the computational. The panelists’ previous studies have demonstrated the “payoff” or mutual instruction of DH and other recognized standards of scholarship. At the same time, in meticulous capture of language, style, form, and cultural production, the panelists highlight the limits that some champions of algorithms might want to leap in a single bound. Technological approaches to literary studies require highly curated corpora and modulation, often excision, of noisy results. Each paper addresses the loss inherent in categories and models, and the gain in tracing discarded, fuzzy, or inaccessible data. While our fields span centuries of Anglophone culture, our work advocates diversity, women’s history, and the DH community’s values of open access and collaborative technological innovation.</p>
                <p>Our papers address disruptions as well as continuities in observational scale as the tools and materials shift. Each panelist speaks from experience with a different dataset and her or his innovative approach to interpretation, touching on both language and technology. The first two speakers propose forms of mid-range reading to describe imaginative and interpretive leaps that scholars make between individual documents/texts and broader social forces; the second two address the reductions and abstractions that are necessary to the research project, themes common to all papers. As an archeologist of technologies, Wythoff rediscovers the concept of the gadget as an instance of human-inanimate interaction mirrored in DH. Booth expands on her response in 
                    <hi rend=""italic"">PMLA </hi>to Franco Moretti’s 
                    <hi rend=""italic"">Distant Reading</hi>, highlighting typologies as well as specific textual features in biographical nonfiction that enforce communal narratives. Allison, co-author on Stanford Lit Lab pamphlets associated with distant reading, proposes reductive reading, or explicit acknowledgment of necessary simplification, even of such ambitious problems as the nature of fictionality, which has been differently framed in studies by Piper, Underwood, and Eliot. While concepts of scale pervade claims for methods, Shore offers the approaches of construction grammar and corpus linguistics for particular insights into abstractions and categorizations. Shore, like Allison, calls on us to acknowledge the motivated reductions that are necessary to the research process. Our talks reflect on the history of technology and biographical representation, the forms of fiction and nonfiction, and the preconditions of selection and labeling of data—enduring issues in the humanities that become more telling with the expanding digital capacity to “read” at large and at speed.
                </p>
                <p>Grant Wythoff, Tacit computing and method in the humanities</p>
                <p>Humanistic research has always involved imaginative and interpretive leaps from the person to ""the social,"" from the text to ""the historical."" Think for instance of the Annales school and its emphasis on the history of collective mentalities, or how Foucault described ""discourse"" by reverse-engineering historical ways of constituting knowledge. Today however, with the availability of big data, many of these forms of humanistic interpretation have become second nature. The search for broad cultural formations is implicit in the earliest steps we take in a research project, from keyword searches to frequency analyses. To what degree are certain kinds of historical argumentation baked into these mundane, day-to-day research activities, and what other kinds of cultural formations might we be overlooking?</p>
                <p>In my current book project, 
                    <hi rend=""italic"">Gadgetry: A History of Techniques,</hi> I reconstruct the history of a discourse on technology. The book focuses on the many kinds of objects that were described as ""gadgets"" across the twentieth century, from dashboard gauges to atomic bombs, can-openers to smartphones. While “gadget” can be a placeholder for any kind of object, even imaginary ones, I argue that its evolving application to particular tools and techniques reveals important lessons about our relationship to technology.
                </p>
                <p>In this book, I explore the user's imagination of how their gadgets work. For example, a single iPhone contains over half the elements of the periodic table, extracted from almost every continent on the planet and compressed into a thin slab that allows the user to dip her toes into a river of collective affect generated by the social network of everyone she's ever met. This is a fantastically science-fictional experience that is now part of our everyday lives. But the emergence of new digital cultures, political movements, and forms of intimacy are all predicated on the unique habits each user adopts in order to understand these complex gadgets.</p>
                <p>For this book, I text mine archives of novels, magazines, and newspapers in order to explore the distinctly vernacular philosophies––the media theories from below––that emerge from users and their everyday practices. Using databases like the Corpus of Historical American English, Historical American Newspapers, and the Media History Digital Library, I proceed by collecting as many instances of the word ""gadget"" as possible and plugging them into categories of my own making based on how the term is applied: is the gadget handmade or mass produced, seen as important or a trinket, does the word refer to the entirety of the tool or a component within it, and so on. Because I have hand-coded this ""dataset"" and designated myself the categories into which I sort each instance of the word, the portrait that emerges of a discourse on technology could be described as entirely of my own making, as opposed to algorithmically-generated. But what really is the distance between these two categories of interpretation? In this talk, I will compare my digital methods to other methods throughout the history of the humanities that have attempted to paint a portrait of collective feeling.</p>
                <p>Alison Booth, Mid-Range reading: typologies, events, and discourse in a network of women’s biographies</p>
                <p>Although many investigate fictionality, scholars have attended much less to nonfiction and biography than to imaginative forms such as novels or film. Digital humanities (DH) expand the scale of literary history while building on existing maps of period, genre, and notable authors, with finding aids shaped by previous scholarship. Thus Andrew Piper’s impressive textual analysis, “Fictionality,” neglects life narrative. Collective Biographies of Women (CBW) accesses a corpus of 1270 English-language biographical collections published across centuries, in a feminist historical study of a “hidden collection” of nonfiction. CBW developed before Google Books glimmered on the horizon; we worked with WorldCat and analogue materials to rediscover such publications as 
                    <hi rend=""italic"">Noted Negro Women</hi> (1893). Reversing the usual DH phases, I published the book before collaborating on an online resource. What could we learn about the trends in gender ideology already constructed by biographers and publishers, publication data, and contents? Biography is a model (i.e. reduction) of a life within networks of typologies based on social difference. Distant reading is not best adapted to ramifications within curated corpora, where there is no mystery of author or genre. We capture the distinctive form and rhetoric of biography (and changing meaning of words such as “noble”) in relation to such scenarios as inter-class contact or recognition of genius. Sentiment analysis or word vectors developed for large corpora of novels or newspapers would miss the mark. The actual dynamics of gender representation, for example, can hardly be captured as a grammatical binary or by rates of male or female agents per 300 words, while nationality is a shifting attribute across geopolitical and individual transformations.
                </p>
                <p>This paper extends Booth’s “Mid-range reading: not a manifesto” and builds on the findings from CBW’s method of mid-range reading as well as from the typologies and networks of women in the CBW database. CBW researchers are tagging discourse in biographies, such as first-person plural and plural proper names, and quantifying the distribution of types of events across versions of the same person or occupational types. Both scales of reading and typologies press upon ethics as well as epistemology: how to classify the individual text, or the character/person. Attention must be paid, yet cognition and knowledge depend on generalizations. CBW has focused on sets of books that document the ways women’s lives have been typologically interpreted. Our “sample corpora” range from all the books that include a short life of the saintly Victorian nurse, Sister Dora, and the distinct set of books that feature the famous adventuress, Lola Montez; other networks cluster around Queen Cleopatra, Frances Trollope, African Americans, women in medicine, Latinas, presenters (publishers, biographers), and others among the 8500 persons. A method we call mid-range reading uses the Biographical Elements and Structure Schema (BESS), a stand-aside XML schema (not TEI editing within the text file) that links element types (of stage of life, events, discourse, persona description, topos) to numbered paragraphs. BESS analyses, then, measure rates and distributions of element types across versions of lives sorted typologically by the contents of interrelated books. In 2018 we will obtain TEI files of remaining texts, with non-consumptive use of the copyright materials, through the HathiTrust Research Center. Becoming in this sense an archive as well as a testing ground for narrative theory of biography and network analysis across centuries of representation of women, CBW can demonstrate the comparative rewards of large-scale textual analysis and mid-range reading, and add to the understanding of biographical representation in many forms.</p>
                <p>Sarah Allison, Harnessing Pegasus: On Setting Reasonable Limits</p>
                <p>This paper takes up a theoretical question in digital humanities practice: how we understand the borders or boundaries of projects. “Reductive reading” is my term for critical methods that call attention to how they subordinate, or reduce, textual complexity. I argue that the explicit way with which DH research acknowledges this act of simplification creates an ethos of critical frankness. As Stephen Ramsay argues, code must “assert its utter lack of neutrality with candor, so that the demonstrably non-neutral act of interpretation can occur.” “Harnessing Pegasus” focuses on the poignant question of setting limits. How do researchers establish the right distance from the texts under consideration, or reduce the scope of their inquiry? Here, I consider how researchers set limits in three projects that aim to understand what we might take to be the constitutive feature of the novel: fictionality.</p>
                <p>It is axiomatic that the most irritating questions after a talk--but often also the best--are those that deal with a project’s limits. Researchers announce what they have done, and the members of the audience say, Ah, but why didn’t you do something else? This practice can help establish that one has taken a reasonable approach to a legitimate question in the field or open up future possibilities for research. It can also bring home the importance of narrowing one’s approach in order to answer a specific question, as in We 
                    <hi rend=""italic"">didn’t </hi>do something else. We did the thing we did. In sharing work publically, researchers are called to account for the boundaries they have set--or, as it is often framed, that they have been forced to set.
                </p>
                <p>It is the latter attitude that interests me here, the moment when the scalar ambitions of distant reading meet pragmatic reality and intellectual justification. Mid-range reading leaves space to account for both. In this paper, I will consider three approaches to fictionality in literary history: by Andrew Piper in 
                    <hi rend=""italic"">Cultural Analytics</hi>,
                    <hi rend=""italic""> </hi>by Ted Underwood, Michael L. Black, Loretta Auvil, and Boris Capitanu in their work on genre in the HathiTrust Digital Library, and by Simon Eliot in his bibliographic work on trends in publishing, 1800-1914. In considering the way each project treats its limitations, I seek to create connections--bridges--across them. How do their definitions of fictionality intersect with Catherine Gallagher’s theoretical treatment of the topic, and what that that tell us about nonfictionality? In each of these three studies, non-fiction is represented by a discrete collection of texts. How does limiting the generic canon change the way we understand fictionality?
                </p>
                <p>Dan Shore, Other than Scale</p>
                <p>This paper explores the limits of the concept of scale in digital inquiry. Quantitative scholars in particular have naturally chosen scale as what sets their approach apart from other established methods. They speak of the computer as a “macroscope” that permits “macroanalysis.” Scholars counted things before computers, but computers let them count and compute lots of things. Contrasting themselves with close readers, distant readers propose, with the help of machines, to step back from the page to see more and see bigger. Claims of scalar difference are often quite quantitatively precise. Instead of offering a reading of a single novel, distant readers study the titles of 7,000 British novels from 1740-1850, or ask how not to read a million books, or search through the 60,237 full texts in EEBO TCP I and II. For nearly all quantitative analyses of texts, the authors could tell the reader exactly how many words they count in how many documents, in light of sophisticated metrics and models.</p>
                <p>Talk of scale in the digital humanities has not been simply ill advised. In spite of quantitative precision, we don’t really know what we talk about when we talk about scale. Individual texts are much bigger than are usually acknowledged. Even when bag-of-words approaches are forthright about discarding word order and syntax, they rarely itemize what they are discarding. What has been characterized as an increase in scale can be more accurately described as the sacrifice of one sort of information for another. The point is not to oppose reductionism, but to be fully aware of what is being reduced.</p>
                <p>Scalar conceptualization of digital tools and methods has tended to crowd out other, non-scalar distinctions. Some, like experimental design, theories of evidence, and falsifiability (an account of what it would mean to be wrong) should be more prominent in the conversation. I’ll focus on concepts - abstraction, categorization, hierarchy - that are central to meaning and linguistic creativity across languages. Here I turn to the insights of construction grammar and corpus linguistics to suggest further possibilities for investigation. The bigram 
                    <hi rend=""italic"">thought leader </hi>is two words, but it is also a single compound noun, the meaning of which can’t be fully predicted from the meaning of its parts. How big is it? An abstract construction like 
                    <hi rend=""italic"">Once upon a time… [] and they lived happily ever </hi>after may be only ten words, and yet as big as the fairy tale that fills its blank. How long is it? The relevant distinctions in these examples are not scalar in any simple sense, and the methods for understanding them cannot be captured by distance or proximity. I start with linguistic examples at the level of the utterance, propose a few ways forward for qualitative and quantitative inquiry, and close by suggesting how the non-scalar distinctions at work in construction grammar might be relevant for specifically literary questions such as genre and narrative form.
                </p>
            </div>
        
        <back>
            <div type=""bibliogr"">
                <listbibl>
                    Bibliography
                    <bibl>Allison, Sarah. 
                        <hi rend=""italic"">Reductive Reading: A Syntax of Victorian Moralizing</hi>. Baltimore: Johns Hopkins University Press, forthcoming 2018.
                    </bibl>
                    <bibl>Allison, Sarah. “Other People’s Data: Humanities Edition,” 
                        <hi rend=""italic"">Cultural Analytics</hi>, Dec. 8, 2016. 
                        <ptr target=""http://culturalanalytics.org/2016/12/other-peoples-data-humanities-edition/""></ptr>
                    </bibl>
                    <bibl>Bode, Katherine. “The Equivalence of ‘Close’ And ‘Distant’ Reading; Or, toward a New Object for Data-Rich Literary History.” 
                        <hi rend=""italic"">Modern Language Quarterly</hi> 78, no. 1 (March 1, 2017): 77–106,
                        <ref target=""https://doi.org/10.1215/00267929-3699787""> </ref>
                        <ptr target=""https://doi.org/10.1215/00267929-3699787""></ptr>.
                    </bibl>
                    <bibl>Booth, Alison. 
                        <hi rend=""italic"">How to Make It as a Woman: Collective Biographical History from Victoria to the Present</hi>. Chicago: University of Chicago Press, 2004.
                    </bibl>
                    <bibl>Booth, Alison. “Mid-Range Reading: Not a Manifesto.” 
                        <hi rend=""italic"">PMLA </hi>132: 3 (May 2017): 620-27.
                    </bibl>
                    <bibl>Burguiere, Andre. 
                        <hi rend=""italic"">The Annales School: An Intellectual History</hi>. Trans. Jane Marie Todd. Ithaca, NY: Cornell University Press, 2009.
                    </bibl>
                    <bibl>Eliot, Simon. “Some Trends in Book Publishing, 1800-1914” in John O. Jordan and Robert L. Pattern (eds.), 
                        <hi rend=""italic"">Literature in the Marketplace</hi>. Cambridge: Cambridge University Press, 2003.
                    </bibl>
                    <bibl>Eliot, Simon, and Jonathan Rose, eds. 
                        <hi rend=""italic"">A Companion to the History of the Book</hi>. Malden, MA: Wiley-Blackwell, 2009.
                    </bibl>
                    <bibl>Gallagher, Catherine. 
                        <hi rend=""italic"">Nobody’s Story: The Vanishing Acts of Women Writers in the Marketplace, 1670-1820. </hi>Berkeley, U. of California P, 1994. 
                    </bibl>
                    <bibl>Gallagher, Catherine. “The Rise of Fictionality.” 
                        <hi rend=""italic"">The Novel</hi>. Ed. Franco Moretti, Vol. 1. Princeton: Princeton UP, 2006. 336-63. 
                    </bibl>
                    <bibl>Goldberg, Adele E. 
                        <hi rend=""italic"">Constructions at Work: The Nature of Generalization in Language. </hi>New York: Oxford UP, 2006.
                    </bibl>
                    <bibl>Goldberg, Adele E. 
                        <hi rend=""italic"">Constructions: A Construction Grammar Approach to Argument Structure</hi>. Chicago: U of Chicago P, 1995.
                    </bibl>
                    <bibl>Hancher, Michael. “Re: Search and Close Reading,” in 
                        <hi rend=""italic"">Debates in the Digital Humanities 2016</hi>. University of Minnesota Press, 2016. 118–38.
                        <ref target=""http://conservancy.umn.edu/handle/11299/181603""> </ref>
                        <ptr target=""http://conservancy.umn.edu/handle/11299/181603""></ptr>.
                    </bibl>
                    <bibl>Langacker, Ronald W. 
                        <hi rend=""italic"">Cognitive Grammar: A Basic Introduction</hi>. Oxford: Oxford UP, 2008.
                    </bibl>
                    <bibl>Nunberg, Geoffrey, Ivan A. Sag, and Thomas Wasow. “Idioms,” 
                        <hi rend=""italic"">Language</hi> 70 (1994): 491–538.
                    </bibl>
                    <bibl>Piper, Andrew. “Fictionality.” 
                        <hi rend=""italic"">Journal of Cultural Analytics</hi>, December 20, 2016.
                        <ref target=""https://doi.org/10.22148/16.011""> </ref>
                        <ptr target=""https://doi.org/10.22148/16.011""></ptr>.
                    </bibl>
                    <bibl>Robertson, Stephen, and Lincoln Mullen. “Digital History &amp; Argument White Paper – Roy Rosenzweig Center for History and New Media.” November 13, 2017. https://rrchnm.org/argument-white-paper/.</bibl>
                    <bibl>Shore, Daniel. 
                        <hi rend=""italic"">Cyberformalism: Histories of Linguistic Forms in the Digital Archive</hi>. Baltimore: Johns Hopkins UP, forthcoming 2018.
                    </bibl>
                    <bibl>Shore, Daniel. “Shakespeare’s Constructicon,” 
                        <hi rend=""italic"">Shakespeare Quarterly</hi> 66.2 (2015): 113-136.
                    </bibl>
                    <bibl>Smith, Barbara Herrnstein. “What Was Close Reading? A Century of Method in Literary Studies,” 
                        <hi rend=""italic"">Minnesota Review</hi> 87 (2016): 57–75.
                    </bibl>
                    <bibl>Underwood, Ted. “Distant Reading and the Blurry Edges of Genre. ” 
                        <hi rend=""italic"">The Stone and the Shell. </hi>22 Oct. 2014.
                    </bibl>
                    <bibl>Underwood, Ted. “Understanding Genre in a Collection of a Million Volumes, Interim Report.” Figshare.
                        <ref target=""https://dx.doi.org/10.6084/m9.figshare.1281251""> </ref>
                        <ptr target=""https://dx.doi.org/10.6084/m9.figshare.1281251""></ptr>
                    </bibl>
                    <bibl>Wythoff, Grant. 
                        <hi rend=""italic"">Gadgetry: A History of Techniques</hi>, in progress.
                    </bibl>
                    <bibl>Wythoff, Grant. 
                        <hi rend=""italic"">The Perversity of Things: Hugo Gernsback on Media, Tinkering, and Scientifiction</hi>. University of Minnesota Press, 2016.
                    </bibl>
                </listbibl>
            </div>
        </back>
    </text>",xml,Creative Commons Attribution 4.0 International,,corpus linguistics;distant reading;fictionality;history of technology;models,English,criticism;digital humanities history;encoding - theory and practice;english;epistemology;historical studies;linguistics;literary studies;text analysis;theory
6517,2018 - Mexico City,Mexico City,Puentes/Bridges,2018-01-01T00:00:00Z,ADHO,ADHO;EHD,El Colegio de México;Universidad Nacional Autónoma de México (UNAM) (National Autonomous University of Mexico),Mexico City,,Mexico,https://dh2018.adho.org/,Conexiones Digitales Afrolatinoamericanas. El Análisis Digital de la Colección Manuel Zapata Olivella,,Eduard Arriaga,"paper, specified ""short paper""","<text>
        
            <p>Las manifestaciones afrolatinoamericanas y sus conexiones con el mundo digital han comenzado a generar un creciente interés en diversos campos de estudio: las humanidades digitales, los estudios culturales, literarios y antropológicos entre otros. A pesar del interés, el estudio de tal intersección se encuentra en una etapa inicial debido a factores como a) las limitaciones de acceso a herramientas digitales por parte de algunos agentes y comunidades identificadas y auto-identificadas como afrolatinoamericanas/afrolatinas; b) limitaciones en la consecución de derechos de autor de algunas piezas y manifestaciones cuya distribución e intercambio digital se hace más difícil; y c) falta de innovación en la forma de clasificar piezas y manifestaciones que, en muchos casos, no coinciden con la tradición letrada que subyace al proceso de archivo ya sea digital o no. Tales limitaciones han hecho más difícil la consolidación de propuestas analíticas que, desde las humanidades digitales, den cuenta del estado y evolución de las culturas afrolatinoamericanas, así como de sus aportes a nivel de conocimiento en espacios locales, regionales y globales. </p>
            <p>Algunas formas de revertir dichas limitaciones ha sido el desarrollo de iniciativas y colecciones digitales por parte las mismas comunidades afrolatinoamericanas en cooperación con entidades académicas, agencias multilaterales, gubernamentales, intergubernamentales y no gubernamentales. Tales iniciativas muestran la diversidad de manifestaciones generadas desde dichas comunidades; manifestaciones que son fundamentales para su identificación, visibilización y, sobre todo, consideración dentro de un modelo de justicia social que, como el contemporáneo, se centra en el reconocimiento de los derechos humanos. Asimismo, dichas adaptaciones tecnológicas se convierten en una forma de lo que Steve E. Jones determina como ‘eversion” (Jones, 2016) o la consolidación de unas realidades híbridas entre lo digital, lo análogo y lo performático. Algunos de los proyectos más importantes en este ámbito son, entre otros, Digital Portobelo, Mueseu Afro Digital Río de Janeiro o Proyecto Afrolatin@, a partir de los cuales se hacen evidentes diversas formas de ser afrolatinoamericano, así como diversas formas de representación y expresión de sujetos cuya identificación intersecta varios espacios discursivos, políticos y de acción. Algunos de los puntos positivos de dichas plataformas y colecciones es que a) son espacios en constante construcción –actuales y constantemente actualizados- y b) permiten ver procesos de acceso, creatividad, justicia simbólico-social que las comunidades están persiguiendo y han perseguido por largo tiempo. Sin embargo, el carácter de construcción constante de dichas plataformas es, al mismo tiempo, un aspecto negativo dado que el flujo de información se convierte en un desafío para unas humanidades digitales cuyo modelo se ha centrado en la digitalización y análisis de información canónica, única, extraordinaria (Manovich, 2016). Las plataformas generadas por parte de esas comunidades afrolatinoamericanas, por el contrario, registran el flujo de la cultura en el presente que no ha sido propiamente abordado por las humanidades ya sean análogas o digitales. En el caso de la intersección entre estudios afrolatinoamericanos y estudios digitales, el proceso de análisis ha estado mucho más rezagado no solo por la falta de bases de datos o de construcción de archivos digitales, sino por la falta de interés y apoyo para construirlos y, a partir de allí, desarrollar metodologías innovadoras de análisis (Gomez, 2011). </p>
            <p>De acuerdo con el panorama descrito, esta presentación corta dará cuenta del proceso de investigación e implementación metodológica llevado a cabo a partir de 
                <hi rend=""italic"">Manuel Zapata Olivella Collections</hi>, una colección digital desarrollada por la biblioteca de la Universidad de Vanderbilt. Manuel Zapata Olivella fue uno de los escritores y activistas afrolatinoamericanos más importantes del siglo XX, cuya obra y pensamiento han influido al movimiento afrolatinoamericano contemporáneo. Sus cartas, manuscritos y documentación personal como escritor, artista y activista habían quedado en un archivo personal manejado por su familia. Sólo hasta el 2008 la Universidad de Vanderbilt adquirió el fondo y desarrolló una colección digital en el cual se hacen visibles varios de sus documentos y proyectos tanto etnológicos como antropológicos. Entre los archivos digitalizados se encuentran los documentos –cartas, panfletos, memorias, comunicaciones personales, fotografías y audios- del 
                <hi rend=""italic"">Primer Congreso de Cultura Negra de las Américas</hi>, realizado en Colombia en 1978. El proyecto, llevado a cabo con apoyo de la Universidad de Indianápolis, consistió en el análisis digital de dicha documentación y del Congreso como uno de los nodos centrales de la acción política, literaria y cultural afrolatinoamericanas del siglo XX y XXI. El proyecto buscaba a) responder preguntas tales como: ¿Cuáles fueron las redes artísticas y textuales que permitieron la emergencia del Congreso?, ¿Cuáles fueron los discursos socio-culturales latinoamericanos con los cuales el congreso desarrolló un diálogo y logró establecer su propio conjunto de valores y códigos para explicar lo afrolatinoamericano?, ¿Cuáles de los valores políticos y estrategias estéticas creadas y adoptadas por el Congreso devinieron patrones de acción y fueron transmitidas al movimiento afrloatinoamericano de la era digital?. Asimismo, el proyecto buscaba b) desarrollar propuestas metodológicas digitales para comenzar a entender la complejidad e interconexión –en tiempo y espacio- del movimiento afrolatinoamericano. Esta última actividad se desarrolló a través de la implementación de mapas de tópicos y el uso de plataformas digitales para visualizar la información de forma inter-relacional –Vg. Scalar, Wandora, Gephi, etc.-, considerando la diversidad de materiales en el ecosistema informativo de la tradición afrolatinoamericana. 
            </p>
            <p>La presentación entonces mostrará los resultados de esa investigación a través del mapeo de textos, de agentes, instituciones y sistemas de valores relacionados para, finalmente, conectarlo con las propuestas ideológicas fundamentales del movimiento afrolatinoamericano surgido de la Conferencia Mundial Contra el Racismo realizada en Durbán en 2001. A través de esta presentación se discutirán no solamente los hallazgos de la investigación en particular sino, sobre todo, las perspectiva de unas humanidades digitales afrolatinoamericanas que, aunque se incluyan en las discusiones regionales (RedHD, Humanidades digitales en Latinoamérica) intentan ir más allá, en busca de la conexión entre activismo e investigación académica con un objetivo claro: la justicia social y la descolonización del conocimiento.</p>
        
        <back>
            <div type=""bibliogr"">
                <listbibl>
                    Bibliografía
                    <bibl>
                        <hi rend=""bold"">Gómez F. P</hi>. (2011). La colección Manuel Zapata Olivella. 
                        <hi rend=""italic"">Revista de estudios colombianos</hi>, 37-38: 117-118.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Jones E. S.</hi> (2016). The Emergence of the Digital Humanities. 
                        <hi rend=""italic"" xml:space=""preserve"">Debates in the Digital Humanities, </hi>University of Minnesota Press. 
                        <ref target=""http://dhdebates.gc.cuny.edu/debates/text/52"">http://dhdebates.gc.cuny.edu/debates/text/52</ref>
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Manovich, L</hi>. (2016). The Science of Culture? Social Computing, Digital Humanities and Cultural Analytics. 
                        <hi rend=""italic"">Journal of Cultural Analytics</hi>. Doi: 
                        <ref target=""https://doi.org/10.22148/16.004"">
                            <hi rend=""italic underline color(0000FF)"">10.22148/16.004</hi>
                        </ref>
                    </bibl>
                </listbibl>
            </div>
        </back>
    </text>",xml,Creative Commons Attribution 4.0 International,,afrolatino;digital analysis;topic maps,English,black studies;cultural studies;data mining / text mining;digital activism and networked communities;diversity;literary studies;spanish;spanish and spanish american studies
9380,2020 - Ottawa,Ottawa,carrefours / intersections,2020-01-01T00:00:00Z,ADHO,ADHO,Carleton University;Université d'Ottawa (University of Ottawa),Ottawa,Ontario,Canada,https://dh2020.adho.org/,"Situated Materialities, Object Agency and Resistant Bodies in Subalternized Craft: Neoliberal Market/Tourist Logics and Questions around what/why of the “decolonializing” of digital humanities",,Radhika Gajjala;Rhiannon Bettivia;Taylar Stagnar;Rustina Untari,"paper, specified ""long paper""","This paper draws on ethnographic work in various indigenous and international contexts of digital archiving and on research in subaltern craft communities to think through the ontic/epistemic imaginaries (Verran, 2001) and the issues surrounding the inclusion of subaltern craft communities in digital global space either through museumizing or entrepreneurial promises of reaching global markets. In doing so, we raise questions regarding the scalar politics of “authenticity” from local to supranational contexts while problematizing notions of “untouched” cultural products.",txt,This text is republished here with permission from the original rights holder.,,archiving;lost objects;memory;metadata;Weaving,English,asia;comparative (2 or more geographical areas);contemporary;cultural analytics;english;ethnographic analysis;feminist studies;first nations and indigenous studies;north america
9821,2019 - Utrecht,Utrecht,Complexities,2019-01-01T00:00:00Z,ADHO,ADHO,Utrecht University,Utrecht,,Netherlands,http://staticweb.hum.uu.nl/dh2019/dh2019.adho.org/index.html,Scholarly Multimedia Editions for Theatre Studies,,Miguel Escobar Varela;Bernard Arps,"paper, specified ""long paper""","<text>
        
            <p>Theatre ‘constitutes itself through disappearance’ (Phelan 1993) and its ephemerality poses methodological problems for researches. Before the twentieth century, most theatre scholarship focused exclusively on texts, whether they were produced before or after a performance. This is true for many theatre traditions around the world (including Javanese theatre, the case study in this paper). A textual model of theatre has serious limitations, as many of the social and improvised aspects of performance are rarely reflected in the texts. Audiovisual documents constitute better (if still imperfect) records, but they have yet to be adopted as authoritative critical editions in theatre studies. Several online platforms offer full length recordings of key theatre performances (for example digitaltheatreplus.com), but they don’t usually include the level of detailed annotation found in literary editions, where individual words or phrases are annotated to report their genesis, elucidate interpretations and trace variations across versions. Audiovisual theatre resources are often accompanied by interviews with performers or introductory notes, but there are no standard formats to annotate specific moments in a performance (the intonation of a word, the movement of a performer, the laughter of the audience) and explain their significance within larger historical and cultural contexts. A scholarly infrastructure for the critical annotation of audiovisual documents has yet to emerge, even though relevant resources and technologies exist. We suggest that a digital philology of performance can be used to imagine new formats for scholarly analysis and communication, at the intersection of theatre studies and digital humanities.</p>
            <div type=""div1"" rend=""DH-Heading"">
                Why philology?
                <p>Conventionally, philology has been associated with the study of literary material and the production of textual editions. However, the principles of philology can be used to interpret all aspects of a theatre performance: the audiovisual, social, and kinesthetic aspects of a performance can all benefit from a philological perspective. Theatre studies tends to be presentist, placing emphasis on novelty rather than tradition (Arps 2016). A philological perspective offers a principled method to study the historical layering of a performance (contemporary performance included), countering this narrow focus on the present. There are many ways in which a text-based philological edition of a performance can document the emergent, interactive and multimedia aspects of a performance, by using notational conventions to represent vocal parameters (an approach pioneered by Tedlock in 1978), tinkering with the spatial arrangement of text on a page, and using extensive notes to describe emergent and interactive aspects of a performance. However, the potential of philological editions can be more fully realized in digital editions that can combine audiovisual sources with careful philological attention. </p>
                <p>There are calls for born-digital scholarship in performance studies (Mee 2018) in response to impressive growth of digital archives that offer full-length recordings of performances around the world (Caplan 2016). However, the authoring platforms suggested by Mee (such as blogs or Scalar) are not sufficiently malleable to accomplish the level of critical attention required by a scholarly, multimedia edition of performance. For example, it is important for scholars to link specific sections of audiovisual media to textual transcription and translations, in ways that transcend subtitles. These different media should all be amenable to meticulous cross-reference and annotation in ways that are sustainable, findable and reusable. There is no straightforward way to achieve these objectives with most available tools. How does a digital edition of a theatre performance look? What should it seek to achieve? Textual editions are standard critical objects that have benefited from a long history of continuous experimentation in both print and born-digital formats. There is an extensive corpus of influential digital editions and an extensive literature that explores how digital editions modify and continue traditions of textual editing (for example Dsicoll et al. 2016). But this level of experimentation and theoretical discussion has yet to be extended to multimedia editions in theatre studies. </p>
                <p>To sketch a prototype for such scholarly, multimedia editions, the present authors embarked on a collaborative journey of creativity and discussion. Both authors have an interest in the Javanese tradition of wayang kulit (shadow puppet theatre). A has worked as a scholar of Javanese language and culture for more than three decades; B is an early-career digital humanities scholar and web developer. In 2016, A published a philological, annotated translation of the work of an influential wayang kulit artist, based on the recording of a performance. The first version of this translation was published in book format. A and B are currently collaborating on an interactive, multimedia version of this translation. The development of a digital portal for this purpose is not just a matter of ‘adding’ audiovisual materials but a dialogical experimentation with the format and possibilities of a digital philology of performance.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading"">
                Conceptualizing multimedia editions
                <p>Spatz (2015) suggests that video can document several aspects of performance, such as training (2015). Although he refers to these videos as ‘editions’, it is unclear how they constitute scholarly interventions. As Sahle (2016) notes, an edition without additional material that makes the document understandable or accessible is just a facsimile or an item in an archive. A critical attitude is required to determine what additional materials are required, and how they should be included. Their inclusion should follow rules derived from the relevant scholarly context, and these rules should be transparently and rigorously applied. An example from A’s print edition is that the symbol • indicates that the dhalang (the puppet-master in wayang kulit) knocks a mallet against a wooden box. The specific sequence of such knocks is of great significance to a performance: it might constitute a cue to the gamelan musicians or indicate that a different personage is speaking, while also contributing to the aural aesthetic of the performance. The transcription of these sounds is surrounded by explanations, and linked to detailed notes (indicated by the symbol ⓐ). For example:</p>
                <quote>[T]he dhalang raps the puppet chest to signal an accelerando and sforzando in the gamelan. ⓐ At the appropriate point in the structure of the piece he raps the pattern •• • as a cue to the gamelan to play slowly and pianissimo. </quote>
                <p>In the print version, the symbols substitute for the experience of listening to the actual sounds of these rhythmical pattern. In the multimedia version, the passage above is time-linked to the recording. The user can play the recording, and the appropriate segment of the transcript will be highlighted in a different color (Fig. 1). The user can also click on any portion of the transcript to navigate trough the audiovisual recording. This description is no longer a stand-in for an absent sound, but an interpretive scholarly layer. People who are not familiar with the tradition might not be able to identify the •• • pattern just by listening to the recording. Thus, the co-presence of audio and annotation, linked through time-based playback directs the attention of the users, making the material more accessible, understandable and usable for future research. </p>
                <p>This example shows that even the simplest inclusion of audiovisual material is never just an appendage. The audiovisual material changes the function and potential of scholarly annotation. We are at the early stages of discovering the full implications of linked transcripts, annotations and audiovisual documents. Besides producing a specific web portal for this wayang kulit performance, we are documenting our process and producing an open-source software package that can be adapted by other scholars to tackle the problems a performance philology poses for other theatrical traditions.</p>
                <p>We aim to develop tools that are usable by theatre scholars (even if they are not interested in web development) in ways that are citable, reusable and sustainable. The transcripts, translations and annotations of our edition are all TEI-complaint and we are working with both an academic publisher and a digital archive to preserve our edition and to manage its metadata records. We are also committed to making our materials available as data: this will enable the perusal of the materials online through customizable portals, as well as their eventual integration within computational, data-driven research projects. We believe that more collaborative work on this area will open new avenues for the digital transformation of theatre scholarship. </p>
                <p>
                    <figure>
                        <graphic url=""Pictures/8bd380d911c3811245a6d289597c4705.png""></graphic>
                    </figure>
                </p>
                <p>Figure 1. As the recording plays, the appropriate section of the transcript is highlighted.</p>
            </div>
        
        <back>
            <div type=""bibliogr"">
                <listbibl>
                    Bibliography
                    <bibl>
                        <hi rend=""bold"">Arps, B.</hi> (2016). 
                        <hi rend=""italic"">Tall Tree, Nest of the Wind: The Javanese Shadow-Play Dewa Ruci Performed by Ki Anom Soeroto: A Study in Performance Philology</hi>. ( Book, Whole). Singapore: NUS Press.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Caplan, D.</hi> (2017). Reassessing Obscurity: The Case for Big Data in Theatre History. 
                        <hi rend=""italic"">Theatre Journal</hi>, 
                        <hi rend=""bold"">68</hi>(4): 555–73 doi:
                        <ref target=""https://doi.org/10.1353/tj.2016.0106"">10.1353/tj.2016.0106</ref>.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Mee, E.</hi> (2018). Born-Digital Scholarship. 
                        <hi rend=""italic"">TDR/The Drama Review</hi>, 
                        <hi rend=""bold"">62</hi>(3): 8–9.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Phelan, P.</hi> (1993). 
                        <hi rend=""italic"">Unmarked: The Politics of Performance</hi>. London; New York: Routledge.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Sahle, P.</hi> (2016). What is a Scholarly Digital Edition?. 
                        <hi rend=""italic"">Digital Scholarly Editing</hi>, vol. 4. 1st ed. (Theories and Practices). Open Book Publishers, pp. 19–40 
                        <ptr target=""http://www.jstor.org/stable/j.ctt1fzhh6v.6""></ptr> (accessed 23 February 2018).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Spatz, B.</hi> (2015). 
                        <hi rend=""italic"">What a Body Can Do: Technique as Knowledge, Practice as Research</hi>. London and New York: Routledge 
                        <ptr target=""http://www.routledge.com/books/details/9781138854109/""></ptr> (accessed 22 June 2017).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Tedlock , Dennis</hi> (1978). 
                        <hi rend=""italic"">Finding the Center. Narrative Poetry of the Zuni Indians</hi>. Lincoln: University of Nebraska Press.
                    </bibl>
                </listbibl>
            </div>
        </back>
    </text>",xml,This text is republished here with permission from the original rights holder.,,digital philology;indonesia;multimedia editions;theatre studies;wayang kulit,English,"audio, video, multimedia;english;film and performing arts studies;open content and open science;oriental and asian studies;scholarly editing;scholarly publishing"
9893,2019 - Utrecht,Utrecht,Complexities,2019-01-01T00:00:00Z,ADHO,ADHO,Utrecht University,Utrecht,,Netherlands,http://staticweb.hum.uu.nl/dh2019/dh2019.adho.org/index.html,"""Building community"" at the National and/or International Level in the Context of the Digital Humanities",,Adeline Joffres;Mike Priddy;Francesca Morselli;Fatiha Idmhand;Thomas Lebarbé;Caroline Abéla;Xavier Granier;Mehdi Chayani;Paul Bertrand;Xavier Rodier;Christophe Parisse;Céline Poudat;Véronique Ginouvès;Fabrice Melka;Michael Sinatra;Emmanuel Château-Dutier;Jason Camlot;Stéfan Sinclair;Gimena Del Rio Riande;Paula Ricaurte;Isabel Galina Russel;José Francisco Barrón Tovar;Ernesto Priani Saisó;Martin Grandjean;Aurélien Berra;Olivier Baude;Stephane Pouyllau,panel / roundtable,"<text>
        
            <p style=""text-align:left; "">Knowledge production has always act globally, and when it comes to the humanities early networks of scholars can still be traced in their letter correspondence. With the emergence of digital humanities more prominently in the 1970s, research communities have organized themselves in many different ways. The enthusiasm generated by the promises of what was sometimes perceived as a ""new field"" were to some extent echoed in new forms of institutionalization, to the point of defining a discipline in its own right. But the enthusiasms was also accompanied by a certain resistance of communities reluctant to introduce digital technology into their field.</p>
            <p style=""text-align:left; "">The term of ""digital humanities"" in these earlier days of adopting digital methods into the humanities created an area, a niche, inside which pioneers in Digital Humanities could gain critical mass. Today, where digital methods are far more widely applied, one can observe an almost opposite trend, the abandoning of a ‘specific label’ and a much broader advocacy concerning all humanities. </p>
            <p style=""text-align:left; "">What remains specific for DH communities is the close alliance between content providers (which themselves are in a process of digitisation content and access), humanities scholars applying digital methods, and computer scientists linking to new methodological achievements in their field. However, this alliance can express itself in very different forms of national and international organisation, and is far from following a specific model.</p>
            <p style=""text-align:left; "">This panel examines different ways of ""forming a community"" among digital humanities scholars and scholars in other fields, and other actors in DH. The contributions span a range from generic ways to design digital research infrastructures in the SSH, over national solutions to supranational coordination</p>
            <p style=""text-align:left; "">The purpose of this panel is to unfold the diversity of the current ""digital humanist movement”, not only to compare, but also to understand what is at stake for the actors involved and what impact the different forms of organisation have on creation and evolution of research communities. We further discuss issues of cohesion and durability. Through the papers presented, we will examine the impact of bottom-up, top-down and horizontal strategies as well as the adoption of hybrid solutions (organizational, disciplinary, methodological, scalar) in the design of research communities. This approach will allow us to put convergences and challenges into perspective and to question the re-compositions at work within SSH communities. </p>
            <p style=""text-align:left; "">This panel will highlight the experiences of SSH research communities from different cultures and organizations rooted at different levels of governance, such as some French communities structured around institutional nodes such as Maisons des Sciences de l'Homme (MSH), or research infrastructures at the national (TGIR Huma-Num) or European level (DARIAH ERIC); project based collaboration of research infrastructures (DANS, The Netherlands) and Canada (CRIHN); and professional networks and transnational associations related to digital humanities (e.g. Humanistica, the French-speaking association of digital humanities, or the Latin American network for digital humanities under construction). The comparison of the experiences presented will not produce a homogeneous and smooth image but will highlight differences in approaches and organisation. Even it seems nearly impossible to give account of every association that could be representative on a way to build community in DH, the chair of the session will make an introduction with a brief summary of this landscape. That said, besides the geographical aspect that we try to include, another is that we are giving voice to formal and informal associations such as the LatamHD network, that is just at an early stage and that is not yet defined in its goals. We decided to propose several solutions to deal with the diversity of needs and practises inside our communities and we wanted to present some of them to share our experiences and initiate discussions during this panel in order to develop collaborations with colleagues sharing the same kind of constraints.</p>
            <p style=""text-align:left; ""> </p>
            <p style=""text-align:left; "">Thus, the objective is to have a broad discussion with the audience to broaden the perspectives to other experiences.</p>
            <p style=""text-align:left; ""> </p>
            <p style=""text-align:left; "">This panel aims to contribute to the reflective work in the wider DH context about factors of constitution, consolidation and evolution of its research communities
                <hi style=""font-size:12pt"">.</hi>
            </p>
            <div type=""div1"" rend=""DH-Heading1"">
                
                    <hi rend=""background(white)"">Talk 1 = “Architecting the Digital Humanities”</hi>
                
                <p style=""text-align:left; "">
                    <hi rend=""background(white)"">The Digital Humanities is a broad church of different communities, each with differing methodologies, approaches to data creation, and data processing; developed organically over time. For cross-community communication and interaction there must be a common form in which to describe the communities and their components. Understanding commonalities and differences is key to the successful building of infrastructures, and especially for distributed transnational supra-community research infrastructures. The creation of international e-infrastructures such as the European Research Infrastructure Consortium (ERICs) such as DARIAH-EU and CESSDA (and others on the ESFRI roadmap) to provide services to broad designated communities means that there is the need to comprehend what form topic specific communities take in order to gather and support them in an efficient manner.</hi>
                </p>
                <p style=""text-align:left; "">This paper will present three architectures, from the abstract to the concrete, created in, and for, humanities e-infrastructures. At the most abstract level is the Reference Model for the Social Sciences and Humanities Data Infrastructures (RM-SSH), a deceptively simple high-level model which can be used to model everything from a researcher with their laptop to a distributed ERIC. The second architecture, the DARIAH Reference Architecture (DARIAH-RA) was created to systematically and formally describe contributions to this e-infrastructure. As such it can be used to describe contributed activities and services as diverse as summer schools and conferences to resource creation and data hosting. The DARIAH-RA is built upon the foundation of the RM-SSH. The most concrete of the architectures is that of the European Holocaust Research Infrastructure (EHRI) which currently describes the metadata processing and ingest of archival descriptions and controlled vocabularies into an aggregating portal, both manually and automatically. This information architecture (EHRI-IA) includes process workflows to aid understanding for sustainability as members of the community change over time.</p>
                <p style=""text-align:left; "">
                    <hi rend=""background(white)"">All three architectures, due to their nature of describing distributed infrastructure systems and communities, use a common model: the Reference Model of Open Distributed Processing (ODP-RM). This provides a framework to describe the architecture of open, distributed, processing (ODP) infrastructures; whenever possible ODP-RM uses a formal description technique to specify the architecture, in order to guarantee the consistency and reliability of the description.</hi>
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                
                    <hi rend=""background(white)"">Talk 2 = “Growing Communities in the Arts and Humanities. The case study of the DARIAH-EU Working Groups”</hi>
                
                <p style=""text-align:left; "">DARIAH-EU is the European research infrastructure for the arts and humanities. In 2016 it was recognised as an ERIC and it comprises 17 Members and several Cooperating Partners in eight non-member countries. The activities of DARIAH comprise four main strands, namely: 1. training and education; 2. resources, tools and methods made available by and for the research community; 3. policy and advocacy support (on topics such as open science); and finally, 4. a growing transnational community of researchers.</p>
                <p style=""text-align:left; "">This paper will focus on the fourth aspect and aims at exploring the case study of the DARIAH-EU Working Groups (henceforth WG) as a model in which research communities organize themselves, given the boundaries and the assets provided by a research infrastructure such as DARIAH. The DARIAH-EU WG are transnational, grass-rooted, self-organized, collaborative groups which have their roots in existing communities of practice. They form the heart of the DARIAH-ERIC community, but at the same time they maintain the existing ties with the (national and local) institutions where the WG members are based.</p>
                <p style=""text-align:left; "">The creation of new DARIAH WGs follows the need of communities to foster innovative scholarly practices and to provide the infrastructure to support them. In turn, participation in existing WGs is a means to consolidate infrastructure and scholarship in certain areas of research, and to create or reinforce the network of expertise inside DARIAH. The WG level enables an organizational structure which is not just flexible and dynamic, but also driven by feedback and as such it helps DARIAH to be sustainable. Furthermore the value of the working groups lies in the fact they allow a better alignment between research institutions functioning on a national basis (universities, data centers, data archives, libraries, archives, projects etc…) and the research interests that emerge in international collaborations - the WGs are therefore able to optimize their own research environment by harnessing both national and international horizons. </p>
                <p style=""text-align:left; "">In addition, the work of the WGs is considered so central in the development of the Research Infrastructure that in 2017 DARIAH-EU established a funding scheme to provide financial support for their activities, including travel to WG meetings, core developments such as the creation of tools, policy documents or dissemination material. </p>
                <p style=""text-align:left; "">This paper will therefore examine the European landscape of the DARIAH WGs, firstly by charting their evolution since 2015 and secondly, by identifying those dynamics of the research community that are the basis for successful collaboration, exchange of information and experiences. </p>
                <p style=""text-align:left; "">This presentation also aims to reflect on what the challenges are in the creation and maintenance of such dispersed communities, and therefore it wishes to contribute to a fruitful discussion with other national and international experiences.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                
                    <hi rend=""background(white)"">Talk 3 = “Building Community"", the Example of French Consortia Labelled by the TGIR Huma-Num in SSH”</hi>
                
                <p style=""text-align:left; "">Based on a review of nearly 10 years, this communication aims to reflect on the factors that led to the construction and development of consortia as the fabric of an emerging digital humanities community in France.</p>
                <p style=""text-align:left; "">
                    <hi rend=""background(white)"">The invention of a national infrastructure, partly based on consortia in France by the TGIR Huma-Num, was an original way of responding to the difficulties of the human and social sciences community in keeping pace with the rapid development of the digital humanities. Starting from the needs, uses and practices of higher education and research stakeholders, consortia have brought together communities from different scientific fields around common challenges. Thus, in 2010, the TGIR Huma-Num launched a call for the creation of consortia around disciplines and/or objects, materials or research data articulated around a human and technological device supported by services.</hi>
                </p>
                <p style=""text-align:left; "">
                    <hi rend=""background(white)"">In five years, 10 consortia have been proposed and validated by the Huma-Num Scientific Council (2 in linguistics, 1 on the corpus of authors in the broad sense, 1 in geography, 1 in ethnology, 1 around medieval sources, 1 in political sociology, 1 in archaeology, 1 on musical data and 1 in relation to the use of 3D in SHS).</hi>
                </p>
                <p style=""text-align:left; "">
                    <hi rend=""background(white)"">The ways in which these communities have been built and the forms they have taken vary, depending on the context in which they emerged and the nature of the research communities they represent. For example, the Consortia Archives des Ethnologues and ImaGEO started from the objectives of processing and promoting the data of researchers whose resource centres and libraries are depositaries. These consortia were thus constituted by focusing on the promotion of collections and their scientific and public mobilization, while other consortia, such as CAHIER, focused on the corpus of authors and their editorial enhancement to give rise to new research, while others are oriented towards a technology and the ensembles created from it, such as the 3D consortium. Still others have preferred to open up to a wide range of documentary typologies and very diversified modes of exploitation, trying to bring together large user communities, such as the COSME consortium dedicated to the study of medieval sources, or the CORLI consortium bringing together linguists and their work on corpora.</hi>
                </p>
                <p style=""text-align:left; "">Each of them has its own mode of governance, internal dynamics and distinct inclusion capacities, but this hybridity has proved to be a strength in working together on issues that cut across all consortia (i.e. data interoperability, legal and ethical issues, pedagogical issues, etc.), which involve them in a transdisciplinary way. In this respect, the FAIR principles are real assets for ensuring the coherence of projects - in particular on legal and ethical issues, long-term preservation or data feedback to civil society. </p>
                <p style=""text-align:left; "">Dialogue on the digital practices of communities and the transmission of knowledge exchanged or acquired within consortia is now a real challenge at European and international level. New practices that need to be articulated at different levels are emerging, and consortia are the incubators.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                Talk 4 = “Leveraging Digital Humanities Centers: The Case of the Centre de recherche interuniversitaire sur les humanités numériques in Canada”
                <p style=""text-align:left; "">As Neil Fraistat powerfully argues in Matthew K. Gold’s collection of essays 
                    <hi rend=""italic"">Debates in the Digital Humanities</hi>, digital humanities centers have become important laboratories for the application of information technology to humanities research; powerful advocates for the significance of such work; crucial focal points for the theorization of the digital humanities as a field; and local nodes for cyberinfrastructure, or e-science (281). The Centre de recherche interuniversitaire sur les humanités numériques (CRIHN) was founded in Québec in the fall of 2013 in order to offer a new structure for over sixty researchers from seven universities working on various aspect of digital culture. These researchers come from various disciplinary backgrounds, primarily in the humanities but with some in social sciences (mainly communication and information studies), but they all have in common a theoretical and practical knowledge of digital humanities that, put under one roof, allow to take the full measure of the digital turn that is characteristic of our times. 
                </p>
                <p style=""text-align:left; "">With the series of change to forms and models of publications, the way that information is created, shared, and consulted has undergone some fundamental changes in the last two decades. What is thus required is not only a reconceptualization of a theoretical understanding of digital culture but also the implementation of a series of new tools for disseminating information, for finding it through data mining techniques, for long-term preservation, but also to visualize this mass of data, be it textual, sound-based or visual. These tools should be developed by and for humanities scholars, and be at the same time studied for the way in which they transform future research as well.</p>
                <p style=""text-align:left; "">The CRIHN provides a space for engaging these topics on these two levels along the two axes found at the core of the Center’s mandate: “Theorizing the Digital” and “Instruments of knowledge”. The first axis focuses on a theoretical framework for understanding the goals and major shifts that have occurred in digital culture, and offer conceptual tools for describing these changes, specifically in the context of research dissemination. The second axis of the centre has as its main goal to assist researchers in transforming in a very concrete fashion the way they create, analyze, visualize, and disseminate humanities research. </p>
                <p style=""text-align:left; "">The CRIHN thus allows a group of researchers to make visible our concept of a platform that can combine discoverability tools with organizational and analytical ones, as well as the modern forms of scholarly dissemination which include an actual social network that goes beyond the use of social media to actually create a live community of researchers that are already involved at the individual level in various projects related to the impact of digital culture on scholarly methods for creating, studying, and disseminating research output.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                
                    <hi rend=""background(white)"" xml:space=""preserve"">Talk 5 = </hi>
                    <hi rend=""background(white)"" style=""font-size:10.5pt"">#LatamHD</hi>
                
                <p style=""text-align:left; "">Latin America is much more than one of the largest and most diverse regions in the world; it is a symbolic construction that broadly covers Mexico and the countries of Central America, South America and the Caribbean. Latin America’s historical, sociocultural, geographical, economic, and political heterogeneity also reflects the organization of communities of practice with different realities and needs. The recent history of Digital Humanities --as Humanidades Digitales, HD-- in Latin America reflects the growing institutional interest and the promotion of initiatives aimed at the professionalization of academics and the opening of programs, curricula and spaces. On the one hand, there is interest in promoting collaboration and cooperation in the region but on the other, there is no consensus on how this could become a regional reality (not only a local one), as every country in the region has different institutional organizations and priorities. Much of the discourse has focused on “shared problems”, such as obsolete infrastructures, the lack of a grant funding system for the Humanities and disparities in digital literacy among students and scholars. It is important however to also consider shared “strengths” that could allow the development of the field in the region in order to provide both solutions to our problems as well as innovative and unique knowledge within our complex landscape.</p>
                <p style=""text-align:left; "">Over the past years individuals and associations have discussed possible forms of cooperation in order to build bridges and promote collaboration in Latin America HD. In 2018, during the Digital Humanities Conference held in Mexico City, a meeting was held to discuss the creation of a regional network that could integrate the different experiences that are emerging in Latin America and the Caribbean and continued, some months later, at the HD Conference of the Asociación Argentina de Humanidades Digitales in Rosario, Argentina. These meetings were useful to discuss initial ideas not only about the importance of creating a network but also reflections on what this should look like, what characteristics it should have and how this would differ from other DH networks around the world.</p>
                <p style=""text-align:left; "">LatamHD now faces the challenge of defining a shared ethos that can guide the future of HD in the region towards its own character, taking our situated practices and context into account. There is a strong conviction that the HD must assume a fundamental commitment to impact research into cultural objects from a renewed and critical perspective that may not coincide with the methods and practices of Anglophone Digital Humanities. This presentation will be a state of the art of the HD context in Latin America and the Caribbean and will describe LatamHD as a common initiative with some shared next steps and challenges. In particular we will discuss how LatamHD could follow the minka spirit (mink'a or minga in Quechua, minca of Quechua minccacuni, ""request help promising something""), in the sense of a pre-Columbian tradition of community and voluntary work with social and reciprocal purposes. For example, the minka may have different purposes for a community, such as the construction of public buildings or helping a person or family, when harvesting or doing other agricultural activities, always with a recompense for those who have helped. The benefit of one should be the benefit of all.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                Talk 6 = When language structures the community: the case of Humanistica
                <p style=""text-align:left; "">Founded in 2014, the Francophone association of digital humanities Humanistica occupies a special position in the landscape of DH communities. However, the international – and even intercontinental – nature of the association is neither a way of distinguishing itself from most of the other national or regional organizations nor the affirmation of the unity and the primacy of a research culture beyond the borders of France, the country most naturally associated with this language. The reason for this broad spectrum is simply that the association has been created as a grassroots movement on the basis of an already existing community that brought together DH actors from a wide variety of French-speaking areas. </p>
                <p style=""text-align:left; "">It is indeed in 2010, during THATCamp Paris, that a “Manifeste des Digital humanities” was written. This fundamental text for Francophone DH rapidly saw the number of its signatories reach more than 250 individuals and institutions. If this first stage of structuring laid the foundation for a common discourse within this growing community, it is after THATCamp Lausanne (2011), Florence (2011) and especially Paris (2012) that many expressed the wish to see the collaboration strengthened within an association. It is then at THATCamp Saint-Malo (2013) that a first provisional committee was elected, before the official founding at DH2014 in Lausanne. Such an obvious link with the philosophy of these “un-conferences”, whose participants often come from many disciplinary, professional and institutional horizons, explains the very broad opening of Humanistica. Its first committee included representatives from France, Canada, Switzerland, Belgium and Luxemburg, and was not limited to tenured profiles, but also included doctoral students and engineers.</p>
                <p style=""text-align:left; "">What, then, brings this very heterogeneous community together? And what services can an association provide, on a scale that lies between the traditional institutions of the academic world, national or international infrastructure projects, and global actors? In recent years, together with the growing institutionalization of digital humanities in the French-speaking areas (new curricula and training programmes, laboratories, chairs, events), the number of un-conferences has dropped, making the community harder to grasp. Although its absolute number has increased significantly – nearly 1.400 subscribers to a very active mailing list, institutions gradually integrating digital methods into their syllabi, etc. –, the normalization of DH has changed the meaning of the “community”, formerly strongly united by its minority status. Moreover, the integration of Humanistica within ADHO in 2016, the creation of the 
                    <hi rend=""italic"">Humanités numériques</hi> journal and the recent decision to create an annual event indicate a form of maturity as well as the relative decline of forms of scientific production and exchange that were regarded as characteristic a decade ago (blogging, un-conferences, etc.).
                </p>
            </div>
        
        <back>
            <div type=""bibliogr"">
                <listbibl>
                    Bibliography
                    <bibl style=""text-align:left; "">
                        <hi rend=""bold"">Álvarez, A.</hi> (2018) “Lenguas, patrimonio cultural y educación en proyectos culturales” en 
                        <hi rend=""italic"">Humanidades Digitales: Lengua, texto, patrimonio y datos</hi>, Bonilla Artigas - RedHD. 
                    </bibl>
                    <bibl style=""text-align:left; "">
                        <hi rend=""bold"">Berra, A.</hi> (2015) ""Pour une histoire des humanités numériques"", 
                        <hi rend=""italic"">Critique</hi>, 819/820, 8, 613-626.
                    </bibl>
                    <bibl style=""text-align:left; "">
                        <hi rend=""bold"">Barrón, F.</hi> (2018) “Introducción: Pensar y hacer Humanidades Digitales. Una demarcación regional” en 
                        <hi rend=""italic"">Humanidades Digitales: Lengua, texto, patrimonio y datos</hi>, Bonilla Artigas - RedHD.
                    </bibl>
                    <bibl style=""text-align:left; "">
                        <hi rend=""bold"">Canagarajah, S.A.</hi> (2012) “A Geopolitics of Academic Writing”, University of Pittsburgh Press. 
                    </bibl>
                    <bibl style=""text-align:left; "">
                        <hi rend=""bold"">Clavert, F.</hi> (2015), 
                        <hi rend=""italic"">Comprendre les humanités numériques : enjeux, outils, réseaux</hi>.
                        <ref target=""https://www.youtube.com/watch?v=8zdyETW-oAo"">
                            <hi rend=""underline color(1155CC)"">https://www.youtube.com/watch?v=8zdyETW-oAo</hi>
                        </ref>.
                    </bibl>
                    <bibl style=""text-align:left; "">
                        <hi rend=""bold"">Dacos, M. et al.</hi> (2011) ""Manifeste des Digital humanities"", 
                        <hi rend=""italic"">THATCamp Paris 2010</hi>, 
                        <ref target=""https://tcp.hypotheses.org/318"">
                            <hi rend=""underline color(1155CC)"">https://tcp.hypotheses.org/318</hi>
                        </ref>.
                    </bibl>
                    <bibl style=""text-align:left; "">
                        <hi rend=""bold"" xml:space=""preserve"">Fiormonte, D., Numerico, T., Tomasi, F. </hi>(2015) 
                        <hi rend=""italic"">The Digital Humanist: A Critical Inquiry</hi>.
                    </bibl>
                    <bibl style=""text-align:left; "">
                        <hi rend=""bold"">Fraistat, N.</hi> (2012). “The function of digital humanities centers at the present time”. In Matthew K. Gold (Ed.). 
                        <hi rend=""italic"">Debates in the Digital Humanities</hi>. Minneapolis, MN: University of Minnesota Press. pp. 278-92
                    </bibl>
                    <bibl style=""text-align:left; "">
                        <hi rend=""bold"">Galina, I.</hi> (2015) 
                        <hi rend=""italic"">Creating a regional DH community – A case study of the RedHD</hi>, DHQ Digital Humanities Quarterly, 9(3), (ISSN: 1938-4122)
                    </bibl>
                    <bibl style=""text-align:left; "">
                        <hi rend=""bold"">Gayol, V., A. Melo Flórez, V. and J.</hi> (2017). 
                        <hi rend=""italic"">Presente y perspectivas de las humanidades digitales en América Latina</hi>. 
                        <hi rend=""italic"">Mélanges de la Casa de Velázquez. Nouvelle série</hi> (47–2): 281–84 doi:
                        <ref target=""https://doi.org/10.4000/mcv.7907"">
                            <hi rend=""underline color(1155CC)"">10.4000/mcv.7907</hi>
                        </ref>.
                    </bibl>
                    <bibl style=""text-align:left; "">
                        <hi rend=""bold"">Grandjean, M.</hi> (2017) ""Humanistica"", 
                        <hi rend=""italic"">Etudes digitales</hi>, 3, 223-226. 
                        <ref target=""https://classiques-garnier.com/etudes-digitales-2017-1-n-3-variations-digitales-et-transformation-du-milieu-humanistica.html"">
                            <hi rend=""underline color(1155CC)"">10.15122/isbn.978-2-406-08531-7.p.0223</hi>
                        </ref>
                    </bibl>
                    <bibl style=""text-align:left; "">
                        <hi rend=""bold"">Grandjean, M.</hi> (2015) ""Les humanités numériques dans l’espace francophone : une communauté qui se structure"", 
                        <hi rend=""italic"">DH Nord</hi>, MESHS, Lille.
                    </bibl>
                    <bibl style=""text-align:left; "">
                        <hi rend=""bold"">Le Deuff, O.</hi> (2014). 
                        <hi rend=""italic"">Le temps des humanités digitales</hi>, FypEditions, 2014.
                    </bibl>
                    <bibl style=""text-align:left; "">
                        <hi rend=""bold"">Mounier, P.</hi> (2018) 
                        <hi rend=""italic"">Les humanités numériques. Une histoire critique</hi>, Editions de la Maison des sciences de l’homme.
                    </bibl>
                    <bibl style=""text-align:left; "">
                        <hi rend=""bold"">Ortega, É. and Gutiérrez, S.</hi> (2014). “MapaHD. Una exploración de las Humanidades Digitales en español y portugués”. 
                        <hi rend=""italic"" xml:space=""preserve"">Ciencias Sociales y Humanidades Digitales. Técnicas, Herramientas y Experiencias de e-Research e Investigación, </hi>Tenerife: CAC, Cuadernos Artesanos de Comunicación, pp. 101–28
                        <ref target=""http://www.cuadernosartesanos.org/2014/cac61.pdf"">
                            <hi rend=""underline color(1155CC)"">http://www.cuadernosartesanos.org/2014/cac61.pdf</hi>
                        </ref> (accessed 14 October 2014).
                    </bibl>
                    <bibl style=""text-align:left; "">
                        <hi rend=""bold background(white)"">Priani, E.</hi>
                        <hi rend=""background(white)"" xml:space=""preserve"">; </hi>
                        <hi rend=""bold background(white)"">Spence, P.</hi>
                        <hi rend=""background(white)"" xml:space=""preserve"">; </hi>
                        <hi rend=""bold background(white)"">Galina Russell, I.</hi>
                        <hi rend=""italic bold background(white)"">et. al.</hi> (2014) 
                        <ref target=""http://www.red-redial.net/revista/anuario-americanista-europeo/article/view/267"">
                            <hi rend=""italic underline color(1155CC)"">Las humanidades digitales en español y portugués. Un estudio de caso: DíaHD/DiaHD</hi>
                        </ref>, Anuario Americanista Europeo, no.12, pp.5-18.
                    </bibl>
                    <bibl style=""text-align:left; "">
                        <hi rend=""bold"">Rio Riande, G.</hi> (2016) “De todo lo visible y lo invisible o volver a pensar la investigación en humanidades digitales”, en 
                        <hi rend=""italic"">Signa: Revista de la Asociación Española de Semiótica (UNED)</hi>, núm. 25, ISSN 1133-3634, pp. 95-108. 
                    </bibl>
                    <bibl style=""text-align:left; "">
                        <hi rend=""bold"">Rio Riande, G.</hi> (2015) “Humanidades Digitales. Mito, actualidad y condiciones de posibilidad en España y América Latina”. ArtyHum, monográfico 1, noviembre de 2015, ISSN 2341-4898, pp. 7-19.
                    </bibl>
                    <bibl style=""text-align:left; "">
                        <hi rend=""bold"">Vinck, D.</hi> (2013). Las culturas y humanidades digitales como nuevo desafío para el desarrollo de la ciencia y la tecnología en América Latina. 
                        <hi rend=""italic"">Universitas Humanística</hi>, 76
                        <ref target=""http://revistas.javeriana.edu.co/index.php/univhumanistica/article/view/5906/7754"" xml:space=""preserve""> </ref>
                        <ref target=""http://revistas.javeriana.edu.co/index.php/univhumanistica/article/view/5906/7754"">
                            <hi rend=""underline color(1155CC)"">http://revistas.javeriana.edu.co/index.php/univhumanistica/article/view/5906/7754</hi>
                        </ref> (accessed 9 August 2014)
                    </bibl>
                </listbibl>
            </div>
        </back>
    </text>",xml,This text is republished here with permission from the original rights holder.,,dh communities;dh networks;european infrastructures;international cooperation;multiscalar complexities;national infrastructures;transnational networks,English,"digital humanities (history, theory and methodology);diversity;english;interdisciplinary & community collaboration;logic and epistemology"
10030,2019 - Utrecht,Utrecht,Complexities,2019-01-01T00:00:00Z,ADHO,ADHO,Utrecht University,Utrecht,,Netherlands,http://staticweb.hum.uu.nl/dh2019/dh2019.adho.org/index.html,Using Visualization to Understand the Complex Spatiality of Mappae Mundi,,Martin Reckziegel;David Joseph Wrisley;Taylor Wright Hixson;Stefan Jänicke,"paper, specified ""long paper""","<text>
        
            <div type=""div1"" rend=""DH-Heading"">
                Introduction
                <p>A common practice in spatial humanities is georeferencing historical maps to generate rasters for use in Geographic Information Systems (GIS) (Clifford et al., 2013). This method is typically carried out with different levels of precision and with different goals in mind; for example, spatial humanities practitioners create base maps from historical maps, they extract vector data or they compare spatial representations over time. If we consider both the historical map and the base map as imperfect representations--rather than reflections--of reality, the georeferencing process creates a relation which needs to be critically analyzed (Presner, et al., 2014). This paper aims to expand the modes of visualization available to scholars of cartography interested in exploratory spatial analysis of medieval maps in a way that the complex spatiality of the historical map is not overtaken by that of normative base maps.</p>
                <p>In the case of historical maps whose coordinates and scales are roughly comparable to modern maps, valuable historical information can be extracted from the georeferencing process (Baiocchi and Lelo, 2005). Furthermore, algorithmic analysis, such as differential distortion, can help identify geometric inaccuracies of so-called “old” maps (Claeys Boùùaert et al, 2016). Visualizing such divergence allows one to analyze historical cartographic technique.</p>
                <p>In this paper we turn instead to 
                    <hi rend=""italic"">very</hi> old maps--examples of so-called “complex” medieval maps that blend conventional T-O structure with pseudo-geographic detail. Historical cartographic studies have emphasized the encyclopedic quality of such maps, their textual sources and their blend of geography and sacred, cosmological detail (Paul, 2018; Edson, 1997). Rather than a modern coordinate system, we find in some of them notions of spatial orientation suggested by the abundance of detail and named entities on the surface of the map. Instead of consistently stretching the map, georeferencing can lead to problems of occultation, that is, to hidden “folds” in the distorted map. Another way of expressing this is that the distances or orientations of places or features on one map representation may not be consistent with another map. Furthermore, a map predating modern coordinate systems may contain non-geographic information. Stretching such a pre-modern map to a contemporary map projection, therefore, might seem counterintuitive. We argue that visualization of purposeful distortion can allow us to understand better the pre-modern organizational structure of maps. In our research we have found that this practice allows us to situate such pre-modern maps on a spectrum between the more topological and the more symbolic.
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading"">
                Map Projections and Georeferencing
                <p>The method of drawing a map of the almost spherical earth on a planar surface is called a map projection, a process only possible with distortion of some important geographic properties. One such projection known as the Mercator (Chamberlin et al, 1950), distorts areal scaling inconsistently, so that the areal scaling factor increases as one moves north. In the process of georeferencing, control points on the historic map are manually referenced on the modern map. For each control point in the coordinate system of a scanned historic map image, there is a control point in the coordinate system of the modern map image, which represents the same entity. Several algorithms exist to use this information to project the whole historic image onto the modern coordinate system. In this paper we use the Thin Plate Spline (TPS) method (Duchon, 1977), which maps the control points accurately and interpolates the locations in between, such that the bending energy of an imaginary surface is minimized.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading"">
                Existing Visualization Techniques for Showing Distortion
                <p>The computation and visualization of modern map projection distortion of a globe-to-map setting has been extensively studied. A common approach is to show ellipses on the map, indicating the distortion of infinitesimal circles on the globe. This method is named after French mathematician Tissot (Tissot, 1881) and has been extended to visualize flexion and skewness simultaneously (Goldberg et al., 2007). Further visualization techniques for the globe-to-map scenario have been elaborated (Tobler, 1966; Mulcahy et al, 2001), including the use of color maps and contour lines. Methods to compute and visualize distortion in a map-to-map scenario also exist (Jenny et al, 2007; Claeys Boùùaert et al, 2016). The latter study presents a methodology to visualize areal and angular distortion using differential analysis for every point of the modern map as projected onto the historic map or vice versa, given an arbitrary, differentiable projection function.</p>
            </div>
            <div type=""div1"" rend=""DH-Heading"">
                Visualizing Areal Distortion in 
                    <hi rend=""italic"">Mappae Mundi</hi>
                
                <p>It goes without saying that because medieval maps do not follow the projections used in modern cartography, by georeferencing them as described in section 2 we do not expect a seamless, intuitive result. Instead, when projecting 
                    <hi rend=""italic"">mappae mundi</hi> onto modern maps or vice versa, topological inconsistencies are likely to occur. As shown by the control points in Figure 1a, an imaginary place A might be left to a place B on the historic map, while their order is reversed on the modern map. Further, the places C and D remain their order. To resolve this, the TPS method creates a “folded” projection of the historic map on the modern map as shown in Figure 1b. 
                </p>
                <p>
                    <figure>
                        <graphic url=""Pictures/6ab107f9b33b6180a2fff97b9d4d3007.png""></graphic>
                        Topological inconsistent projection.
                    </figure>In order to show the pre-modern organizational structure of historical maps, possibly demonstrated by those regions of topological inconsistency, we visualize how the historic map will be scaled and where it will be folded by the TPS method. We base our calculations on an established areal scaling factor formula (Claeys Boùùaert et al., 2016) shown in Eq(1) in Figure 2 which can be simplified to Eq(2). This factor can also be derived by calculating the area A of the parallelogram the partial derivatives span using the shoelace formula (Meister, 1769), shown in Eq(3). The term Â will be negative only if the points of the parallelogram are found in a clockwise direction; in which case the TPS projection is flipped. As such, this property helps us to identify folded regions. The resulting visualization for the historic map of the example outlined above is shown in Figure 1c.
                </p>
                <p>Our visualization design can be read like a traditional contour map showing a mountain area: the higher the mountain, the larger the scaling factor of the image. Each contour line in the visualization represents a region where the scaling is identical. The wider such contour line is drawn, the smaller the gradient is, i.e., the smaller the change of scaling is at that location. To remain independent from units, we normalize that factor between the minimal and maximal occuring scales. Black contour lines represent mean scaling. The more saturated the lines are, the larger the magnification or shrinkage is with respect to the mean. The color blue indicates a factor smaller, respectively the color red a factor greater than the mean. Turquoise indicates shrinkage, and yellow, magnification in a folded region, that is, where the orientation of features of the historic map is flipped. A white line represents the crease of the fold. In addition to the contour lines, we identify the regions which will overlap in the projected image and draw those darker, resulting in “shadows” around folded areas. The result of applying the projection on the visualization itself can be seen in Figure 1d.</p>
                <p>
                    <figure>
                        <graphic url=""Pictures/c4c856b22d6c1ecdec8cfa8a8eb3381b.png""></graphic>
                        Areal scaling factor calculation.
                    </figure>
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading"">
                Discussion
                <p>At this stage of our research, we have used three medieval 
                    <hi rend=""italic"">mappae mundi</hi>: the Ebstorf map made in Northern Germany around 1235, the Cotton Anglo-Saxon map created at Canterbury between 1025 and 1050 and the Hanss Rüst woodcut map made in Augsburg around 1480. The abovementioned distortion techniques for medieval maps provide us with important insight into the particular blend of pseudo-geographic and non-geographic features found in each document. Results of this visualization are shown in Figure 3.
                </p>
                <p>The Ebstorf map is the most detailed of our three examples. The key distortion, located around the map center, is due to the seal with Christ indicating Jerusalem, a symbolic, rather than geographic, placement. Other distortion is visible around Sicily, Crete, Cologne and cities of the Alexander legends. In the Cotton Anglo-Saxon map, no folds were produced given the chosen control points. On the other hand, we observed significant scalar expansion relative to the mean in the regions of Barbary and North Africa as well as the Western Mediterranean and the Black seas. Shrinkage of scale was observed particularly in two directions: along the axis Jerusalem-Babilonia-India as well as over Scotland and the Hebrides. The Hanss Rüst map exhibited the least geographic realism of all three.</p>
                <p>
                    <figure>
                        <graphic url=""Pictures/e0b62b13edd7ae69f1e9b06aae67e3f2.jpg""></graphic>
                        Visualization results. From top to bottom: The historic map image, the historic map including our visualization and the historic map projected onto a mercator map.
                    </figure>The folds created by map distortion, visualized in our design, provide strong visual stimuli for understanding the continuum of pseudo-geographic features of old maps, that is, for the critical evaluation of the spatiality of such maps on their own terms.
                </p>
                <p>Whereas for the TPS method used in this paper we chose control points based on written geographic information (names of provinces, cities, images of walled cities), other choices for control points could lead to contradictory results. In future work, we intend not only to expand the set of maps that we can annotate, but also expand and develop our visualization methods. Finally, we intend to alter our mode of annotation, by choosing, as in classic modes of georeferencing, features on the map, such as peninsulas, mountains or rivers, instead of text or in combination with text to assess what different results we might obtain.</p>
            </div>
        
        <back>
            <div type=""bibliogr"">
                <listbibl>
                    Bibliography
                    <bibl>
                        <hi rend=""bold"">Anglo-Saxon World Map</hi> (11th century). British Library. 
                        <ptr target=""https://www.bl.uk/collection-items/anglo-saxon-world-map""></ptr> (accessed 4.25.19).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Baiocchi, V., Lelo, K.</hi> (2005). Georeferencing the Historical Maps of Rome Between the Seventeenth and Eighteenth Centuries, in: CIPA 2005 XX International Symposium, 26 September – 01 October, 2005, Torino, Italy.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Chamberlin, W., Grosvenor, G.H.</hi> (1950). The Round Earth on Flat Paper: Map Projections Used by Cartographers. National Geographic Society, Washington.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Claeys Boùùaert, M., De Baets, B., Vervust, S., Neutens, T., De Maeyer, P., Van de Weghe, N.</hi> (2016). Computation and Visualisation of the Accuracy of Old Maps Using Differential Distortion Analysis. International Journal of Geographical Information Science 30, 1255–1280.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Clifford, J., MacFadyen, J., Macfarlane, D.</hi> (2013). Georeferencing in QGIS 2.0. Programming Historian. 
                        <ptr target=""https://programminghistorian.org/en/lessons/georeferencing-qgis""></ptr> (accessed 4.25.19).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Duchon, J.</hi> (1977). Splines Minimizing Rotation-Invariant Semi-Norms in Sobolev Spaces, in: Schempp, W., Zeller, K. (Eds.), Constructive Theory of Functions of Several Variables, Lecture Notes in Mathematics. Springer Berlin Heidelberg, pp. 85–100.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Ebstorfer World Map</hi> (13th century). 
                        <ptr target=""https://commons.wikimedia.org/wiki/File:Ebstorfer-stich2.jpg""></ptr> (accessed 4.25.19).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Edson, E.</hi> (1997). Mapping Time and Space: How Medieval Mapmakers Viewed Their World. British Library.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Goldberg, D.M., Gott, J.R.</hi> (2007). Flexion and Skewness in Map Projections of the Earth. Cartographica: The International Journal for Geographic Information and Geovisualization 42, 297–318.
                        <ref target=""https://doi.org/10.3138/carto.42.4.297""> </ref>
                        <ptr target=""https://doi.org/10.3138/carto.42.4.297""></ptr>
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Jenny, B., Weber, A., Hurni, L.</hi> (2007). Visualizing the Planimetric Accuracy of Historical Maps with MapAnalyst. Cartographica 42, 89–94.
                        <ref target=""https://doi.org/10.3138/carto-v42-1-089""> </ref>
                        <ptr target=""https://doi.org/10.3138/carto-v42-1-089""></ptr>
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Mappa mundi : “Das ist die mapa mu[n]di un alle land un kungk reich wie sie ligend in der ga[n]tze welt”</hi> (15th century). The Morgan Library &amp; Museum. 
                        <ptr target=""https://www.themorgan.org/incunables/145336""></ptr> (accessed 4.25.19).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Meister, A.L.F.</hi> (1769). Generalia de genesi figurarum planarum et inde pendentibus earum affectionibus. Göttingen.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Mulcahy, K.A., Clarke, K.C.</hi> (2001). Symbolization of Map Projection Distortion: A Review. Cartography and Geographic Information Science 28, 167–182.
                        <ref target=""https://doi.org/10.1559/152304001782153044""> </ref>
                        <ptr target=""https://doi.org/10.1559/152304001782153044""></ptr>
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Paul, N.L.</hi> (2018). Introducing the Oxford Outremer Map. Fordham Medieval Digital Projects. 
                        <ptr target=""https://medievalomeka.ace.fordham.edu/exhibits/show/oxford-outremer-map/mpcontext""></ptr> (accessed 4.25.19).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Presner, T.S., Shepard, D., Kawano, Y.</hi> (2014). Hypercities: Thick Mapping in the Digital Humanities. Harvard University Press, Cambridge.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Tissot, N.A.</hi> (1881). Mémoire sur La Représentation des Surfaces et les Projections des Cartes Géographiques. Gauthier-Villars, Paris.
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Tobler, W.B.</hi> (1966). Medieval Distortions: The Projections of Ancient Maps. Annals of the Association of American Geographers 56, 351–360.
                        <ref target=""https://doi.org/10.1111/j.1467-8306.1966.tb00562.x""> </ref>
                        <ptr target=""https://doi.org/10.1111/j.1467-8306.1966.tb00562.x""></ptr>
                    </bibl>
                </listbibl>
            </div>
        </back>
    </text>",xml,This text is republished here with permission from the original rights holder.,,distortion;mappae mundi;map warping;medieval studies;visualization,English,"english;geography and geo-humanities;image processing;medieval studies;spatial & spatio-temporal analysis, modeling and visualization"
10135,2019 - Utrecht,Utrecht,Complexities,2019-01-01T00:00:00Z,ADHO,ADHO,Utrecht University,Utrecht,,Netherlands,http://staticweb.hum.uu.nl/dh2019/dh2019.adho.org/index.html,Encoding Early Modern English Drama: Embedding Digital Approaches In Undergraduate Literature Courses.,,Elizabeth Williamson,"paper, specified ""long paper""","<text>
        
            <p>There has been greater inclusion of teaching in DH debates in recent years, yet in practice, UK digital humanities teaching tends to be found in explicitly DH postgraduate courses or as specific skills training for self-selecting staff or (often postgrad) students; it also appears less in English literature teaching than in history, classics, media studies or linguistics. This paper offers a case study where TEI XML encoding was introduced to first-year undergraduates in an established course on Shakespeare, to facilitate discussion on how digital humanists can enable integration of digital skills into ‘traditional’ English literature teaching by capitalizing on affinities between DH, book history, and textual scholarship. Integrating digital approaches into undergraduate teaching of English literature enables us to introduce students early on to reflecting critically on the digital, and lets us embrace the complexities of encoding as editing, rather than allowing undergraduates to only interact with the digital through a GUI.</p>
            <p>Early modern studies provides an ideal context in which to teach text encoding and digital literacy skills. In part this is due to the availability of encoded early modern texts for analysis and reuse, for example in the massive release into the public domain of lightly encoded EEBO-TCP texts in January 2015, and in part to fewer issues around copyright than with more modern texts (see Brown and Zimmer, 2017). More specifically, there is a synergy between the existing concerns of the Shakespeare course under discussion and those of digital publication, where the latter finds a natural fit in conversations on book history, text technologies, and editorial agency. Olin Bjork, in an article comparing American composition and computing classes to the “new media studies” side of digital humanities, suggests that “A weakness of digital humanities is that it undertheorizes the transformation of material objects into digital objects” (Bjork, 2012: 103). The materiality and the instability of the text are complexities that go to the heart of early modern literature studies: these are issues that our students grapple with when they consider the nature of the early modern play-text, yet rarely do we recognise that the digital text must be part of this conversation. Accordingly, in a course that unsettles the Shakespearean play as single authoritative text, there is a real need to push conversations on early print and textual scholarship into the realm of the digital, to unsettle and critique the digital texts the students encounter more often than they open their assigned course book.</p>
            <p>The course under discussion is a first year module with c.200 students enrolled, and the digital element ran as a successful pilot in 2018 and was expanded in 2019. The digital element is introduced in a guest lecture by a digital humanist; issues raised are debated in seminar groups, and existing digital texts and projects are introduced to the students, including A Digital Anthology of Early Modern English Drama (EMED), Internet Shakespeare Editions, the Queen’s Men Editions, Digital Renaissance Editions, and Folger Digital Texts, where students use the Folger API to explore the possibilities opened up by text encoding. The students then have the opportunity to create their own digital edition of the ending of King Lear, opting in to an additional workshop on TEI XML. They can elect to do their final assessment as a TEI-encoded play excerpt coupled with traditional essay, which allows them to reflect on the differences between early print, modern printed editions, and digital media. Writing about the medium and the choices it encourages or enforces allows them to critically reflect on digital texts at a crucially early point in their university careers. In the encoding part of the assignment, by taking ownership of a digital play text, they come to see both the scholarly edition and the digital medium as less an unquestionably authoritative black box and more something that they themselves can have agency over and interrogate. By pulling back the curtain on the scholarly text and the digital medium, they are more able to critique both text and textual manifestation. </p>
            <p>DH in the undergraduate classroom often tends towards GUI publication, with wikis, Wordpress sites, or platforms like the Alliance for Networking Visual Culture’s Scalar (Bjork, 2012: 99–100). While that is a valuable part of the picture, this paper explores what happens when students are introduced to the complexities of XML encoding as an editing practice, and how exposure to the component parts of a digital publication opens up that black box. This reveals to the students the variety of people involved in publication, in modern as well as early modern times, and demonstrates that encoders are editors and developers are intellectual partners who have concrete influence over the resulting output. Significantly, this message is also imparted to fellow academic staff teaching on the course. This approach thus invites fellow academic staff into the digital humanities, developing by proxy their understanding of digital resource creation and consequently their ability to critique this growing area of scholarly production.</p>
            <p>The aim of this paper is to share experiences and create discussion around the natural affinity between early modern studies and digital publication and digital critical literacy, especially in an undergraduate context. A parallel can be seen between the instinct to view the digital object as something that appears from thin air and the unquestioning acceptance of a particular critical edition as the immutable authoritative text. It is too easy to ignore the digital provenance of a text online or the multiple agents involved in producing any (especially canonical) text. To do this is to remove those who construct the text, and obscure the encoding as well as editorial choices made at every stage of its creation. To direct attention towards these is to put them back. This is a conversation that we need to begin early on in students’ academic career, to situate digital critical literacy within an existing tradition of literary criticism: we need to teach students to close-read the material digital object at the same time as the literary text and its early print origins.</p>
        
        <back>
            <div type=""bibliogr"">
                <listbibl>
                    Bibliography
                    <bibl>
                        <hi rend=""bold"">Bjork, O.</hi> (2012). Digital Humanities and the First-Year Writing Course. In Hirsch, B. ed., (2012) 
                        <hi rend=""italic"">Digital Humanities Pedagogy: Practices, Principles and Politics</hi>. Open Book Publishers, pp. 97–119. 
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Brown, M., Poston, M. and Williamson, E.</hi> A Digital Anthology of Early Modern English Drama https://emed.folger.edu/ (accessed 20 November 2018).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Greatley-Hirsch, B.</hi> (2015) Digital Renaissance Editions 
                        <ref target=""http://digitalrenaissance.uvic.ca"">http://digitalrenaissance.uvic.ca</ref> (accessed 20 November 2017).
                    </bibl>
                    <bibl>Hackfest and Ideas Hack, Early English Books Online Text Creation Partnership (EEBO-TCP) at the Bodleian Libraries http://www.bodleian.ox.ac.uk/eebotcp/early-english-books-hackfest/ (accessed 20 November 2018).</bibl>
                    <bibl>
                        <hi rend=""bold"" xml:space=""preserve"">Hirsch, B. </hi>ed. (2012) 
                        <hi rend=""italic"">Digital Humanities Pedagogy: Practices, Principles and Politics</hi>. Open Book Publishers. 
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Hirsch, B., and Jenstad, J.</hi> (2016). Beyond the Text: Digital Editions and Performance. 
                        <hi rend=""italic"">Shakespeare Bulletin</hi> 34, 107–27. 
                    </bibl>
                    <bibl>Internet Shakespeare Editions, (2016). 
                        <ref target=""http://internetshakespeare.uvic.ca/"">http://internetshakespeare.uvic.ca/</ref> (accessed 20 November 2017).
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Mowat, B., Werstine, P., Poston, M. and Niles, R.</hi>, eds., (n.d.) Shakespeare's Plays from Folger Digital Texts. 
                        <ref target=""http://www.folgerdigitaltexts.org"">www.folgerdigitaltexts.org</ref> (accessed 20 November 2018). 
                    </bibl>
                    <bibl>The Alliance for Networking Visual Culture (n.d.) Scalar 
                        <ref target=""https://scalar.usc.edu/scalar/"">https://scalar.usc.edu/scalar/</ref> (accessed 20 November 2017).
                    </bibl>
                    <bibl>Queen's Men Editions, (2011). 
                        <ref target=""http://qme.internetshakespeare.uvic.ca/"">http://qme.internetshakespeare.uvic.ca/</ref> (accessed 20 November 2017). 
                    </bibl>
                    <bibl>
                        <hi rend=""bold"">Zimmer, E. and Brown, M.</hi> (2017) History of Early English Books Online. Folgerpedia. 
                        <ref target=""https://folgerpedia.folger.edu/History_of_Early_English_Books_Online"">https://folgerpedia.folger.edu/History_of_Early_English_Books_Online</ref> (accessed 20 November 2018).
                    </bibl>
                </listbibl>
            </div>
        </back>
    </text>",xml,This text is republished here with permission from the original rights holder.,,drama;early modern;early print;editing;teaching,English,"bibliographic methods / textual studies;english;literary studies;renaissance studies;teaching, pedagogy, and curriculum;text encoding and markup languages"
10738,2018 - University of Cologne,University of Cologne,Kritik der digitalen vernunft,2018-01-01T00:00:00Z,DHd,DHd,,Cologne,,Germany,https://dhd2018.uni-koeln.de/,Deutsche Geschichte-Digital: Ergebnisse der TEI-Konvertierung und Integration in Pilotprojekten,,Matthew Hiebert;Simone Lässig;Andreas Witt,poster / demo / art installation,"<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""de"">
      <body>
         <p>Das Deutsche Historische Institut in Washington (DHI) befindet sich in der Entwicklungsphase von "" Deutsche Geschichte-
                <hi rend=""italic"">Digital</hi> / German History-
                <hi rend=""italic"">Digital</hi>"" (DG-D), einer transatlantischen digitalen Initiative, um die wissenschaftlichen Bedürfnisse von HistorikerInnen im Kontext neuer historiografischer und technologischer Herausforderungen zu bewältigen. DG-D ist eine neue Infrastruktur zur Erleichterung der transnationalen historischen Wissensschöpfung für eine große Wissenschaftsgemeinschaft und eine wachsende Zahl von ""Citizen Scholars"", die bereits auf digitale Ressourcen des DHI angewiesen sind. Im Poster stellen wir zwei zentrale GH-Digital-Pilotprojekte und deren Integration in die DG-D ""Knowledge Creation Environment"" vor. Das erste ist ""Deutsche Geschichte in Dokumenten und Bildern"", unterstützt von der Deutschen Forschungsgemeinschaft (DFG), und das zweite ist Deutsche Geschichte 
                <hi rend=""italic"">Intersections</hi>, unterstützt durch das Europäische Wiederaufbauprogramm (ERP). 
            </p>
         <p>Die Planung für DG-D umfasste die Befragung von mehr als vierhundert WissenschaftlerInnen, die bereits mit digitalen Ressourcen arbeiten, welche vom DHI produziert wurden. Die umfassendste dieser Ressourcen ist die im Jahr 2003 gestartete digitale Quellensammlung ""Deutsche Geschichte in Dokumenten und Bildern / German History in Documents and Images"" (GHDI), die an deutsch- und englischsprachigen Universitäten weitläufig genutzt wird. Derzeit wird GHDI in Verbindung mit DG-D einem technischen und konzeptionellen Umbau unterzogen. Es enthält Tausende Seiten englischsprachiger Übersetzungen deutscher historischer Texte sowie Bilder und Karten, die von ca. 5.000 Besuchern pro Tag genutzt werden. Unsere Planung für DG-D beinhaltet auch weiterhin Konsultationen und Workshops mit ExpertInnen aus den Geschichtswissenschaften und den digitalen Geisteswissenschaften sowie die Gründung von Partnerschaften mit Institutionen und großen Initiativen, die unser Interesse für die Zukunft der Geschichte im digitalen Zeitalter teilen.</p>
         <p>Die Deutsche Geschichte-
                <hi rend=""italic"">Digital</hi>-Plattform befasst sich mit den Bedürfnissen der digitalen Forschung durch fünf Ziele und integrierte Arbeitspakete, die auf diese Ziele abgestimmt sind: Entdeckung, Analyse, Produktion, Bewahrung und Gemeinschaft. DG-D beinhaltet die Entwicklung eines Peer-Review-Index von wissenschaftlichen digitalen Objekten mit Dublin Core (DC) und CLARINs Component MetaData Infrastructure (CMDI) Standards über einen angepassten Blacklight (http://projectblacklight.org/) Technologie-Stack.
            </p>
         <p>Für WissenschaftlerInnen, die historische digitale Projekte in Nordamerika entwickeln, gibt es keine interinstitutionelle Infrastruktur für die Speicherung ihrer Daten oder die Bereitstellung von Open Access. CLARIN-D, Teil der europäischen Forschungsinfrastruktur CLARIN, berät und unterstützt das DG-D-Projekt zur Erstellung eines Portals für CLARIN in Nordamerika am DHI Washington. Im Mittelpunkt dieses Prozesses steht die Implementierung eines Repository-Systems, das eine nachhaltige Speicherung des Inhalts und die Einbindung in eine digitale Umgebung ermöglicht, um den Zugriff, die Suche und die interoperablen Datenformate zu erleichtern. Unsere Partnerschaft mit CLARIN fördert den freien Zugang, die offene, kooperative Wissenschafts- und Wissenserzeugung im nordamerikanischen Kontext und ist ein wichtiger Bestandteil der gesamten Strategie der digitalen Geisteswissenschaften des DHI. Als Institut der Max Weber Stiftung sind wir auch in Partnerschaft mit DARIAH-DE. DARIAH-DE wird Web-Hosting und langfristige Bewahrung von DHI-Digitalprojekten in ihrer Gesamtheit, einschließlich der ersten Version der Webseite Deutsche Geschichte in Dokumenten und Bildern, zur Verfügung stellen.</p>
         <p>Als kooperative Wissensplattform wird DG-D Redakteure, Forscher und Citizen Scientists bei der Entwicklung weiterer innovativer Online-Projekte zusammenbringen. Drei solcher Pilotprojekte befinden sich derzeit in der Entwicklung und beinhalten TEI und unsere Internationalisierung der Scalar 2.0 Plattform. DG-D verwendet Scalar 2.0 für das Baseline Content Management System, insbesondere aufgrund seiner Schnittstellenfunktionen, Unterstützung für Resource Description Framework (RDF), Konnektivität zu externen Repositorien, Dublin Core (DC) Unterstützung, Hypothes.is Integration und sein Mehrfachpfad-Navigationssystem.</p>
         <p>HistorikerInnen nutzen zunehmend digitale Geisteswissenschaften, um Daten zu analysieren und ihre Forschungsergebnisse darzustellen. Ein weiterer Vorteil der Speicherung von TEI-Digitalobjekten in einem CLARIN-Repository ist, dass eine ganze Palette von korpus-linguistischen analytischen Werkzeugen von WissenschaftlerInnen auf Textinhalte angewendet werden kann. In diesem Zusammenhang werden wir unsere Entwicklung von Scalar Adapters für den Anschluss an deutsche Repositorien und virtuelle Forschungsumgebungen (VREs) diskutieren.</p>
         <p>Die DG-D-Plattform integriert die Blog-Aggregation, ein erweitertes Diskussionssystem, Community-orientierte Tools und Social Media, um miteinander kooperierende Wissensgemeinschaften zu erleichtern und Forschung zu öffnen. Dies ist ein wegweisender Aspekt unseres Projektes, das die Annahme von sozialen und gemeinschaftlichen digitalen Instrumenten durch HistorikerInnen in ihren Forschungsaktivitäten untersuchen wird. Wir wollen hierbei auch die einzigartige Rolle nutzen, die das DHI als Drehscheibe des transatlantischen wissenschaftlichen Dialogs und als eines großen Knotenpunkts in einem internationalen Netzwerk von HistorikerInnen spielt, um die Zusammenhänge zwischen verschiedenen Wissenschaftsgemeinschaften zu erleichtern.</p>
         <p>Deutsche Geschichte-
                <hi rend=""italic"">Digital</hi> Projekte bietet ein Modell für neue, quellenbasierte methodische Ansätze in den Geschichtswissenschaften. Die Initiative zielt darauf ab, durch digitale Instrumente, Standards und Methoden zur argumentbasierten Forschung beizutragen. Es fördert transnationale Ansätze in der historischen Forschung durch das Verfügbarmachen einer transnationalen technischen Plattform, die auf TEI und anderen aufkommenden Standards in den digitalen Geisteswissenschaften wie DC und RDF gründet. 
            </p>
         <p>Es unterstützt narratologische Komplexität in der Geschichtsschreibung und vermeidet redaktionelle Ansätzen, die eine singuläre Erzählung oder „
                <hi rend=""italic"">Master Narrative</hi>“ ergeben. 
            </p>
      </body>
      <back>
         <div type=""bibliogr"">
            <listBibl>
               <head>Bibliographie</head>
               <bibl>
                  <hi rend=""bold"">Cohen, Daniel J., and Roy Rosenzweig </hi>(2006): 
                        <hi rend=""italic"">Digital History: A Guide to Gathering, Preserving, and Presenting the Past on the Web. </hi>Philadelphia: University of Pennsylvania Press.
                    </bibl>
               <bibl>
                  <hi rend=""bold"">Cohen, Daniel J., Michael Frisch, Patrick Gallagher, Steven Mintz, Kirsten Sword, Amy Murrell Taylor, William G. Thomas III, and William J. Turkel </hi>(2008): “Interchange: The Promise of Digital History.” 
                        <hi rend=""italic"">Journal of American History</hi>, volume 95, issue 2, 452-491.
                    </bibl>
               <bibl>
                  <hi rend=""bold"">“Diskussionsforum: Historische Grundwissenschaften und die digitale Herausforderung.” </hi>From H-Soz-Kult, November 15, 2015 (
                        <ref target=""http://www.hsozkult.de/text/id/texte-2890"">http://www.hsozkult.de/text/id/texte-2890</ref>).
                    </bibl>
               <bibl>
                  <hi rend=""bold"">Fiedler, Norman and Werthmann, Antonina and Stuehrberg, Maik and Schonefeld, Oliver and Bingel, Joachim and Witt, Andreas </hi>(2014): Research infrastructures in non-university research facilities. Research paper. Mannheim: Institute for German Language, 2014. 116 S.</bibl>
               <bibl>
                  <hi rend=""bold"">Hiebert, Matthew, Lässig, Simone and Witt, Andreas </hi>(2017): German history-digital: A platform for transnational historical knowledge co-creation. In: Digital Humanities 2017, Conference Abstracts, McGill University & Université de Montréal Montréal, Canada August 8-11, 2017. Montréal: McGill University & Université de Montréal, 2017. p. 269-271</bibl>
               <bibl>
                  <hi rend=""bold"">Hiebert, Matthew, Bowen, W. R., and Siemens, R.G </hi>(2015): “Implementing a social knowledge creation environment.” Scholarly and Research Communication, 6(3).</bibl>
               <bibl>
                  <hi rend=""bold"">Mandić, Slobodan </hi>(2005): 
                        <hi rend=""italic"">Computerization and Historiography 1995-2005</hi>. Belgrade: Belgrade Historical Society.
                    </bibl>
               <bibl>
                  <hi rend=""bold"">McCullough, Kelly, and James Retallack </hi>(2013): “Digital History Anthologies on the Web: German History in Documents and Images.” 
                        <hi rend=""italic"">Central European History</hi>, volume 46, 346-361.
                    </bibl>
               <bibl>
                  <hi rend=""bold"">Ngai, Mae M </hi>(2012): “The Future of the Discipline: The Promise and Perils of Transnational History.” 
                        <hi rend=""italic"">Perspectives on History</hi>, December 2012 (
                        <ref target=""https://www.historians.org/publications-and-directories/perspectives-on-history/december-2012/the-future-of-the-discipline/promises-and-perils-of-transnational-history"">https://www.historians.org/publications-and-directories/perspectives-on-history/december-2012/the-future-of-the-discipline/promises-and-perils-of-transnational-history</ref>).
                    </bibl>
               <bibl>
                  <hi rend=""bold"">Patel, Kiran Klaus </hi>(2010): “Transnational History.” In <hi rend=""italic"">European History Online</hi> (EGO), published by the Institute of European History (IEG). Mainz, 2010 (<ref target=""http://www.ieg-ego.eu/patelk-2010-en"">http://www.ieg-ego.eu/patelk-2010-en</ref>).
                    </bibl>
               <bibl>
                  <hi rend=""bold"">Patel, Kiran Klaus </hi>(2011): “Zeitgeschichte im digitalen Zeitalter: Neue und alte Herausforderungen.” 
                        <hi rend=""italic"">Vierteljahrshefte für Zeitgeschichte</hi>, volume 59, issue 3, July, 331-51.
                    </bibl>
               <bibl>
                  <hi rend=""bold"">Putnam, Lara </hi>(2016): “The Transnational and the Text-Searchable: Digitized Sources and the Shadows They Cast.” 
                        <hi rend=""italic"">The American Historical Review</hi>, volume 121, issue 2, April, 377-402. 
                    </bibl>
               <bibl>
                  <hi rend=""bold"">Sahle, Patrick </hi>(2013):
                        <hi rend=""italic"">Digital Editionsformen</hi>. 
                            <hi rend=""italic"">Zum Umgang mit der Überlieferung unter den Bedingungen des Medienwandels. </hi>Volume 3 (Norderstedt).
                    </bibl>
               <bibl>
                  <hi rend=""bold"">Thomas, William G., III </hi>(2016): “Renegotiating the Archive: Scholarly Practice in the Digital Age.” 
                        (<ref target=""http://railroads.unl.edu/blog/?p=1195"">http://railroads.unl.edu/blog/?p=1195</ref>). 
                    </bibl>
            </listBibl>
         </div>
      </back>
   </text>

",xml,Creative Commons Attribution 4.0 International,,archivierung;geschichte;infrastruktur;konservierung;tei,German,archivierung;forschung;infrastruktur;kollaboration;kommunikation;konservierung
10910,2019 - Johannes Gutenberg University;Goethe University,Johannes Gutenberg University;Goethe University,multimedial & multimodal,2019-01-01T00:00:00Z,DHd,DHd,Johannes Gutenberg-Universität Mainz (Johannes Gutenberg University of Mainz);Johann-Wolfgang-Goethe-Universität Frankfurt am Main (Goethe University of Frankfurt),Frankfurt & Mainz,,Germany,https://dhd2019.org/,„Medialization follows function!“ Multimodaler Hypertext als Publikationsmedium (nicht nur) für die Geschichtswissenschaft,,Christian Wachter,poster / demo / art installation,"<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""de"">
      <body>
         <div type=""div1"" rend=""DH-Heading1"">
            <head>Wissenschaftliches Publizieren: Knowledge Design wird im Mediendesign sichtbar</head>
            <p style=""text-align:left;"">Vermittlung von Wissen ist immer an den Gebrauch von Medien gebunden. Dabei haben selbige stets Einfluss auf die Semantik der Botschaften. Gerade im wissenschaftlichen Kontext gilt es, diese Wirkung der 
                    <hi rend=""italic"">Medienästhetik</hi> (zum Begriff s. Schnell 2000, 2001) beim Gestalten von Publikationen zu beachten und reflektiert einzusetzen. Hier gilt schließlich Klaus Krippendorffs Leitsatz: „Design is making sense of things” (Krippendorff 2006: xiii).
                </p>
            <p style=""text-align:left;"">So benutzen Geisteswissenschaftler*innen sinnvollerweise traditionell typografische Publikationsformen. Immerhin ermöglichen tendenziell linear gestaltete Narrative eine präzise Vermittlung logischer Argumentationsverläufe. Diese werden isomorph im Textfluss symbolisch repräsentiert und können von Leser*innen eng nachvollzogen werden. Die textsprachliche Modalität macht diese direkte Vermittlung möglich.</p>
         </div>
         <div type=""div1"" rend=""DH-Heading1"">
            <head>Hypertext erweitert den Möglichkeitsspielraum, Wissen zu medialisieren</head>
            <p style=""text-align:left;"">Wenn jedoch komplexere, pluralistisch angelegte Zusammenhänge vermittelt werden sollen, leistet 
                    <hi rend=""italic"">Hypertext</hi> als ein unlineares Medium eindeutig mehr: Gleichzeitigkeiten, Verflechtungen, Perspektivenpluralismus oder Anschlussfähigkeit an weitere Methoden sind insbesondere zu nennen. Sie können mit Hypertext auf eine explizite Weise vermittelt werden, wie es mit der Typografie nicht möglich ist. Dies ist die Kernaussage meines Promotionsprojektes, das ich mit dem präsentierten Poster vorstelle. Das Projekt ist als 
                    <hi rend=""italic"">medientheoretischer Beitrag zur Grundlagenforschung des E-Publishing</hi> gedacht.
                </p>
            <p style=""text-align:left;"">Dabei liegt der Fokus auf der Geschichtswissenschaft, da ich Strategien und Ziele der Wissenserzeugung innerhalb meiner eigenen Disziplin reflektiere und davon abhebend frage, welche mediale Vermittlungsform sich im Einzelfall als adäquat erweist. Diese grundlegende Blickrichtung motiviert den Titel „Medialization follows function!“<hi rend=""superscript"">1</hi>. Weil in anderen Disziplinen ganz ähnliche Strategien und Ziele der argumentativ-logischen Wissensgestaltung und ‑vermittlung bestehen, soll das präsentierte Poster auch zu einem Ausblick über die Geschichtswissenschaft hinaus anregen.</p>
            <p style=""text-align:left;"">In der historischen Metatheorie wurden nicht nur die textuell-narrativen Bedingungen der Repräsentation von Geschichte bereits besprochen (s. einführend Crivellari et al. 2004; Haas 2004; Rüsen 2013: 191-220; Stopka 2018). Darüber hinaus wurden etwa auch Visualität als produktive Erweiterung der Ausdrucksmöglichkeiten (v.a. Haas 2006; Staley 2014) sowie Hypertext als Medium zur pluralistischen Darstellung von Geschichte(n) (v.a. Krameritsch 2007, 2009) ins Spiel gebracht. Krameritschs Beiträge stellen essenzielle Grundlagenarbeiten dar, an der sich mein Dissertationsprojekt methodisch und inhaltlich stark orientiert. Anders als Krameritsch geht es mir jedoch weniger um kollaborative Praxen der Wissenserzeugung in der Postmoderne oder um die Abbildung einer geschichtswissenschaftlichen Diskurs- und Wissenslandschaft mithilfe von netzwerkartigen Hypertexten. Vielmehr untersuche ich, wie einzelne Wissensangebote für sich hypertextuell publiziert werden können. Wo sich Krameritsch doch hierauf bezieht, sind es wiederum netzwerkartige, von Benutzer*innen relativ frei zu navigierende Hypertexte, für die er als innovative Vermittlungsformen votiert. Auf der Basis meiner theoretischen Reflexionen gelange ich hingegen zu visualisierten, 
                    <hi rend=""italic"">multilinear</hi> gestalteten Hypertexten als vielversprechendste Varianten. Sie lösen m.E. deutlich stärker die historiografische Kernaufgabe ein, Geschichte(n) als (pluralistische) Zusammenhänge narrativ strukturiert zu vermitteln. 
                </p>
         </div>
         <div type=""div1"" rend=""DH-Heading1"">
            <head>Theoretische Fundierung</head>
            <p style=""text-align:left;"">Den Beginn macht eine epistemologische Grundlegung, die von einem non-dualistischen konstruktivistischen Wissensbegriff (vgl. zusammenfassend Weber 2010: 183-184) ausgeht. Dieses Wissensverständnis verlangt, in Publikationen stets Material und Verfahren zu explizieren, mit denen konstruiert wird; nur so werden die Wissensprodukte epistemisch überhaupt nachvollziehbar (vgl. Ceccato nach Zitterbarth 1991: 77). Im Kern geht es dabei natürlich nicht um Auflistungen parzellierter Einzelinformationen, sondern um das interpretierende, logisch-argumentative Herausstellen Sinn-voller Beziehungen zwischen Informationen. 
                    <hi rend=""italic"">Sinnzusammenhänge</hi> mit ihren 
                    <hi rend=""italic"">Kohärenzstrukturen</hi> stellen so die eigentlichen Wissensangebote (nicht nur) der Historiografie dar (vgl. Haas 2004: 233). Weil das Knowledge Design beim Publizieren symbolisch in ein Mediendesign überführt wird, folgen in der Dissertation medientheoretische Reflexionen, die schwerpunktmäßig die besondere Eignung, aber auch Grenzen von Hypertext für die Repräsentation explizit von Zusammenhängen (vgl. Storrer 2000, 2004; Winko 2005, 2008) adressieren. Insgesamt operationalisiere ich transdisziplinär Forschungsergebnisse v.a. aus der Literaturwissenschaft, den Medienwissenschaften sowie der Informatik. Die Multimodalitätsforschung (anschließend an Kress / van Leeuwen 2001) wird insbesondere in bild-linguistischer Prägung einbezogen. Texte, Bilder und Text-Bild-Kombinationen lassen sich daran ansetzend als Komplexe aus verknüpften Propositionen fassen (s. zusammenfassend Große 2011: 118-122). Narrative Texte geben die Propositionen semantisch explizit und hauptsächlich monosequenziert an, was medienästhetisch zu einer entsprechend sukzessiven Rezeption (z.B. von Argumentationslinien) führt. Sämtliche Zusammenhänge werden jedoch erst am Ende der Lektüre oder bei hoher Komplexität doch lediglich partiell erkennbar. Dementgegen können Bilder pluralistisch verknüpfte Propositionen simultan darstellen, wobei die Zusammenhänge semantisch unterdeterminiert bleiben. Sie werden allerdings ganzheitlich und nicht sukzessive wahrgenommen (vgl. Stöckl 2011: 48-49). Beide Modalitäten bieten gewissermaßen Vor‑ und Nachteile für die Wissensvermittlung.
                </p>
         </div>
         <div type=""div1"" rend=""DH-Heading1"">
            <head>Multimodaler Hypertext kombiniert konstruktiv verschiedene Medienästhetiken</head>
            <p style=""text-align:left;"">Genau hier erweist sich die multimodale Kombination aus 
                    <hi rend=""italic"">textueller Darstellung in Knoten und Kanten</hi> mit einem 
                    <hi rend=""italic"">Mapping der Gesamtstruktur</hi> eines Hypertextes als vielversprechend. Logische Zusammenhänge werden nämlich über Knoten und Kanten hinweg als narrative Pfade repräsentiert – mehrfach nebeneinander sowie verknüpft, daher multilinear. Gleichzeitig wird ein ikonischer Überblick über die gesamte Kohärenzstruktur gegeben. Die Nachteile der einen Modalität werden weitreichend durch die Vorteile der anderen kompensiert, was besonders relevant ist, wenn Zusammenhänge aufgrund der in ihnen angelegten Pluralität kaum linear darzustellen sind. Auch die Einbindung von Video‑ oder Bildelementen erweitert den medienästhetischen Gestaltungsspielraum. Wird das Mapping im User Interface als interaktives navigatorisches Mittel genutzt, können Knoten und Kanten vom visualisierten Kohärenzgerüst ausgehend direkt angesteuert werden. Ein derartiges Prinzip haben E-Publishing-Tools wie 
                    <hi rend=""italic"">Scalar</hi> (The Alliance for Networking Visual Culture: https://scalar.me/anvc/scalar/) längst umgesetzt, weswegen ich sie im Promotionsprojekt evaluativ heranziehe.
                </p>
            <p style=""text-align:left; "">Als eine Hauptaussage des Projektes kann gelten, dass derlei Hypertexte mitnichten allein medienpädagogisch bedeutsam sind, sondern auch eine genuin epistemische Relevanz besitzen. Schließlich verrät das multimodale Mediendesign direkt etwas über die Konstruktionsweisen und ‑bedingungen von komplexen, pluralistischen Wissensangeboten. In dieser Hinsicht möchte ich mit dem Promotionsprojekt einen theoretischen Beitrag leisten, um ein reflektiertes E-Publishing sowie die (Weiter‑)Entwicklung von E-Publishing-Tools zu unterstützen.</p>
         </div>
      </body>
      <back>
         <div type=""notes"">
            <note place=""foot"" id=""ftn1"" n=""1""> Er ist an den architektonischen Gestaltungsgrundsatz „Form follows function“ angelehnt, der von Louis H. Sullivan berühmt gemacht wurde (Sullivan 1896).</note>
         </div>
         <div type=""bibliogr"">
            <listBibl>
               <head>Bibliographie</head>
               <bibl>
                  <hi rend=""bold"">The Alliance for Networking Visual Culture:</hi>
                  <hi rend=""italic"">Scalar</hi> https://scalar.me/anvc/scalar/ [letzter Zugriff 29. Dezember 2018].
                    </bibl>
               <bibl>
                  <hi rend=""bold"">Crivellari, Fabio / Kirchmann, Kay / Sandl, Marcus / Schlögl, Rudolf (2004):</hi>
                  <hi rend=""italic"">Einleitung. Die Medialität der Geschichte und die Historizität der Medien</hi>, 
                        in: 
                        <hi rend=""bold"">Crivellari, Fabio / Kirchmann, Kay / Sandl, Marcus / Schlögl, Rudolf (eds.):</hi>
                  <hi rend=""italic"">Die Medien der Geschichte. Historizität und Medialität in interdisziplinärer Perspektive</hi> (= Historische Kulturwissenschaft 4),
                        Konstanz: UVK Verlagsgesellschaft 9-45.
                    </bibl>
               <bibl>
                  <hi rend=""bold"">Große, Franziska (2011):</hi>
                  <hi rend=""italic"">Bild-Linguistik. Grundbegriffe und Methoden der linguistischen Bildanalyse in Text- und Diskursumgebungen</hi> (= Germanistische Arbeiten zu Sprache und Kulturgeschichte 50),
                        Frankfurt a.M. / Berlin / Bern / Brüssel / New York / Oxford / Wien: Peter Lang.
                    </bibl>
               <bibl>
                  <hi rend=""bold"">Haas, Stefan (2004):</hi>
                  <hi rend=""italic"">Designing Knowledge. Theoretische und pragmatische Perspektiven der medialen Bedingungen der Erkenntnisformulierung und ‑vermittlung in den Kultur‑ und Sozialwissenschaften</hi>, 
                        in: 
                        <hi rend=""bold"">Crivellari, Fabio / Kirchmann, Kay / Sandl, Marcus / Schlögl, Rudolf (eds.):</hi>
                  <hi rend=""italic"">Die Medien der Geschichte. Historizität und Medialität in interdisziplinärer Perspektive</hi> (= Historische Kulturwissenschaft 4),
                        Konstanz: UVK Verlagsgesellschaft 211-236.
                    </bibl>
               <bibl>
                  <hi rend=""bold"">Haas, Stefan (2006):</hi>
                  <hi rend=""italic"">Vom Schreiben in Bildern. Visualität, Narrativität und digitale Medien in den historischen Wissenschaften</hi>, 
                        in: zeitenblicke 5, vol. 3: http://www.zeitenblicke.de/2006/3/Haas*index_html [letzter Zugriff 5. November 2013].
                    </bibl>
               <bibl style=""text-align:left;"">
                  <hi rend=""bold"">Krameritsch, Jakob (2007):</hi>
                  <hi rend=""italic"">Geschichte(n) im Netzwerk. Hypertext und dessen Potenziale für die Produktion, Repräsentation und Rezeption der historischen Erzählung</hi>,
                        Münster / München: Waxmann.
                    </bibl>
               <bibl style=""text-align:left;"">
                  <hi rend=""bold"">Krameritsch, Jakob (2009):</hi>
                  <hi rend=""italic"">Die fünf Typen des historischen Erzählens – im Zeitalter digitaler Medien</hi>, 
                        in: Zeithistorische Forschungen / Studies in Contemporary History 6, vol. 3: 413-432.
                    </bibl>
               <bibl style=""text-align:left;"">
                  <hi rend=""bold"">Kress, Gunther / van Leeuwen, Theo (2001):</hi>
                  <hi rend=""italic"">Multimodal Discourse The Modes and Media of Contemporary Communication</hi>, 
                        London / New York: Arnold / Oxford University Press.
                    </bibl>
               <bibl style=""text-align:left;"">
                  <hi rend=""bold"">Krippendorff, Klaus (2006):</hi>
                  <hi rend=""italic"">The Semantic Turn. A New Foundation for Design</hi>,
                        Boca Raton / London / New York: Taylor & Francis.
                    </bibl>
               <bibl style=""text-align:left;"">
                  <hi rend=""bold"">Rüsen, Jörn (2013):</hi>
                  <hi rend=""italic"">Historik. Theorie der Geschichtswissenschaft</hi>, 
                        Köln / Weimar / Wien: Böhlau.
                    </bibl>
               <bibl style=""text-align:left;"">
                  <hi rend=""bold"">Schnell, Ralf (2000):</hi>
                  <hi rend=""italic"">Medienästhetik. Zu Geschichte und Theorie audiovisueller Wahrnehmungsformen</hi>, 
                        Stuttgart: J.B. Metzler.
                    </bibl>
               <bibl style=""text-align:left;"">
                  <hi rend=""bold"">Schnell, Ralf (2001):</hi>
                  <hi rend=""italic"">Medienästhetik</hi>, 
                        in: 
                        <hi rend=""bold"">Schanze, Helmut (ed.):</hi>
                  <hi rend=""italic"">Handbuch der Mediengeschichte</hi>, Stuttgart: Kröner 72-95.
                    </bibl>
               <bibl style=""text-align:left;"">
                  <hi rend=""bold"">Staley, David J. (2014):</hi>
                  <hi rend=""italic"">Computers, Visualization, and History. How New Technology Will Transform Our Understanding of the Past</hi>, 
                        Armonk / London: M.E. Sharpe.
                    </bibl>
               <bibl style=""text-align:left;"">
                  <hi rend=""bold"">Stöckl, Hartmut (2011):</hi>
                  <hi rend=""italic"">Sprache-Bild-Texte lesen. Bausteine zur Methodik einer Grundkompetenz</hi>, 
                        in: 
                        <hi rend=""bold"">Diekmannshenke, Hajo / Klemm, Michael / Stöckl, Hartmut (eds.):</hi>
                  <hi rend=""italic"">Bildlinguistik. Theorien – Methoden – Fallbeispiele</hi> (= Philologische Studien und Quellen 228), 
                        Berlin: Erich Schmidt Verlag 45-70.
                    </bibl>
               <bibl style=""text-align:left;"">
                  <hi rend=""bold"">Stopka, Katja (2018):</hi>
                  <hi rend=""italic"">Geschichte und Literatur</hi>, 
                        in: 
                        <hi rend=""bold"">Busse, Laura / Enderle, Wilfried / Hohls, Rüdiger / Meyer, Thomas / Prellwitz, Jens / Schuhmann, Annette (eds.):</hi>
                  <hi rend=""italic"">Clio-Guide. Ein Handbuch zu digitalen Ressourcen für die Geschichtswissenschaften</hi> (= Historisches Forum 23 / Veröffentlichungen von Clio-online 2), 
                        Berlin: Clio-online und Humboldt-Universität zu Berlin E.5-1-E.5-19.
                    </bibl>
               <bibl style=""text-align:left;"">
                  <hi rend=""bold"">Storrer, Angelika (2000):</hi>
                  <hi rend=""italic"">Was ist 'hyper' am Hypertext?</hi>, in: 
                        <hi rend=""bold"">Kallmeyer, Werner (ed.):</hi>
                  <hi rend=""italic"">Sprache und neue Medien</hi> 
                        (= Institut für deutsche Sprache. Jahrbuch 1999). Berlin: De Gruyter 222-249.
                    </bibl>
               <bibl style=""text-align:left;"">
                  <hi rend=""bold"">Storrer, Angelika (2004):</hi>
                  <hi rend=""italic"">Kohärenz in Hypertexten</hi>, 
                        in: Zeitschrift für germanistische Linguistik 31, vol. 2: 274-292.
                    </bibl>
               <bibl style=""text-align:left;"">
                  <hi rend=""bold"">Sullivan, Louis H. (1896):</hi>
                  <hi rend=""italic"">The Tall Office Building Artistically Considered</hi>, 
                        in: Lippincott’s Magazine 57: 403-409.
                    </bibl>
               <bibl style=""text-align:left;"">
                  <hi rend=""bold"">Weber, Stefan (2010):</hi>
                  <hi rend=""italic"">Konstruktivistische Medientheorien</hi>, 
                        in: 
                        <hi rend=""bold"">Weber, Stefan (ed.):</hi>
                  <hi rend=""italic"">Theorien der Medien. Von der Kulturkritik bis zum Konstruktivismus</hi> 
                        (= UTB 2424). Konstanz: UVK Verlagsgesellschaft 170-188.
                    </bibl>
               <bibl style=""text-align:left;"">
                  <hi rend=""bold"">Winko, Simone (2005):</hi>
                  <hi rend=""italic"">Hyper – Text – Literatur. Digitale Literatur als Herausforderung an die Literaturwissenschaft</hi>, 
                        in: 
                        <hi rend=""bold"">Segeberg, Harro / Winko, Simone (eds.):</hi>
                  <hi rend=""italic"">Digitalität und Literalität. Zur Zukunft der Literatur</hi>, München: W. Fink 137-157.
                    </bibl>
               <bibl style=""text-align:left;"">
                  <hi rend=""bold"">Winko, Simone (2008):</hi>
                  <hi rend=""italic"">Lost in hypertext? Autorkonzepte und neue Medien</hi>, 
                        in: 
                        <hi rend=""bold"">Jannidis, Fotis / Lauer, Gerhard / Martinez, Matias / Winko, Simone (eds.):</hi>
                  <hi rend=""italic"">Rückkehr des Autors. Zur Erneuerung eines umstrittenen Begriffs</hi> 
                        (= Studien und Texte zur Sozialgeschichte der Literatur 71). Tübingen: Max Niemeyer Verlag 511-533.
                    </bibl>
               <bibl style=""text-align:left; "">
                  <hi rend=""bold"">Zitterbarth, Walter (1991):</hi>
                  <hi rend=""italic"">Der Erlanger Konstruktivismus in seiner Beziehung zum konstruktiven Realismus</hi>, 
                        in: 
                        <hi rend=""bold"">Peschl, Markus F. (ed.):</hi>
                  <hi rend=""italic"">Formen des Konstruktivismus in der Diskussion. Materialien zu den ""Acht Vorlesungen über den Konstruktiven Realismus""</hi> 
                        (= Cognitive Science 2). Wien: Wiener Universitätsverlag 73-87.
                    </bibl>
            </listBibl>
         </div>
      </back>
   </text>

",xml,Creative Commons Attribution 4.0 International,,e-publishing;hypertext;wissensrepräsentation,German,gestaltung;kommunikation;multimodale kommunikation;schreiben;veröffentlichung;visualisierung
11809,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,How to Set Up a Web Server for Teaching and Research in the Humanities,,Lisa Tagliaferri,workshop / tutorial,"<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p style=""text-align: left; "">This workshop will go over how to complete an initial Linux server setup for use with the web. We will go over security, firewalls, HTTPS, and high availability. Administering one’s own server rather than relying on managed web hosting empowers researchers, teachers, and students by providing them with complete control over their web assets. The resulting setup can be used for webapps, static sites like Jekyll and Hugo, or more robust sites like WordPress, Omeka, Scalar, and Drupal. These will be ready for use with domain names. In addition to providing an entry point to the web, servers can also enable teams of researchers and students to collaborate on programming projects or access shared data. </p>
        </body>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,devops;linux;web development;web server,English,"computer science;contemporary;english;global;humanities computing;public humanities collaborations and methods;software development, systems, analysis and methods"
11882,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Low-stakes activities for text analysis instruction in the undergraduate classroom,,Marcela Y. Isuster,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p style=""text-align: left; "">The introduction of digital text analysis tools and methodologies in (non-digital) humanities undergraduate courses has been sparsely documented in the literature. Furthermore, most of the times we encounter it, it is done in the context of semester-long or mid-term projects (Boyle and Hall 2016; Ficke 2014), where the stakes for the students are very high. Other times, they include a session on text analysis but no practical application of the tools and methodologies discussed in the course, other than a follow along demonstration.</p>
            <p style=""text-align: left; "">This short paper introduces a middle point between these two extremes through the introduction of low stakes activities and assignments to help student discover and use digital text analysis tools and methodologies.</p>
            <p style=""text-align: left; "">Besides giving students the opportunity to interact with the material in a safe and relaxed manner, low stakes activities help with student retention, confidence, and relationship building (Hamilton 2020; Meer and Chapman 2014). Low stakes activities are also a useful tool to assess comprehension and instruction when the person delivering the lesson is not the regular or official instructor in the course, such as the case of a librarian or a guest speaker. Furthermore, these types of activities are particularly useful for digital humanities instruction because they contribute to scaffolding, a method that has been identified as ideal in this type of instruction (Griffin and Taylor 2017; Isuster 2020; Sample and Schrum 2013; Tracy and Hoiem, 2018).</p>
            <p style=""text-align: left; "">In the context of a Hispanic Studies course, a librarian offered a workshop series on digital text analysis and the web-based reading and analysis environment Voyant Tools. Interspersed with instruction there were a series of low stakes assessments that helped students understand and apply the content of the workshops. Working with the class readings, the librarian created activities that did not rely on having a single answer but encouraged students to discuss and interrogate both the methods and the information used. For example, when preparing a text for text analysis, students debated how different research questions necessitate different text preparation. The activities were completed in groups and were not graded. Results were discussed within the class.</p>
            <p style=""text-align: left; "">The short paper presentation will explore the process of creating and implementing low stakes activities for digital text analysis and other digital humanities instruction. It will discuss the benefits of these types of activities as they pertain to digital humanities instruction and engagement and will share best practices and tips to help attendees create these kinds of activities in their own classrooms, including assignment design and sourcing materials.</p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl style=""text-align: left;"">Boyle, M. and Hall, C. (2016) ‘Teaching “Don Quixote” in the Digital Age: Page and Screen, Visual and Tactile’, 
                        <hi rend=""italic"">Hispania</hi>, 99(4), pp. 600–614.
                    </bibl>
                    <bibl style=""text-align: left;"">Ficke, S.H. (2014) ‘From Text to Tags: The Digital Humanities in an Introductory Literature Course’, 
                        <hi rend=""italic"">CEA Critic</hi>, 76(2), pp. 200–210. 
                        <ref target=""https://doi.org/10.1353/cea.2014.0012"">10.1353/cea.2014.0012</ref>.
                    </bibl>
                    <bibl style=""text-align: left;"">Griffin, M. and Taylor, T.I. (2017) ‘Shifting expectations: Revisiting core concepts of academic librarianship in undergraduate classes with a digital humanities focus’, 
                        <hi rend=""italic"">College & Undergraduate Libraries</hi>, 24(2–4), pp. 452–466. 
                        <ref target=""https://doi.org/10.1080/10691316.2017.1325346"">10.1080/10691316.2017.1325346</ref>.
                    </bibl>
                    <bibl style=""text-align: left;"">Hamilton, M. (2020) ‘Implementation of a low-stakes daily assessment in a large introductory LAC course’, 
                        <hi rend=""italic"">Teaching and Assessment Symposium</hi> [Preprint]. Available at: 
                        <ref target=""https://digscholarship.unco.edu/posters_2020/4"">https://digscholarship.unco.edu/posters_2020/4</ref>.
                    </bibl>
                    <bibl style=""text-align: left;"">Isuster, M.Y. (2020) ‘From students to authors: Fostering student content creation with Scalar’, 
                        <hi rend=""italic"">College & Undergraduate Libraries</hi>, 27(2-4), pp. 133–148. 
                        <ref target=""https://doi.org/10.1080/10691316.2020.1830908"">10.1080/10691316.2020.1830908</ref>.
                    </bibl>
                    <bibl style=""text-align: left;"">Meer, N.M. and Chapman, A. (2014) ‘Assessment for confidence: Exploring the impact that low-stakes assessment design has on student retention’, 
                        <hi rend=""italic"">The International Journal of Management Education</hi>, 12(2), pp. 186–192. 
                        <ref target=""https://doi.org/10.1016/j.ijme.2014.01.003"">10.1016/j.ijme.2014.01.003</ref>.
                    </bibl>
                    <bibl style=""text-align: left;"">Sample, M. and Schrum, K. (2013) ‘What’s Wrong with Writing Essays: A Conversation’, in Cohen, D.J. and Scheinfedlt, J.T. (eds) 
                        <hi rend=""italic"">Hacking the academy : new approaches to scholarship and teaching from digital humanities</hi>. Ann Arbor, MI: University of Michigan Press, pp. 87–96.
                    </bibl>
                    <bibl style=""text-align: left;"">Tracy, D.G. and Hoiem, E.M. (2018) ‘Scaffolding and Play Approaches to Digital Humanities Pedagogy: Assessment and Iteration in Topically-Driven Courses’, 
                        <hi rend=""italic"">Digital Humanities Quarterly</hi>, 11(4). Available at: 
                        <ref target=""http://digitalhumanities.org:8081/dhq/vol/11/4/000358/000358.html"">http://digitalhumanities.org:8081/dhq/vol/11/4/000358/000358.html</ref>.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,assessment;instruction;pedagogy;text analysis,English,contemporary;curricular and pedagogical development and analysis;education/ pedagogy;english;global;library & information science;text mining and analysis
11998,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,Detecting Latent Textual Bias with Topic Modeling and Sentiment Analysis,,Ashley Sanders,"paper, specified ""short paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <p>Bias detection is an emerging area of research for digital humanists, computational linguists, and information studies scholars, alike, who point to biases inherent in our algorithms, software, tools, and platforms, but we are only just beginning to examine how computational methods could be used to interrogate our primary textual sources 
                <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""Vj2SctZ0"",""properties"":{""formattedCitation"":""(Noble, 2018; Al-Sarraj and Lubbad, 2018; Chen et al., 2020)"",""plainCitation"":""(Noble, 2018; Al-Sarraj and Lubbad, 2018; Chen et al., 2020)"",""noteIndex"":0},""citationItems"":[{""id"":4550,""uris"":[""http://zotero.org/users/227324/items/Y2DL9XJK""],""itemData"":{""id"":4550,""type"":""book"",""event-place"":""New York"",""ISBN"":""978-1-4798-3724-3"",""language"":""English"",""note"":""section: xv, 229 pages : illustrations ; 23 cm"",""number-of-pages"":""xv, 229"",""publisher"":""New York University Press"",""publisher-place"":""New York"",""source"":""WorldCat Discovery Service"",""title"":""Algorithms of Oppression: How Search Engines Reinforce Racism"",""title-short"":""Algorithms of Oppression"",""author"":[{""family"":""Noble"",""given"":""Safiya Umoja""}],""accessed"":{""date-parts"":[[""2021"",5,19]]},""issued"":{""date-parts"":[[""2018""]]}}},{""id"":4494,""uris"":[""http://zotero.org/users/227324/items/ISFK4VNP""],""itemData"":{""id"":4494,""type"":""paper-conference"",""abstract"":""The online mass media plays a critical role in influencing the public opinion about controversial political events. Bias in press reports and articles to some ideological or political sides is common and opposites the neutrality nature of press and media. Bias can take different aspects and ways. One of the main aspects of press bias is using mislead terms and vocabularies. In summer 2014, Western media, news and press agencies covered Israeli war on Gaza. In general, Palestinian people complain that there is a notable bias in western media with the Israeli story and opinion and vice versa. In this research paper we report a text mining experimental study, that's have conducted on western media analysis to identify patterns in the press orientation and further in the media bias towards side to another. We have followed the text mining techniques and machine learning in an effort to detect the bias in news agencies. We have crawled news articles form seven major outlets in the western media. Then we have made preprocessing to convert them into useful structured form, building sentiment classifiers that be able to predict articles bias. In addition, we have compared three of supervised machine learning algorithms used in sentiment classification associated with different number of grams, where we have found that SVM with bio-gram gave the better outperformed outputs, with performance metrics are 91.76% accuracy, 88.33% recall and f- measure 91.46%."",""container-title"":""2018 International Conference on Promising Electronic Technologies (ICPET)"",""DOI"":""10.1109/ICPET.2018.00024"",""event"":""2018 International Conference on Promising Electronic Technologies (ICPET)"",""page"":""98-103"",""source"":""IEEE Xplore"",""title"":""Bias Detection of Palestinian/Israeli Conflict in Western Media: A Sentiment Analysis Experimental Study"",""title-short"":""Bias Detection of Palestinian/Israeli Conflict in Western Media"",""author"":[{""family"":""Al-Sarraj"",""given"":""Wael F.""},{""family"":""Lubbad"",""given"":""Heba M.""}],""issued"":{""date-parts"":[[""2018"",10]]}}},{""id"":4470,""uris"":[""http://zotero.org/users/227324/items/FZFPS9SR""],""itemData"":{""id"":4470,""type"":""article-journal"",""abstract"":""Media plays an important role in shaping public opinion. Biased media can influence people in undesirable directions and hence should be unmasked as such. We observe that featurebased and neural text classification approaches which rely only on the distribution of low-level lexical information fail to detect media bias. This weakness becomes most noticeable for articles on new events, where words appear in new contexts and hence their \""bias predictiveness\"" is unclear. In this paper, we therefore study how second-order information about biased statements in an article helps to improve detection effectiveness. In particular, we utilize the probability distributions of the frequency, positions, and sequential order of lexical and informational sentence-level bias in a Gaussian Mixture Model. On an existing media bias dataset, we find that the frequency and positions of biased statements strongly impact article-level bias, whereas their exact sequential order is secondary. Using a standard model for sentence-level bias detection, we provide empirical evidence that article-level bias detectors that use second-order information clearly outperform those without."",""container-title"":""arXiv:2010.10649 [cs]"",""note"":""arXiv: 2010.10649"",""source"":""arXiv.org"",""title"":""Detecting Media Bias in News Articles using Gaussian Bias Distributions"",""URL"":""http://arxiv.org/abs/2010.10649"",""author"":[{""family"":""Chen"",""given"":""Wei-Fan""},{""family"":""Al-Khatib"",""given"":""Khalid""},{""family"":""Stein"",""given"":""Benno""},{""family"":""Wachsmuth"",""given"":""Henning""}],""accessed"":{""date-parts"":[[""2021"",5,12]]},""issued"":{""date-parts"":[[""2020"",10,20]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Noble, 2018; Al-Sarraj and Lubbad, 2018; Chen et al., 2020). This project seeks to develop a method for bias detection that can be used at the outset of a study with little initial knowledge of the corpus, requires little pre-processing and is both beginner-friendly and language-agnostic. Word2Vec and similarity measures allow us to compare a test corpus against a comparison corpus of biased or neutral terms. This works especially well with contemporary texts, such as online news articles in English, but it becomes an increasingly difficult task with historical or non-English language sources to find appropriate comparative corpora 
                <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""I6s4sENs"",""properties"":{""formattedCitation"":""(Patankar and Bose, 2017)"",""plainCitation"":""(Patankar and Bose, 2017)"",""noteIndex"":0},""citationItems"":[{""id"":4497,""uris"":[""http://zotero.org/users/227324/items/96NGHHYP""],""itemData"":{""id"":4497,""type"":""paper-conference"",""abstract"":""Given the ongoing controversy over biased news, it would be useful to have a system that can detect the extent of bias in online news articles and indicate it to the user in real time. Here we measure bias in a given sentence or article as the word vector similarity with a corpus of biased words. We compute the word vector similarity of each of the sentences with the words taken from a Wikipedia Neutral Point of View (NPOV) corpus, measured using the word2vec tool, where our model is trained using Wikipedia articles. We then compute the bias score, which indicates how much that article uses biased words. This is implemented as a web browser extension, which queries an online server running our bias detection algorithm. Finally, we validate the accuracy of our bias detection by comparing bias rankings of a variety of articles from various sources. We get lower bias scores for Wikipedia articles than for news articles, which is lower than that for opinion articles."",""container-title"":""2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA)"",""DOI"":""10.1109/ICMLA.2017.00-62"",""event"":""2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA)"",""page"":""785-788"",""source"":""IEEE Xplore"",""title"":""Bias Discovery in News Articles Using Word Vectors"",""author"":[{""family"":""Patankar"",""given"":""Anish Anil""},{""family"":""Bose"",""given"":""Joy""}],""issued"":{""date-parts"":[[""2017"",12]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Patankar and Bose, 2017). Building classifiers to identify bias with feature extraction, support vector machine learning algorithms, decision trees, and naïve Bayes approaches work well but require a deep understanding of the corpus and are not accessible to those who are new to computation.
                <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""xjcGKJmT"",""properties"":{""formattedCitation"":""(Al-Sarraj and Lubbad, 2018; Leavy, 2019; Manzini et al., 2019)"",""plainCitation"":""(Al-Sarraj and Lubbad, 2018; Leavy, 2019; Manzini et al., 2019)"",""noteIndex"":0},""citationItems"":[{""id"":4494,""uris"":[""http://zotero.org/users/227324/items/ISFK4VNP""],""itemData"":{""id"":4494,""type"":""paper-conference"",""abstract"":""The online mass media plays a critical role in influencing the public opinion about controversial political events. Bias in press reports and articles to some ideological or political sides is common and opposites the neutrality nature of press and media. Bias can take different aspects and ways. One of the main aspects of press bias is using mislead terms and vocabularies. In summer 2014, Western media, news and press agencies covered Israeli war on Gaza. In general, Palestinian people complain that there is a notable bias in western media with the Israeli story and opinion and vice versa. In this research paper we report a text mining experimental study, that's have conducted on western media analysis to identify patterns in the press orientation and further in the media bias towards side to another. We have followed the text mining techniques and machine learning in an effort to detect the bias in news agencies. We have crawled news articles form seven major outlets in the western media. Then we have made preprocessing to convert them into useful structured form, building sentiment classifiers that be able to predict articles bias. In addition, we have compared three of supervised machine learning algorithms used in sentiment classification associated with different number of grams, where we have found that SVM with bio-gram gave the better outperformed outputs, with performance metrics are 91.76% accuracy, 88.33% recall and f- measure 91.46%."",""container-title"":""2018 International Conference on Promising Electronic Technologies (ICPET)"",""DOI"":""10.1109/ICPET.2018.00024"",""event"":""2018 International Conference on Promising Electronic Technologies (ICPET)"",""page"":""98-103"",""source"":""IEEE Xplore"",""title"":""Bias Detection of Palestinian/Israeli Conflict in Western Media: A Sentiment Analysis Experimental Study"",""title-short"":""Bias Detection of Palestinian/Israeli Conflict in Western Media"",""author"":[{""family"":""Al-Sarraj"",""given"":""Wael F.""},{""family"":""Lubbad"",""given"":""Heba M.""}],""issued"":{""date-parts"":[[""2018"",10]]}}},{""id"":3557,""uris"":[""http://zotero.org/users/227324/items/UEIH6I5H""],""itemData"":{""id"":3557,""type"":""article-journal"",""container-title"":""Digital Scholarship in the Humanities"",""DOI"":""10.1093/llc/fqy005"",""ISSN"":""2055-7671, 2055-768X"",""issue"":""1"",""language"":""en"",""page"":""48-63"",""source"":""DOI.org (Crossref)"",""title"":""Uncovering gender bias in newspaper coverage of Irish politicians using machine learning"",""volume"":""34"",""author"":[{""family"":""Leavy"",""given"":""Susan""}],""issued"":{""date-parts"":[[""2019"",4,1]]}}},{""id"":4529,""uris"":[""http://zotero.org/users/227324/items/55KLCB7U""],""itemData"":{""id"":4529,""type"":""article-journal"",""abstract"":""Online texts—across genres, registers, domains, and styles—are riddled with human stereotypes, expressed in overt or subtle ways. Word embeddings, trained on these texts, perpetuate and amplify these stereotypes, and propagate biases to machine learning models that use word embeddings as features. In this work, we propose a method to debias word embeddings in multiclass settings such as race and religion, extending the work of (Bolukbasi et al., 2016) from the binary setting, such as binary gender. Next, we propose a novel methodology for the evaluation of multiclass debiasing. We demonstrate that our multiclass debiasing is robust and maintains the efﬁcacy in standard NLP tasks."",""container-title"":""arXiv:1904.04047 [cs, stat]"",""language"":""en"",""note"":""arXiv: 1904.04047"",""source"":""arXiv.org"",""title"":""Black is to Criminal as Caucasian is to Police: Detecting and Removing Multiclass Bias in Word Embeddings"",""title-short"":""Black is to Criminal as Caucasian is to Police"",""URL"":""http://arxiv.org/abs/1904.04047"",""author"":[{""family"":""Manzini"",""given"":""Thomas""},{""family"":""Lim"",""given"":""Yao Chong""},{""family"":""Tsvetkov"",""given"":""Yulia""},{""family"":""Black"",""given"":""Alan W.""}],""accessed"":{""date-parts"":[[""2021"",5,12]]},""issued"":{""date-parts"":[[""2019"",7,1]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Al-Sarraj and Lubbad, 2018; Leavy, 2019; Manzini et al., 2019) Therefore, with the aforementioned aims in mind, I chose to use the latent Dirichlet allocation (LDA) algorithm for topic modeling to study a set of three chronicles covering the 300 years of Ottoman Algerian history, written in French by two nineteenth-century French scholars and one twentieth-century Algerian scholar (Vayssettes, 1867; Mercier, 1903; Gaïd, 1978).
                <note place=""foot"" xml:id=""ftn1"" n=""1"">
                    <p rend=""footnote text""> For more details on the authors, see the introductory chapter and/or the README on my GitHub repository for this project, available at 
                        <ref target=""https://github.com/AshleySanders/OttomanAlgeria/"">
                            https://github.com/AshleySanders/OttomanAlgeria/
                        </ref>. It should also be noted that I have not included the one additional Algerian chronicle of these governors, written in Arabic, because the LDA algorithm separates topics by language first and then by significant collocations, which would not help me identify common themes that cut across three centuries, individual biographies, and sources/authors. For those interested in topic modeling a collection of Arabic documents, see Richard Nielsen’s introduction using R: 
                        <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""AVHQx7Pu"",""properties"":{""formattedCitation"":""Richard Nielsen, \\uc0\\u8220{}Quantitative Text Analysis in Arabic,\\uc0\\u8221{} {\\i{}Http://Www.Mit.Edu/~rnielsen/ArabicTextWorkshop.ZipSlides:Http://Www.Mit.Edu/~rnielsen/Arabic_text_slides.Pdfhttp://Www.Mit.Edu/~rnielsen/> \\uc0\\u8220{}Helpful Stuff\\uc0\\u8221{} (at the Bottom)} (Workshop, Cairo University, April 4, 2019), http://www.mit.edu/~rnielsen/arabic_text_slides.pdf."",""plainCitation"":""Richard Nielsen, “Quantitative Text Analysis in Arabic,” Http://Www.Mit.Edu/~rnielsen/ArabicTextWorkshop.ZipSlides:Http://Www.Mit.Edu/~rnielsen/Arabic_text_slides.Pdfhttp://Www.Mit.Edu/~rnielsen/> “Helpful Stuff” (at the Bottom) (Workshop, Cairo University, April 4, 2019), http://www.mit.edu/~rnielsen/arabic_text_slides.pdf."",""dontUpdate"":true,""noteIndex"":2},""citationItems"":[{""id"":4560,""uris"":[""http://zotero.org/users/227324/items/LDDHLFE9""],""itemData"":{""id"":4560,""type"":""speech"",""event-place"":""Cairo University"",""genre"":""Workshop"",""language"":""en"",""publisher-place"":""Cairo University"",""title"":""Quantitative Text Analysis in Arabic"",""URL"":""http://www.mit.edu/~rnielsen/arabic_text_slides.pdf"",""author"":[{""family"":""Nielsen"",""given"":""Richard""}],""accessed"":{""date-parts"":[[""2021"",5,19]]},""issued"":{""date-parts"":[[""2019"",4,4]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>Richard Nielsen, “Quantitative Text Analysis in Arabic,” (Workshop, Cairo University, April 4, 2019), accessed May 6, 2021, http://www.mit.edu/~rnielsen/arabic_text_slides.pdf.
                    </p>
                </note>
            </p>
            <p>At just 138 documents and approximately 183,000 words, the corpus is much smaller than one normally uses for topic modeling, but its manageable size made it a promising test case for this approach. The scalar feature of the LDA algorithm was particularly interesting to examine, as the topics of each larger, more detailed model neatly nested under the model with the next most topics, creating a hierarchy.
                <note place=""foot"" xml:id=""ftn2"" n=""2"">
                    <p rend=""footnote text"">
                        <hi rend=""color(222222)"">The resulting nested or hierarchical model visualizes major and minor themes in the authors’ perceptions and presentations of Ottoman gubernatorial histories. Jo Guldi and Benjamin Williams applied a similar approach to British Parliamentary discourse to reveal previously invisible connections between speeches and political tactics, but, as this chapter shows, the method is also useful for text summarization and bias detection.</hi>
                        <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""yKbNSSop"",""properties"":{""formattedCitation"":""(Guldi and Williams, 2018)"",""plainCitation"":""(Guldi and Williams, 2018)"",""noteIndex"":3},""citationItems"":[{""id"":4302,""uris"":[""http://zotero.org/users/227324/items/8D4TUA75""],""itemData"":{""id"":4302,""type"":""article-journal"",""abstract"":""Scholars need tools that will allow them to generalize about the fit of themes, events, and rhetorical styles represented in a body of texts. In this article, we introduce the concept of “nested topics,” an approach to topic modeling large-scale textual corpora that highlights implicit ontologies and relationships within the texts themselves. This tool exploits the fact that topic modeling can be used to generalize about topics on an aggregate level as well as a fine-grained level, an approach that has the consequences of revealing overarching themes that appear across all texts as well as more idosyncratic events and rehtorical styles that adhere to only a few documents. The tool’s effectiveness is tested by modeling discussions of property in British parliamentary debates in the nineteenth century. Nested topics help the authors to locate the rhetorical styles engaged in by Irish parliamentarians as they defended tenant rights in the 1880s."",""container-title"":""Current Research in Digital History"",""DOI"":""https://doi.org/10.31835/crdh.2018.01"",""ISSN"":""2637-5923"",""journalAbbreviation"":""CRDH"",""language"":""en"",""source"":""crdh.rrchnm.org"",""title"":""Synthesis and Large-Scale Textual Corpora: A Nested Topic Model of Britain’s Debates over Landed Property in the Nineteenth Century"",""title-short"":""Synthesis and Large-Scale Textual Corpora"",""URL"":""https://crdh.rrchnm.org/essays/v01-01-synthesis-and-large-scale-textual-corpora/"",""volume"":""1"",""author"":[{""family"":""Guldi"",""given"":""Jo""},{""family"":""Williams"",""given"":""Benjamin""}],""accessed"":{""date-parts"":[[""2021"",1,11]]},""issued"":{""date-parts"":[[""2018""]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Guldi and Williams, 2018) 
                    </p>
                </note> Nesting models of 4-, 7-, 11-, and 20-topics provided a detailed summary of the corpus, with the 4-topic model serving as a general overview, and the 20-topic model offering a glimpse into the richness of the region’s history with topics related to some of the dominant themes of the corpus, such as “governance and succession,” but also much more granular themes, including “illness, death, burial, and remembrance,” and the “roles of women.” Pairing topic models at different scales (4-, 7-, 11-, and 20-topics) with sentiment analysis of the topic models at 11- and 20-topics, as well as targeted close reading, guided by topics of interest and using the concordance method to identify passages with key terms of interest uncovered the stories of lesser known actors, including women, Jews, Spaniards, and the councilmen of provincial governors, as well as biases inherent in the writing of their histories 
                <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""NpXji3ov"",""properties"":{""formattedCitation"":""(Ghasiya and Okamura, 2021)"",""plainCitation"":""(Ghasiya and Okamura, 2021)"",""noteIndex"":0},""citationItems"":[{""id"":4945,""uris"":[""http://zotero.org/users/227324/items/9W4FM4TS""],""itemData"":{""id"":4945,""type"":""article-journal"",""abstract"":""For Japan—a country that has always been described with virtually no major natural resources such as oil, gas, and coal—the Middle Eastern region has a special place in its economic and foreign policy. In 2017, 39% of Japan’s energy came from oil, and 87% of Japan’s imported oil came from the Middle East, predominantly Saudi Arabia and the UAE. The above facts are enough to discern the critical significance of the Middle Eastern region for Japan. For Japan to have an unhindered supply of oil and other natural resources, it is pertinent that this region remains peaceful. In this scenario, the Middle East-related articles in Japan’s newspapers can help understand Japan’s perspective towards the Middle East. This paper would first apply the topic modelling approach non-negative matrix factorization (NMF) on Middle East-related articles from three newspapers of Japan. After discovering crucial topics, we would utilize traditional supervised machine learning algorithms to determine the overall and topic-specific sentiments from the collected headlines. Our topic modelling results discovered that the Japanese media widely reported issues like Islamic State, the refugee crisis, the Syrian civil war, Qasem Soleimani killing, and Iran nuclear deal. Further, the news related to Saudi Arabia, Syria, and Trump garnered high negative sentiment."",""container-title"":""Digital Scholarship in the Humanities"",""DOI"":""10.1093/llc/fqab019"",""ISSN"":""2055-7671"",""issue"":""fqab019"",""journalAbbreviation"":""Digital Scholarship in the Humanities"",""source"":""Silverchair"",""title"":""Understanding the Middle East through the eyes of Japan’s Newspapers: A topic modelling and sentiment analysis approach"",""title-short"":""Understanding the Middle East through the eyes of Japan’s Newspapers"",""URL"":""https://doi.org/10.1093/llc/fqab019"",""author"":[{""family"":""Ghasiya"",""given"":""Piyush""},{""family"":""Okamura"",""given"":""Koji""}],""accessed"":{""date-parts"":[[""2021"",6,19]]},""issued"":{""date-parts"":[[""2021"",3,13]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Ghasiya and Okamura, 2021). 
            </p>
            <p>The anti-Arab and/or anti-Turkish sentiments one might expect to observe were absent, but a latent anti-Semitic sentiment appeared in the more granular topic models that, despite my careful reading of the texts, had escaped my notice. The resulting model aids the scholar in weaving the disparate threads of these individuals’ lives into the tapestry of the region’s history, and the method may well be applied to other corpora, topics, languages, and time periods to reveal hidden biases, especially in larger collections of documents that would be impossible for a single scholar to read. I am currently testing this bias detection method with additional corpora and this presentation will briefly report the results of these trials along with the original study.</p>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"" style=""font-family:Garamond;font-size:12pt"">Al-Sarraj, W. F. and Lubbad, H. M.</hi>
                        <hi style=""font-family:Garamond;font-size:12pt"" xml:space=""preserve""> (2018). Bias Detection of Palestinian/Israeli Conflict in Western Media: A Sentiment Analysis Experimental Study. </hi>
                        <hi rend=""italic"" style=""font-family:Garamond;font-size:12pt"">2018 International Conference on Promising Electronic Technologies (ICPET)</hi>
                        . pp. 98–103 doi:10.1109/ICPET.2018.00024.
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"" style=""font-family:Garamond;font-size:12pt"">Chen, W.-F., Al-Khatib, K., Stein, B. and Wachsmuth, H.</hi>
                        <hi style=""font-family:Garamond;font-size:12pt"" xml:space=""preserve""> (2020). Detecting Media Bias in News Articles using Gaussian Bias Distributions. </hi>
                        <hi rend=""italic"" style=""font-family:Garamond;font-size:12pt"">ArXiv:2010.10649 [Cs]</hi>
                        <hi style=""font-family:Garamond;font-size:12pt"" xml:space=""preserve""> http://arxiv.org/abs/2010.10649 (accessed 12 May 2021).</hi>
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"" style=""font-family:Garamond;font-size:12pt"">Ghasiya, P. and Okamura, K.</hi>
                        <hi style=""font-family:Garamond;font-size:12pt"" xml:space=""preserve""> (2021). Understanding the Middle East through the eyes of Japan’s Newspapers: A topic modelling and sentiment analysis approach. </hi>
                        <hi rend=""italic"" style=""font-family:Garamond;font-size:12pt"">Digital Scholarship in the Humanities</hi>
                        (fqab019) doi:10.1093/llc/fqab019. https://doi.org/10.1093/llc/fqab019 (accessed 19 June 2021).
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"" style=""font-family:Garamond;font-size:12pt"">Guldi, J. and Williams, B.</hi>
                        <hi style=""font-family:Garamond;font-size:12pt"" xml:space=""preserve""> (2018). Synthesis and Large-Scale Textual Corpora: A Nested Topic Model of Britain’s Debates over Landed Property in the Nineteenth Century. </hi>
                        <hi rend=""italic"" style=""font-family:Garamond;font-size:12pt"">Current Research in Digital History</hi>
                        <hi style=""font-family:Garamond;font-size:12pt"" xml:space=""preserve"">, </hi>
                        <hi rend=""bold"" style=""font-family:Garamond;font-size:12pt"">1</hi>
                        doi:https://doi.org/10.31835/crdh.2018.01. https://crdh.rrchnm.org/essays/v01-01-synthesis-and-large-scale-textual-corpora/ (accessed 11 January 2021).
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"" style=""font-family:Garamond;font-size:12pt"">Leavy, S.</hi>
                        <hi style=""font-family:Garamond;font-size:12pt"" xml:space=""preserve""> (2019). Uncovering gender bias in newspaper coverage of Irish politicians using machine learning. </hi>
                        <hi rend=""italic"" style=""font-family:Garamond;font-size:12pt"">Digital Scholarship in the Humanities</hi>
                        <hi style=""font-family:Garamond;font-size:12pt"" xml:space=""preserve"">, </hi>
                        <hi rend=""bold"" style=""font-family:Garamond;font-size:12pt"">34</hi>
                        (1): 48–63 doi:10.1093/llc/fqy005.
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"" style=""font-family:Garamond;font-size:12pt"">Manzini, T., Lim, Y. C., Tsvetkov, Y. and Black, A. W.</hi>
                        <hi style=""font-family:Garamond;font-size:12pt"" xml:space=""preserve""> (2019). Black is to Criminal as Caucasian is to Police: Detecting and Removing Multiclass Bias in Word Embeddings. </hi>
                        <hi rend=""italic"" style=""font-family:Garamond;font-size:12pt"">ArXiv:1904.04047 [Cs, Stat]</hi>
                        <hi style=""font-family:Garamond;font-size:12pt"" xml:space=""preserve""> http://arxiv.org/abs/1904.04047 (accessed 12 May 2021).</hi>
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"" style=""font-family:Garamond;font-size:12pt"">Nielsen, R.</hi>
                        <hi style=""font-family:Garamond;font-size:12pt"" xml:space=""preserve""> (2019). Quantitative Text Analysis in Arabic Workshop Cairo University http://www.mit.edu/~rnielsen/arabic_text_slides.pdf (accessed 19 May 2021).</hi>
                    </bibl>
                    <bibl rend=""Bibliography"">
                        <hi rend=""bold"" style=""font-family:Garamond;font-size:12pt"">Noble, S. U.</hi>
                        <hi style=""font-family:Garamond;font-size:12pt"" xml:space=""preserve""> (2018). </hi>
                        <hi rend=""italic"" style=""font-family:Garamond;font-size:12pt"">Algorithms of Oppression: How Search Engines Reinforce Racism</hi>
                        . New York: New York University Press (accessed 19 May 2021).
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"" style=""font-family:Garamond;font-size:12pt"">Patankar, A. A. and Bose, J.</hi>
                        <hi style=""font-family:Garamond;font-size:12pt"" xml:space=""preserve""> (2017). Bias Discovery in News Articles Using Word Vectors. </hi>
                        <hi rend=""italic"" style=""font-family:Garamond;font-size:12pt"">2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA)</hi>
                        . pp. 785–88 doi:10.1109/ICMLA.2017.00-62.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,bias detection;sentiment analysis;topic modeling,English,15th-17th century;18th century;19th century;africa;cultural studies;english;europe;history;natural language processing;text mining and analysis
12048,2022 - Tokyo,Tokyo,Responding to Asian Diversity,2022-01-01T00:00:00Z,ADHO,ADHO,,Tokyo,,Japan,https://dh2022.adho.org/,"Computational approaches to literary periodization: an experiment in Italian narrative of 19""th"" and 20""th"" century",,Fabio Ciotti,"paper, specified ""long paper""","<text xmlns=""http://www.tei-c.org/ns/1.0"" xml:lang=""en"">
        <body>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Theoretical background</head>
                <p style=""text-align: left; "">Periodization is one of the fundamental topics of literary studies. As Rene Wellek puts it in one of the most notorious and important books of the last century theory of literature: “the concept of period is certainly one of the main instruments of historical knowledge”, meaning, of course, literary-historical knowledge. 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""MHb3gcBk"",""properties"":{""formattedCitation"":""(Wellek, 1956: 268)"",""plainCitation"":""(Wellek, 1956: 268)"",""noteIndex"":0},""citationItems"":[{""id"":23068,""uris"":[""http://zotero.org/users/563326/items/X69H59ED""],""uri"":[""http://zotero.org/users/563326/items/X69H59ED""],""itemData"":{""id"":23068,""type"":""book"",""archive"":""/z-wcorg/"",""event-place"":""New York"",""ISBN"":""0-15-689084-4"",""language"":""English"",""publisher"":""Harcourt, Brace & World"",""publisher-place"":""New York"",""source"":""http://worldcat.org"",""title"":""Theory of literature"",""author"":[{""family"":""Wellek"",""given"":""Ren??."",""suffix"":""Warren, Austin,,""}],""issued"":{""date-parts"":[[""1956""]]}},""locator"":""268""}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Wellek, 1956: 268). And yet is one of the most controversial and debated:
                </p>
                <quote>It is virtually impossible to divide periods according to dates for, as [Jurij] Lotman points out, human culture is a dynamic system. Attempts to locate stages of cultural development within strict temporal boundaries contradict that dynamism. 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""fS5WjYLz"",""properties"":{""formattedCitation"":""(Bassnett, 2013: 41)"",""plainCitation"":""(Bassnett, 2013: 41)"",""noteIndex"":0},""citationItems"":[{""id"":23069,""uris"":[""http://zotero.org/users/563326/items/HYAW8M2G""],""uri"":[""http://zotero.org/users/563326/items/HYAW8M2G""],""itemData"":{""id"":23069,""type"":""book"",""archive"":""/z-wcorg/"",""event-place"":""London"",""ISBN"":""978-0-415-50670-0"",""language"":""English"",""publisher"":""Routledge"",""publisher-place"":""London"",""source"":""http://worldcat.org"",""title"":""Translation studies"",""author"":[{""family"":""Bassnett"",""given"":""Susan"",""suffix"":""""}],""issued"":{""date-parts"":[[""2013""]]}},""locator"":""41""}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Bassnett, 2013: 41)
                </quote>
                <p style=""text-align: left; "">How it comes that we can hypostatize the dynamic nature of cultural systems, superimposing on them a scalar chronology? How can we say, as Jameson puts it, that Ulysses is something that happened in 1922 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""wceoZivr"",""properties"":{""formattedCitation"":""(Jameson, 1971: 313)"",""plainCitation"":""(Jameson, 1971: 313)"",""noteIndex"":0},""citationItems"":[{""id"":23070,""uris"":[""http://zotero.org/users/563326/items/PPXFBW2C""],""uri"":[""http://zotero.org/users/563326/items/PPXFBW2C""],""itemData"":{""id"":23070,""type"":""book"",""archive"":""/z-wcorg/"",""event-place"":""Princeton (N.J.)"",""ISBN"":""0-691-01311-X"",""language"":""English"",""publisher"":""Princeton University Press"",""publisher-place"":""Princeton (N.J.)"",""source"":""http://worldcat.org"",""title"":""Marxism and form : twentieth-century dialectical theories of literature"",""author"":[{""family"":""Jameson"",""given"":""Fredric."",""suffix"":""""}],""issued"":{""date-parts"":[[""1971""]]}},""locator"":""313""}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Jameson, 1971: 313)? Following Meneghelli 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""xtBsafhB"",""properties"":{""formattedCitation"":""(Meneghelli, 2013)"",""plainCitation"":""(Meneghelli, 2013)"",""noteIndex"":0},""citationItems"":[{""id"":23071,""uris"":[""http://zotero.org/users/563326/items/94BW622F""],""uri"":[""http://zotero.org/users/563326/items/94BW622F""],""itemData"":{""id"":23071,""type"":""article-journal"",""container-title"":""CLCWeb: Comparative Literature and Culture"",""DOI"":""10.7771/1481-4374.2386"",""ISSN"":""1481-4374"",""issue"":""7"",""journalAbbreviation"":""CLCWeb: Comparative Literature and Culture"",""language"":""en"",""source"":""DOI.org (Crossref)"",""title"":""Periodization, Comparative Literature, and Italian Modernism"",""URL"":""https://docs.lib.purdue.edu/clcweb/vol15/iss7/12"",""volume"":""15"",""author"":[{""family"":""Meneghelli"",""given"":""Donata""}],""accessed"":{""date-parts"":[[""2021"",12,8]]},""issued"":{""date-parts"":[[""2013"",12,31]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Meneghelli, 2013), we can individuate at least 4 critical issues, or even aporias in literary periodization:
                </p>
                <list rend=""numbered"">
                    <item>Historical categories are related to cultural and social phenomena and overlap and interact in complex ways, determining 
                        <hi rend=""italic"">anisochronies</hi> and 
                        <hi rend=""italic"">dischronies</hi>;
                    </item>
                    <item>Most if not all literary-historical categories have an ontological and trans-historical status and meaning embedded in them (take for instance Romanticism or Modernism);</item>
                    <item>Historical categories interact with and are dependent on geospatial ones, resulting in a multiplicity of asynchronous periodizations;</item>
                    <item>The notion of a historical category in literature is strictly associated with the canonical corpus of texts that are considered representative of a period, and the “dialectics between these two poles, period and canon, are complex and manifold” (Meneghelli, 2013: 3).</item>
                </list>
                <p style=""text-align: left; "">This last point is particularly relevant: literary periodization is usually the product of a process of generalization and synthesis, within a historical and social horizon, of the small-scale critical and interpretive practices that characterize the study of literary texts. Being bound to idiosyncratic hermeneutical practices and to the “epistemology of close reading”, periodization suffers from all the pitfalls and limitations of that approach. In the last two decades, the landscape of literary and cultural studies has been enriched by a methodological perspective that is based on a quantitative approach. Among the various disciplinary labels that identify this current in studies, the most common is distant reading, introduced by Franco Moretti in his work on World Literature 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""ximCqQmL"",""properties"":{""formattedCitation"":""(Moretti, 2000)"",""plainCitation"":""(Moretti, 2000)"",""noteIndex"":0},""citationItems"":[{""id"":9395,""uris"":[""http://zotero.org/groups/113737/items/TBZ8UJQZ""],""uri"":[""http://zotero.org/groups/113737/items/TBZ8UJQZ""],""itemData"":{""id"":9395,""type"":""article-magazine"",""container-title"":""The New Left Review"",""issue"":""1"",""language"":""en"",""title"":""Conjectures on World Literature"",""URL"":""http://newleftreview.org/A2094"",""author"":[{""family"":""Moretti"",""given"":""Franco""}],""issued"":{""date-parts"":[[""2000""]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Moretti, 2000) and subsequently extended to denote (even retroactively) the entire tradition of quantitative literary studies 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""qgkuCAs2"",""properties"":{""formattedCitation"":""(Moretti, 2013; Underwood, 2019; Piper, 2018; Jockers, 2013)"",""plainCitation"":""(Moretti, 2013; Underwood, 2019; Piper, 2018; Jockers, 2013)"",""noteIndex"":0},""citationItems"":[{""id"":9592,""uris"":[""http://zotero.org/groups/113737/items/NXW5B9R3""],""uri"":[""http://zotero.org/groups/113737/items/NXW5B9R3""],""itemData"":{""id"":9592,""type"":""book"",""abstract"":""How does a literary historian end up thinking in terms of z-scores, principal component analysis, and clustering coefficient?\n\nIn the ten essays collected in this volume, Franco Moretti reconstructs the intellectual trajectory of his philosophy of ‘distant reading’. From the evolutionary model of ‘Modern European Literature’, through the geo-cultural dominant of ‘Conjectures on World Literature’ and ‘Planet Hollywood’ to the quantitative findings of ‘Style, inc.’ and the abstract patterns of ‘Network Theory, Plot Analysis’, the book follows two decades of critical explorations that have come to define – well beyond the wildest expectations of its author – a growing field of unorthodox literary studies."",""event-place"":""London"",""ISBN"":""978-1-78168-084-1"",""language"":""en"",""number-of-pages"":""224"",""publisher"":""Verso"",""publisher-place"":""London"",""title"":""Distant reading"",""URL"":""http://www.amazon.de/Distant-Reading-Franco-Moretti/dp/1781680841"",""author"":[{""family"":""Moretti"",""given"":""Franco""}],""issued"":{""date-parts"":[[""2013""]]}}},{""id"":78,""uris"":[""http://zotero.org/users/563326/items/B3AUADSC""],""uri"":[""http://zotero.org/users/563326/items/B3AUADSC""],""itemData"":{""id"":78,""type"":""book"",""call-number"":""PN73 .U53 2019"",""event-place"":""Chicago"",""ISBN"":""978-0-226-61266-9"",""publisher"":""The University of Chicago Press"",""publisher-place"":""Chicago"",""source"":""Library of Congress ISBN"",""title"":""Distant horizons: digital evidence and literary change"",""title-short"":""Distant horizons"",""author"":[{""family"":""Underwood"",""given"":""Ted""}],""issued"":{""date-parts"":[[""2019""]]}}},{""id"":77,""uris"":[""http://zotero.org/users/563326/items/DWL7YP9A""],""uri"":[""http://zotero.org/users/563326/items/DWL7YP9A""],""itemData"":{""id"":77,""type"":""book"",""call-number"":""PN98.E4 P56 2018"",""event-place"":""Chicago ; London"",""ISBN"":""978-0-226-56861-4"",""number-of-pages"":""243"",""publisher"":""The University of Chicago Press"",""publisher-place"":""Chicago ; London"",""source"":""Library of Congress ISBN"",""title"":""Enumerations: data and literary study"",""title-short"":""Enumerations"",""author"":[{""family"":""Piper"",""given"":""Andrew""}],""issued"":{""date-parts"":[[""2018""]]}}},{""id"":9743,""uris"":[""http://zotero.org/groups/113737/items/NCNSAG62""],""uri"":[""http://zotero.org/groups/113737/items/NCNSAG62""],""itemData"":{""id"":9743,""type"":""book"",""abstract"":""In this volume, Matthew L. Jockers introduces readers to large-scale literary computing and the revolutionary potential of macroanalysis--a new approach to the study of the literary record designed for probing the digital-textual world as it exists today, in digital form and in large quantities. Using computational analysis to retrieve key words, phrases, and linguistic patterns across thousands of texts in digital libraries, researchers can draw conclusions based on quantifiable evidence regarding how literary trends are employed over time, across periods, within regions, or within demographic groups, as well as how cultural, historical, and societal linkages may bind individual authors, texts, and genres into an aggregate literary culture.\n \nMoving beyond the limitations of literary interpretation based on the \""close-reading\"" of individual works, Jockers describes how this new method of studying large collections of digital material can help us to better understand and contextualize the individual works within those collections."",""collection-title"":""Topics in the Digital Humanities"",""ISBN"":""978-0-252-07907-8"",""language"":""en"",""publisher"":""University of Illinois Press"",""title"":""Macroanalysis: Digital Methods and Literary History"",""URL"":""http://books.google.de/books?hl=de&lr=&id=mPOdxQgpOSUC&oi=fnd&pg=PP2&dq=Macroanalysis:+Digital+Methods+and+Literary+History&ots=R8NZyYyjSh&sig=OkLlZGTVZZMmpYgvq8CQgRzlRSw#v=onepage&q=Macroanalysis%3A%20Digital%20Methods%20and%20Literary%20History&f=false"",""author"":[{""family"":""Jockers"",""given"":""Matthew L.""}],""issued"":{""date-parts"":[[""2013"",6]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Moretti, 2013; Underwood, 2019; Piper, 2018; Jockers, 2013). In this framework literary texts are elements of a population whose synchronic and diachronic characteristics should be empirically investigated on a molar scale, adopting statistical-probabilistic and computational methods. This would require the move from 
                    <hi rend=""italic"">interpretation</hi> to 
                    <hi rend=""italic"">explanation</hi> as the primary methodology of scholarly inquiry in the cultural and literary domains 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""fpyviCGK"",""properties"":{""formattedCitation"":""(Ciotti, 2021)"",""plainCitation"":""(Ciotti, 2021)"",""noteIndex"":0},""citationItems"":[{""id"":23073,""uris"":[""http://zotero.org/users/563326/items/NYDFYR4I""],""uri"":[""http://zotero.org/users/563326/items/NYDFYR4I""],""itemData"":{""id"":23073,""type"":""article-journal"",""abstract"":""Since Franco Moretti coined the successful term distant reading, quantitative/computational text analysis methods have gained wide circulation in literary studies. The diffusion of distant reading approaches has raised a lively debate and has attracted various criticisms, both from “traditional literary scholars” and from self-critical adopters. One important reason underlying these critical positions is the fact that it lacks sound and coherent rationales from the point of view of the theory: distant reading is the first methodology in literary studies that does not come with a theory of literature embedded in it. Consequently, all distant reading studies derive their theoretical frameworks and terms from literary theories that mostly rely on the notion that literary texts can be explained only by the way of interpretation. On what grounds, then, can we construct a theory of literature amenable to distant reading methods? I think that the better theoretical frameworks are the cognitive and bio-evolutionistic approaches to literature and cultural evolution studies. These theoretical approaches require a change in the level of description of the literary domain and justify the move from \""interpretation\"" to \""explanation\"" as the real aim of the scholarly inquiry."",""container-title"":""TESTO & SENSO"",""ISSN"":""2036-2293"",""issue"":""23"",""title"":""Distant reading in literary studies: a methodology in quest of theory"",""author"":[{""family"":""Ciotti"",""given"":""Fabio""}],""issued"":{""date-parts"":[[""2021""]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Ciotti, 2021). 
                </p>
                <p style=""text-align: left; "">The possible contribution of a distant reading approach to the literary periodization problem, has been previously explored by some important studies, like 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""6nGWCm9S"",""properties"":{""formattedCitation"":""(Jockers, 2013: chap. 6)"",""plainCitation"":""(Jockers, 2013: chap. 6)"",""noteIndex"":0},""citationItems"":[{""id"":9743,""uris"":[""http://zotero.org/groups/113737/items/NCNSAG62""],""uri"":[""http://zotero.org/groups/113737/items/NCNSAG62""],""itemData"":{""id"":9743,""type"":""book"",""abstract"":""In this volume, Matthew L. Jockers introduces readers to large-scale literary computing and the revolutionary potential of macroanalysis--a new approach to the study of the literary record designed for probing the digital-textual world as it exists today, in digital form and in large quantities. Using computational analysis to retrieve key words, phrases, and linguistic patterns across thousands of texts in digital libraries, researchers can draw conclusions based on quantifiable evidence regarding how literary trends are employed over time, across periods, within regions, or within demographic groups, as well as how cultural, historical, and societal linkages may bind individual authors, texts, and genres into an aggregate literary culture.\n \nMoving beyond the limitations of literary interpretation based on the \""close-reading\"" of individual works, Jockers describes how this new method of studying large collections of digital material can help us to better understand and contextualize the individual works within those collections."",""collection-title"":""Topics in the Digital Humanities"",""ISBN"":""978-0-252-07907-8"",""language"":""en"",""publisher"":""University of Illinois Press"",""title"":""Macroanalysis: Digital Methods and Literary History"",""URL"":""http://books.google.de/books?hl=de&lr=&id=mPOdxQgpOSUC&oi=fnd&pg=PP2&dq=Macroanalysis:+Digital+Methods+and+Literary+History&ots=R8NZyYyjSh&sig=OkLlZGTVZZMmpYgvq8CQgRzlRSw#v=onepage&q=Macroanalysis%3A%20Digital%20Methods%20and%20Literary%20History&f=false"",""author"":[{""family"":""Jockers"",""given"":""Matthew L.""}],""issued"":{""date-parts"":[[""2013"",6]]}},""locator"":""6"",""label"":""chapter""}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Jockers, 2013: chap. 6), 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""SFTfOWSB"",""properties"":{""formattedCitation"":""(Piper, 2018: chap. 4)"",""plainCitation"":""(Piper, 2018: chap. 4)"",""noteIndex"":0},""citationItems"":[{""id"":77,""uris"":[""http://zotero.org/users/563326/items/DWL7YP9A""],""uri"":[""http://zotero.org/users/563326/items/DWL7YP9A""],""itemData"":{""id"":77,""type"":""book"",""call-number"":""PN98.E4 P56 2018"",""event-place"":""Chicago ; London"",""ISBN"":""978-0-226-56861-4"",""number-of-pages"":""243"",""publisher"":""The University of Chicago Press"",""publisher-place"":""Chicago ; London"",""source"":""Library of Congress ISBN"",""title"":""Enumerations: data and literary study"",""title-short"":""Enumerations"",""author"":[{""family"":""Piper"",""given"":""Andrew""}],""issued"":{""date-parts"":[[""2018""]]}},""locator"":""4"",""label"":""chapter""}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Piper, 2018: chap. 4), 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""JXUMQRFz"",""properties"":{""formattedCitation"":""(Underwood, 2019)"",""plainCitation"":""(Underwood, 2019)"",""noteIndex"":0},""citationItems"":[{""id"":78,""uris"":[""http://zotero.org/users/563326/items/B3AUADSC""],""uri"":[""http://zotero.org/users/563326/items/B3AUADSC""],""itemData"":{""id"":78,""type"":""book"",""call-number"":""PN73 .U53 2019"",""event-place"":""Chicago"",""ISBN"":""978-0-226-61266-9"",""publisher"":""The University of Chicago Press"",""publisher-place"":""Chicago"",""source"":""Library of Congress ISBN"",""title"":""Distant horizons: digital evidence and literary change"",""title-short"":""Distant horizons"",""author"":[{""family"":""Underwood"",""given"":""Ted""}],""issued"":{""date-parts"":[[""2019""]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Underwood, 2019) for English narrative fiction, all based on a supervised classification approach; while 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""XdMNW8Qe"",""properties"":{""formattedCitation"":""(Jannidis and Lauer, 2014)"",""plainCitation"":""(Jannidis and Lauer, 2014)"",""noteIndex"":0},""citationItems"":[{""id"":14351,""uris"":[""http://zotero.org/groups/643516/items/4DAVX3FR""],""uri"":[""http://zotero.org/groups/643516/items/4DAVX3FR""],""itemData"":{""id"":14351,""type"":""chapter"",""container-title"":""Distant Readings. Topologies of German Culture in the Long Nineteenth Century"",""event-place"":""Rochester"",""language"":""en"",""note"":""bibtex: jannidis_burrowss_2014"",""page"":""29-54"",""publisher"":""Camden House"",""publisher-place"":""Rochester"",""title"":""Burrows’s Delta and Its Use in German Literary History"",""URL"":""gerhardlauer.de/index.php/download_file/view/335/1/"",""author"":[{""family"":""Jannidis"",""given"":""Fotis""},{""family"":""Lauer"",""given"":""Gerhard""}],""editor"":[{""family"":""Erlin"",""given"":""Matt""},{""family"":""Tatlock"",""given"":""Lynne""}],""issued"":{""date-parts"":[[""2014""]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Jannidis and Lauer, 2014) for German literature adopted a stylometric method. This paper explores the results of a mainly explorative and unsupervised analysis of a corpus of 19
                    <hi rend=""superscript"">th</hi> and 20th century Italian narrative fiction.
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>The corpus and the methodology</head>
                <p style=""text-align: left; "">The main research hypothesis is if adopting computational quantitative methods, it’s possible to identify time-based groupings in a set of texts distributed over a long historical period. Related to this there is the question of whether those eventual groupings are aligned with traditional historical periodization. The corpus consists of 660 Italian novels and short novels written between 1810 and 2000 of different aesthetic ""levels"", canonization status, genre, dimension, and authors’ gender. Admittedly, this corpus is still far from being adequate and well balanced, mainly due to the uneven chronological distribution, but it is sufficient for an exploratory inquiry.</p>
                <p style=""text-align: left; "">I wanted to test if the corpus can be clustered in a chronological sensible way using an algorithmic approach without presuming any prior categorization: this explains the preference for unsupervised methods in this research. In particular, I have adopted two different approaches, based on different assumptions, analytical techniques and features selection:</p>
                <list rend=""numbered"">
                    <item>bootstrap consensus network, following (Eder, 2017) that applies phylogenetic consensus networks method to MFW based clustering;</item>
                    <item>lexicon-based text analysis and subsequent K-Means clustering of the results.</item>
                </list>
                <p style=""text-align: left; "">Fort the first experiment I have adopted the popular stylometric R package 
                    <hi rend=""italic"">Stylo</hi>
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""DOw0LjCA"",""properties"":{""formattedCitation"":""(Eder et al., 2016)"",""plainCitation"":""(Eder et al., 2016)"",""noteIndex"":0},""citationItems"":[{""id"":21620,""uris"":[""http://zotero.org/groups/1624882/items/BUVWB3VR""],""uri"":[""http://zotero.org/groups/1624882/items/BUVWB3VR""],""itemData"":{""id"":21620,""type"":""article-journal"",""container-title"":""The R Journal"",""ISSN"":""2073-4859"",""issue"":""1"",""language"":""en"",""page"":""107-121"",""title"":""Stylometry with R: A Package for Computational Text Analysis"",""volume"":""8"",""author"":[{""family"":""Eder"",""given"":""Maciej""},{""family"":""Rybicki"",""given"":""Jan""},{""family"":""Kestemont"",""given"":""Mike""}],""issued"":{""date-parts"":[[""2016""]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Eder et al., 2016) to generate the consensus network dataset, conflating ten hierarchical clusterings generated comparing from 100 to 1000 most frequent words. The resulting output dataset is imported into the network analysis tool Gephi 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""dKwsbgCF"",""properties"":{""formattedCitation"":""(Bastian et al., 2009)"",""plainCitation"":""(Bastian et al., 2009)"",""noteIndex"":0},""citationItems"":[{""id"":21501,""uris"":[""http://zotero.org/groups/1624882/items/NUL5XE72""],""uri"":[""http://zotero.org/groups/1624882/items/NUL5XE72""],""itemData"":{""id"":21501,""type"":""webpage"",""language"":""en"",""title"":""Gephi - The Open Graph Viz Platform"",""URL"":""https://gephi.org/"",""author"":[{""family"":""Bastian"",""given"":""Mathieu""},{""family"":""Heymann"",""given"":""Sebastien""},{""family"":""Jacomy"",""given"":""Mathieu""}],""accessed"":{""date-parts"":[[""2018"",11,26]]},""issued"":{""date-parts"":[[""2009""]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Bastian et al., 2009) and each node is associated with an attribute that specifies its decade of composition. Then modularity is calculated with a resolution set at 4, resulting in 10 modules, and the final layout is generated applying the layout algorithm Force Atlas 2.
                </p>
                <p style=""text-align: left; "">The second approach is based on the text analysis of the corpus with the tool 
                    <hi rend=""italic"">Linguistic Inquiry and Word Count</hi> (
                    <hi rend=""italic"">LIWC</hi>) 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""jOFaMGB9"",""properties"":{""formattedCitation"":""(Pennebaker et al., 2015)"",""plainCitation"":""(Pennebaker et al., 2015)"",""noteIndex"":0},""citationItems"":[{""id"":23075,""uris"":[""http://zotero.org/users/563326/items/8PZK35JN""],""uri"":[""http://zotero.org/users/563326/items/8PZK35JN""],""itemData"":{""id"":23075,""type"":""article-journal"",""abstract"":""The paper summarizes the nature of the LIWC2015 text analysis program, including the development of the dictionaries and the basic psychometrics of the output. Results of the 2015 version are compared with the 2007 version."",""DOI"":""10.15781/T29G6Z"",""note"":""publisher: University of Texas at Austin"",""source"":""DOI.org (Datacite)"",""title"":""The Development and Psychometric Properties of LIWC2015"",""URL"":""http://hdl.handle.net/2152/31333"",""author"":[{""family"":""Pennebaker"",""given"":""James W.""},{""family"":""Boyd"",""given"":""Ryan L.""},{""family"":""Jordan"",""given"":""Kayla""},{""family"":""Blackburn"",""given"":""Kate""}],""accessed"":{""date-parts"":[[""2021"",12,8]]},""issued"":{""date-parts"":[[""2015""]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Pennebaker et al., 2015). For each text, LIWC produces a vector containing the relative frequencies of various words-classes (E.g.: ""Affect Words"", ""Cognitive Processes"", ""Perceptual Processes"", ""Biological Processes""....). The final output is a low dimensional document matrix, to which I have applied a K-Means clustering process, adopting the Python implementation of the algorithm in the 
                    <hi rend=""italic"">SciKit-Learn</hi> library 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""A7QCNvwN"",""properties"":{""formattedCitation"":""(Pedregosa et al., 2011)"",""plainCitation"":""(Pedregosa et al., 2011)"",""noteIndex"":0},""citationItems"":[{""id"":23079,""uris"":[""http://zotero.org/users/563326/items/AM5MGWGN""],""uri"":[""http://zotero.org/users/563326/items/AM5MGWGN""],""itemData"":{""id"":23079,""type"":""article-journal"",""container-title"":""Journal of Machine Learning Research"",""page"":""2825–2830"",""title"":""Scikit-learn: Machine Learning in Python"",""volume"":""12"",""author"":[{""family"":""Pedregosa"",""given"":""F.""},{""family"":""Varoquaux"",""given"":""G.""},{""family"":""Gramfort"",""given"":""A.""},{""family"":""Michel"",""given"":""V.""},{""family"":""Thirion"",""given"":""B.""},{""family"":""Grisel"",""given"":""O.""},{""family"":""Blondel"",""given"":""M.""},{""family"":""Prettenhofer"",""given"":""P.""},{""family"":""Weiss"",""given"":""R.""},{""family"":""Dubourg"",""given"":""V.""},{""family"":""Vanderplas"",""given"":""J.""},{""family"":""Passos"",""given"":""A.""},{""family"":""Cournapeau"",""given"":""D.""},{""family"":""Brucher"",""given"":""M.""},{""family"":""Perrot"",""given"":""M.""},{""family"":""Duchesnay"",""given"":""E.""}],""issued"":{""date-parts"":[[""2011""]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Pedregosa et al., 2011). The choice of the number of clusters has been done evaluating 20 different models with 
                    <hi rend=""italic"">Elbow method</hi> and 
                    <hi rend=""italic"">Silhouette Score</hi> tests, which both indicated an optimal value of 4 clusters.
                </p>
            </div>
            <div type=""div1"" rend=""DH-Heading1"">
                <head>Results and future directions</head>
                <p style=""text-align: left; "">The results of the stylometric approach represented in Fig.1 shows that the texts clustered in time sensible way are only those written in the second half of the 20
                    <hi rend=""superscript"">th</hi> century (that in the network have a blue color tone), while texts written in the first and second half of the 19
                    <hi rend=""superscript"">th</hi> century e in the first half of 20
                    <hi rend=""superscript"">th</hi> are not clearly separated, with the exception of the island in the upper right part of the graph, which is mostly composed of canonical Italian modernist texts.
                </p>
                <figure>
                    <graphic n=""1001"" width=""12.319cm"" height=""12.319cm"" url=""Pictures/f514364a2180618c1abff11b98f948cf.png"" rend=""inline""/>
                    <head>Consensus Network of the corpus: red 1810-1860; green 1860-1900; yellow 1900-1940; blue 1940-2010</head>
                </figure>
                <p style=""text-align: left; "">This overall result is confirmed by the K-Means approach. For my analysis I have produced two matrices using the LIWC dictionary for Italian 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""Oe6Nh7RK"",""properties"":{""formattedCitation"":""(Agosti and Rellini, 2007)"",""plainCitation"":""(Agosti and Rellini, 2007)"",""noteIndex"":0},""citationItems"":[{""id"":23078,""uris"":[""http://zotero.org/users/563326/items/NXQXPK6N""],""uri"":[""http://zotero.org/users/563326/items/NXQXPK6N""],""itemData"":{""id"":23078,""type"":""article-journal"",""container-title"":""Austin, TX: LIWC. net"",""title"":""The Italian LIWC dictionary"",""author"":[{""family"":""Agosti"",""given"":""A.""},{""family"":""Rellini"",""given"":""A.""}],""issued"":{""date-parts"":[[""2007""]]}}}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Agosti and Rellini, 2007):
                </p>
                <list rend=""bulleted"">
                    <item>a matrix with all LIWC lexical categories;</item>
                    <item>a matrix limited to the following word categories: Verbs, Pronouns, orthographic signs of represented speech, and categories related to emotional and cognitive activity.</item>
                </list>
                <p style=""text-align: left; "">In this way I can test an additional hypothesis very common in literary-historical and critical scholarship: the linguistic sphere of the cognitive and emotional dimension is a characteristic feature of the evolution of narrative along the nineteenth and twentieth centuries, namely it’s a characteristic of the transition to the Modernism. While the K-Means clustering of the first matrix has very little relation to chronology, the second one provides clear indicators of temporal segmentation (Figure 2). Therefore, we can say that the incidence of the lexicon related to the sphere of thought/consciousness/emotivity is a signal of an evolutional pattern in the Italian novel. Anyway, also in this case the more clearly time-based cluster is that of the text written in the second half of the 20
                    <hi rend=""superscript"">th</hi> century.
                </p>
                <figure>
                    <graphic n=""1002"" width=""13.399322222222223cm"" height=""9.051636111111112cm"" url=""Pictures/7ba82f17121d4aa77bfcec9b222cb72f.png"" rend=""inline""/>
                    <head>K-Means clusters in the document matrix restricted to the cognitive/emotional lexicon</head>
                </figure>
                <p style=""text-align: left; "">In conclusion, the first analysis in general confirms for Italian literature the limited role of the time dimension for clustering texts on a purely stylometric base already observed by 
                    <?biblio ADDIN ZOTERO_ITEM CSL_CITATION {""citationID"":""rjihgbqd"",""properties"":{""formattedCitation"":""(Jockers, 2013: chap. 6)"",""plainCitation"":""(Jockers, 2013: chap. 6)"",""noteIndex"":0},""citationItems"":[{""id"":9743,""uris"":[""http://zotero.org/groups/113737/items/NCNSAG62""],""uri"":[""http://zotero.org/groups/113737/items/NCNSAG62""],""itemData"":{""id"":9743,""type"":""book"",""abstract"":""In this volume, Matthew L. Jockers introduces readers to large-scale literary computing and the revolutionary potential of macroanalysis--a new approach to the study of the literary record designed for probing the digital-textual world as it exists today, in digital form and in large quantities. Using computational analysis to retrieve key words, phrases, and linguistic patterns across thousands of texts in digital libraries, researchers can draw conclusions based on quantifiable evidence regarding how literary trends are employed over time, across periods, within regions, or within demographic groups, as well as how cultural, historical, and societal linkages may bind individual authors, texts, and genres into an aggregate literary culture.\n \nMoving beyond the limitations of literary interpretation based on the \""close-reading\"" of individual works, Jockers describes how this new method of studying large collections of digital material can help us to better understand and contextualize the individual works within those collections."",""collection-title"":""Topics in the Digital Humanities"",""ISBN"":""978-0-252-07907-8"",""language"":""en"",""publisher"":""University of Illinois Press"",""title"":""Macroanalysis: Digital Methods and Literary History"",""URL"":""http://books.google.de/books?hl=de&lr=&id=mPOdxQgpOSUC&oi=fnd&pg=PP2&dq=Macroanalysis:+Digital+Methods+and+Literary+History&ots=R8NZyYyjSh&sig=OkLlZGTVZZMmpYgvq8CQgRzlRSw#v=onepage&q=Macroanalysis%3A%20Digital%20Methods%20and%20Literary%20History&f=false"",""author"":[{""family"":""Jockers"",""given"":""Matthew L.""}],""issued"":{""date-parts"":[[""2013"",6]]}},""locator"":""6"",""label"":""chapter""}],""schema"":""https://github.com/citation-style-language/schema/raw/master/csl-citation.json""}?>(Jockers, 2013: chap. 6), as compared to authorship and even author gender. Instead, there is some evidence that quantitative empirical analysis partially confirms the relevance of cognitive/emotional lexicon in the evolution of literature. In this direction, I think that a fruitful development of the research will require a more effective way to identify the presence of cognitive/emotional attitudes in texts. To this end, we are training a streamlined Italian BERT language model to identify the relevant textual blocks, and the provisional results are promising.
                </p>
            </div>
        </body>
        <back>
            <div type=""bibliogr"">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Agosti, A. and Rellini, A.</hi> (2007). The Italian LIWC dictionary. 
                        <hi rend=""italic"">Austin, TX: LIWC. Net</hi>.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Bassnett, S.</hi> (2013). 
                        <hi rend=""italic"">Translation Studies</hi>. London: Routledge.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Bastian, M., Heymann, S. and Jacomy, M.</hi> (2009). Gephi - The Open Graph Viz Platform https://gephi.org/ (accessed 26 November 2018).
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Ciotti, F.</hi> (2021). Distant reading in literary studies: a methodology in quest of theory. 
                        <hi rend=""italic"">TESTO & SENSO</hi>(23).
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Eder, M.</hi> (2017). Visualization in stylometry: Cluster analysis using networks. 
                        <hi rend=""italic"">Digital Scholarship in the Humanities</hi>, 
                        <hi rend=""bold"">32</hi>(1): 50–64 doi:10.1093/llc/fqv061.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Eder, M., Rybicki, J. and Kestemont, M.</hi> (2016). Stylometry with R: A Package for Computational Text Analysis. 
                        <hi rend=""italic"">The R Journal</hi>, 
                        <hi rend=""bold"">8</hi>(1): 107–21.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Jameson, Fredric.</hi> (1971). 
                        <hi rend=""italic"">Marxism and Form : Twentieth-Century Dialectical Theories of Literature</hi>. Princeton (N.J.): Princeton University Press.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Jannidis, F. and Lauer, G.</hi> (2014). Burrows’s Delta and Its Use in German Literary History. In Erlin, M. and Tatlock, L. (eds), 
                        <hi rend=""italic"">Distant Readings. Topologies of German Culture in the Long Nineteenth Century</hi>. Rochester: Camden House, pp. 29–54 gerhardlauer.de/index.php/download_file/view/335/1/.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Jockers, M. L.</hi> (2013). 
                        <hi rend=""italic"">Macroanalysis: Digital Methods and Literary History</hi>. (Topics in the Digital Humanities). University of Illinois Press 
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">helli, D.</hi> (2013). Periodization, Comparative Literature, and Italian Modernism. 
                        <hi rend=""italic"">CLCWeb: Comparative Literature and Culture</hi>, 
                        <hi rend=""bold"">15</hi>(7) doi:10.7771/1481-4374.2386. https://docs.lib.purdue.edu/clcweb/vol15/iss7/12 (accessed 8 December 2021).
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Moretti, F.</hi> (2000). Conjectures on World Literature. 
                        <hi rend=""italic"">The New Left Review</hi> http://newleftreview.org/A2094.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Moretti, F.</hi> (2013). 
                        <hi rend=""italic"">Distant Reading</hi>. London: Verso http://www.amazon.de/Distant-Reading-Franco-Moretti/dp/1781680841.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., et al.</hi> (2011). Scikit-learn: Machine Learning in Python. 
                        <hi rend=""italic"">Journal of Machine Learning Research</hi>, 
                        <hi rend=""bold"">12</hi>: 2825–30.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Pennebaker, J. W., Boyd, R. L., Jordan, K. and Blackburn, K.</hi> (2015). The Development and Psychometric Properties of LIWC2015. University of Texas at Austin doi:10.15781/T29G6Z. http://hdl.handle.net/2152/31333 (accessed 8 December 2021).
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Piper, A.</hi> (2018). 
                        <hi rend=""italic"">Enumerations: Data and Literary Study</hi>. Chicago ; London: The University of Chicago Press.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Underwood, T.</hi> (2019). 
                        <hi rend=""italic"">Distant Horizons: Digital Evidence and Literary Change</hi>. Chicago: The University of Chicago Press.
                    </bibl>
                    <bibl style=""text-align: left; "">
                        <hi rend=""bold"">Wellek, R., Warren, Austin,,</hi> (1956). 
                        <hi rend=""italic"">Theory of Literature</hi>. New York: Harcourt, Brace & World.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>

",xml,This text is republished here with permission from the original rights holder.,,computational literary studies;distant reading;history of literature;italian modernism;theory of literature,English,19th century;20th century;cultural analytics;english;europe;literary studies;text mining and analysis
